{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import count\n",
    "from collections import deque\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import tqdm\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from time import sleep\n",
    "import os\n",
    "\n",
    "#Import Custom Classes\n",
    "\n",
    "from Source.nn_model_dqn import QNetwork\n",
    "from Source.dqn_rcv_agent import Agent, ReplayBuffer, EpsilonGreedyStrategy\n",
    "from Source.env_manager import EnvManager\n",
    "from Source.misc_fun.utils import plot, get_moving_average, Generate_BeamDir, All_Exhaustive_RateMeas\n",
    "from Source.PER import PrioritizedReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "#Hyper-parameters\n",
    "BUFFER_SIZE = 8#int(1e5)      #replay buffer size\n",
    "BATCH_SIZE = 8#128             #minibatch size\n",
    "GAMMA = 0.999                #discount factor\n",
    "TAU = 1e-2#1e-1                  #for soft update of target parameters\n",
    "LR = 1e-3                   #learning rate\n",
    "TEST_EVERY = 1600            #how often to test the network\n",
    "UPDATE_EVERY =1\n",
    "eps_start = 1.0\n",
    "eps_end = 0.5\n",
    "eps_decay = 0.9981 #125e-6\n",
    "PER_ALPHA = 0.6\n",
    "PER_BETA = 0.4\n",
    "PRIORITIZED_REPLAY = False\n",
    "\n",
    "episodes = 6000 #3100 train, 500 test\n",
    "seed = 0                    #random seed number\n",
    "#%%\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "inp_fptr = open(\"ricianch_variation.txt\")\n",
    "ch_randvals = inp_fptr.read().splitlines()\n",
    "ch_randvals = [np.complex(a.replace('i','j')) for a in ch_randvals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.1128+0.0082264j)\n"
     ]
    }
   ],
   "source": [
    "print(ch_randvals[0])\n",
    "\n",
    "#print(np.complex(ch_randvals[0].replace('i','j')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beamset: [(0.39269908, 8) (0.78539816, 8) (1.17809725, 8) (1.57079633, 8)\n",
      " (1.96349541, 8) (2.35619449, 8) (2.74889357, 8) (3.14159265, 8)]\n",
      "Bemset in deg: [(22.500000000000004, 8), (45.0, 8), (67.5, 8), (90.0, 8), (112.5, 8), (135.0, 8), (157.5, 8), (180.0, 8)]\n",
      "Ntx: 8, active Ntx: 4, Beam: [ 0.35355339+0.j         -0.21414724-0.28132003j -0.09413548+0.34079101j\n",
      "  0.32818294-0.13151411j -0.30342524-0.18147485j  0.03938632+0.3513527j\n",
      "  0.25571266-0.24415371j -0.34915657-0.05558496j]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Testing (beam_dir, beam_width) Beamset\n",
    "from Source.antenna.ula import var_steervec\n",
    "from Source.misc_fun.utils import Generate_Beams, var_plotbeam\n",
    "\n",
    "width_vec = np.array([np.pi/8])\n",
    "beamset = Generate_Beams(8,width_vec)\n",
    "\n",
    "print(\"Beamset: {}\".format(beamset))\n",
    "print(\"Bemset in deg: {}\".format([(x[0]*180/np.pi,x[1]) for x in beamset]))\n",
    "\n",
    "tx_beam = var_steervec(8,beamset[5], 0)\n",
    "print(\"Ntx: {}, active Ntx: {}, Beam: {}\".format(8, 4, tx_beam))\n",
    "\n",
    "theta, gr = var_plotbeam(beamset[5], 8)\n",
    "theta2, gr2 = var_plotbeam(beamset[7], 8)\n",
    "theta3, gr3 = var_plotbeam(beamset[2], 4)\n",
    "ax = plt.subplot(111, projection='polar')\n",
    "##print(theta.shape, gr.shape)\n",
    "ax.plot(theta,gr, theta2, gr2, theta3,gr3)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {},
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uma-los\n",
      "[]\n",
      "QNetwork(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=4, out_features=400, bias=True)\n",
      "    (1): Linear(in_features=400, out_features=400, bias=True)\n",
      "    (2): Linear(in_features=400, out_features=64, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      "  (output): Linear(in_features=64, out_features=16, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Choose the environment\n",
    "em = EnvManager(device, 'combrf-v7', seed)\n",
    "available_actions = em.num_actions_available()\n",
    "random.seed(seed)\n",
    "state_size = em.state_size()\n",
    "print(em.env.ch_model)\n",
    "print(em.env.sc_xyz)\n",
    "\n",
    "#EPISODE length\n",
    "min_episode_length = em.env.N_rx\n",
    "max_episode_length = em.env.N_rx\n",
    "episode_delta = 1\n",
    "\n",
    "#Select the strategy\n",
    "strategy = EpsilonGreedyStrategy(eps_start, eps_end, eps_decay, 3500)\n",
    "\n",
    "if PRIORITIZED_REPLAY:\n",
    "    beta_strategy = EpsilonGreedyStrategy(PER_BETA, 1.0, eps_decay, 3500)\n",
    "\n",
    "#Initialize the agent\n",
    "agent = Agent(strategy, state_size, available_actions, seed, device)\n",
    "\n",
    "#Instantiate MemoryBuffer\n",
    "if not PRIORITIZED_REPLAY:\n",
    "    memory = ReplayBuffer(available_actions, BUFFER_SIZE, BATCH_SIZE, seed, device)\n",
    "else:\n",
    "    memory = PrioritizedReplayBuffer(available_actions, BUFFER_SIZE, BATCH_SIZE, PER_ALPHA,seed, device)\n",
    "\n",
    "policy_net = QNetwork(state_size, available_actions, seed).to(device)\n",
    "target_net = QNetwork(state_size, available_actions, seed).to(device)\n",
    "print(policy_net)\n",
    "\n",
    "#Initialize target_net weights to policy_net weights\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval() #Set the target_net in eval mode\n",
    "\n",
    "#Select the optimizer\n",
    "optimizer = optim.Adam(params=policy_net.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tx_locs: [array([[-300. , -300. ,   21.5]]), array([[-300. , -200. ,   21.5]]), array([[-300. , -100. ,   21.5]]), array([[-300. , -400. ,   21.5]]), array([[-300. , -500. ,   21.5]]), array([[-200. , -300. ,   21.5]]), array([[-200. , -200. ,   21.5]]), array([[-200. , -100. ,   21.5]]), array([[-200. , -400. ,   21.5]]), array([[-200. , -500. ,   21.5]]), array([[-100. , -300. ,   21.5]]), array([[-100. , -200. ,   21.5]]), array([[-100. , -100. ,   21.5]]), array([[-100. , -400. ,   21.5]]), array([[-100. , -500. ,   21.5]]), array([[-400. , -300. ,   21.5]]), array([[-400. , -200. ,   21.5]]), array([[-400. , -100. ,   21.5]]), array([[-400. , -400. ,   21.5]]), array([[-400. , -500. ,   21.5]]), array([[-500. , -300. ,   21.5]]), array([[-500. , -200. ,   21.5]]), array([[-500. , -100. ,   21.5]]), array([[-500. , -400. ,   21.5]]), array([[-500. , -500. ,   21.5]])]\n"
     ]
    }
   ],
   "source": [
    "print(\"tx_locs: {}\".format(em.env.tx_locs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beamset: [(0.19634954, 16) (0.39269908, 16) (0.58904862, 16) (0.78539816, 16)\n",
      " (0.9817477 , 16) (1.17809725, 16) (1.37444679, 16) (1.57079633, 16)\n",
      " (1.76714587, 16) (1.96349541, 16) (2.15984495, 16) (2.35619449, 16)\n",
      " (2.55254403, 16) (2.74889357, 16) (2.94524311, 16) (3.14159265, 16)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Beamset: {}\".format(em.env.BeamSet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Test with random untrained actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "obs = em.env.reset(np.exp(1j * 2 * np.pi * 0.6),0)\n",
    "#print(len(em.env.beamwidth_vec))\n",
    "#print(em.env.action_space.n)\n",
    "print(obs)\n",
    "ep_rwd=[]\n",
    "while True:\n",
    "    action = random.randrange(em.env.action_space.n)\n",
    "    \n",
    "    obs, rwd, done,_ = em.env.step(action)\n",
    "    print(action)\n",
    "    ep_rwd.append(rwd)\n",
    "    if done:\n",
    "        break\n",
    "        \n",
    "print(\"Episode score: {}\".format(np.sum(ep_rwd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "uma-los\n"
     ]
    }
   ],
   "source": [
    "print(em.env.sc_xyz)\n",
    "print(em.env.ch_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "from Source.misc_fun.channel_mmW import *\n",
    "from Source.misc_fun.geometry import *\n",
    "from Source.antenna import ula\n",
    "\n",
    "def Compute_AvgError(em, device, policy_net, ch_randval, loc_errors):\n",
    "    #loc_errors = []\n",
    "    for tx_loc in em.env.tx_locs:\n",
    "        tx_dir_ndx = 0\n",
    "        norm_tx_xloc = np.array([(tx_loc[0][0]) / 1000])  \n",
    "        norm_tx_yloc = np.array([(tx_loc[0][1]) / 1000])  \n",
    "        norm_tx_zloc = np.array([(tx_loc[0][2]) / 22.5])\n",
    "        norm_tx_ndx = np.array([tx_dir_ndx/ em.env.obs_space.nvec[3]])\n",
    "        obs = np.array([np.concatenate((norm_tx_ndx, norm_tx_xloc, norm_tx_yloc, norm_tx_zloc), axis=0)])\n",
    "        obs_tensor = torch.tensor(obs, device=device, dtype=torch.float32)\n",
    "        policy_net.eval()\n",
    "        with torch.no_grad():\n",
    "            action_probs = policy_net(obs_tensor).detach().data.cpu().numpy()[0]  \n",
    "        policy_net.train()\n",
    "        best_rxdir_ndx= np.argsort(action_probs)[::-1][0]\n",
    "        \n",
    "        #compute dqn rate\n",
    "        \n",
    "        dbp = 4 * tx_loc[0, 2] * em.env.rx_loc[0, 2] * em.env.freq / em.env.c\n",
    "        d_2d = np.linalg.norm(np.array([[tx_loc[0, 0], tx_loc[0, 1], 0]]) - np.array(\n",
    "            [[em.env.rx_loc[0, 0], em.env.rx_loc[0, 1], 0]]))\n",
    "\n",
    "        if(dbp <= d_2d <= 5e3) and (em.env.ch_model == 'uma-los'):\n",
    "            ch_model = em.env.init_ch_model + '-dbp'\n",
    "        else:\n",
    "            ch_model = em.env.init_ch_model\n",
    "\n",
    "        channel = Channel(em.env.freq, tx_loc, em.env.rx_loc, em.env.sc_xyz, 'model', ch_model, 'nrx', em.env.N_rx,\n",
    "                               'ntx', em.env.N_tx, 'nFFT', em.env.nFFT, 'df', em.env.df)\n",
    "\n",
    "        tx_num = em.env.get_txloc_ndx(tx_loc)\n",
    "        channel.generate_paths(ch_randval, tx_num)\n",
    "        h = channel.get_h()  # channel coefficient\n",
    "    \n",
    "        tx_bdir = em.env.BeamSet[tx_dir_ndx]\n",
    "        tx_beam = ula.var_steervec(em.env.N_tx, tx_bdir, 0)\n",
    "        rx_bdir =em.env.BeamSet[best_rxdir_ndx]                \n",
    "        wRF = ula.var_steervec(em.env.N_rx, rx_bdir , 0)\n",
    "        eff_ch = np.array(h[:,:,0]).dot(tx_beam)\n",
    "        rssi_val = np.sqrt(em.env.N_rx*em.env.N_tx)*np.array(np.conj(wRF.T).dot(eff_ch)) #+ (np.conj(wRF.T).dot(self.noise))[0]\n",
    "        Es = db2lin(em.env.P_tx)  # * (1e-3 / self.B)\n",
    "        SNR = Es * np.abs(rssi_val) ** 2 / (em.env.N0 * em.env.B)\n",
    "        dqn_rate = np.log2(1 + SNR)  # in Gbit/s (self.B / self.nFFT) *\n",
    "        \n",
    "        #compute exh rate\n",
    "        max_rate = 0.0\n",
    "        min_rate = 1e10\n",
    "        max_action_ndx = 0\n",
    "        min_action_ndx = 0\n",
    "        max_rssi_val = 0\n",
    "        min_rssi_val =0\n",
    "        for rbdir_ndx in range(em.env.action_space.n):\n",
    "            wRF = ula.var_steervec(em.env.N_rx, em.env.BeamSet[rbdir_ndx], 0)\n",
    "\n",
    "            rssi_val = np.sqrt(em.env.N_rx * em.env.N_tx) * np.array(np.conj(wRF.T).dot(eff_ch)) #+ (np.conj(wRF.T).dot(self.noise))[0]\n",
    "            Es = db2lin(em.env.P_tx)  # * (1e-3 / self.B)\n",
    "            SNR = Es * np.abs(rssi_val) ** 2 / (em.env.N0 * em.env.B)\n",
    "            rate = np.log2(1 + SNR)\n",
    "\n",
    "            if rate > max_rate:\n",
    "                max_rate = rate\n",
    "                max_action_ndx = rbdir_ndx\n",
    "                max_rssi_val = rssi_val\n",
    "\n",
    "            if rate < min_rate:\n",
    "                min_rate = rate\n",
    "                min_action_ndx = rbdir_ndx\n",
    "                min_rssi_val = rssi_val\n",
    "        exh_rate = max_rate\n",
    "        loc_errors.append(exh_rate-dqn_rate)\n",
    "        \n",
    "    return np.mean(loc_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Train the DQN agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dac811464e84834bd7eccee28865e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='training loop: ', max=6000.0, style=ProgressStyle(descrip"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [2, 1, 3, 0, 4, 15, 5, 14, 6, 13, 7, 12, 8, 11, 9, 10], prevep_bestaction: 2\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 1\n",
      "Episode 1,\tScore: 5.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 2, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 5.071712493896484\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [2, 1, 3, 0, 4, 15, 5, 14, 6, 13, 7, 12, 8, 11, 9, 10], prevep_bestaction: 2\n",
      "tx_loc:[[-300.  -400.    21.5]] not converged until episode: 2\n",
      "Episode 2,\tScore: 5.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 2, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 5.003763198852539\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [2, 1, 3, 0, 4, 15, 5, 14, 6, 13, 7, 12, 8, 11, 9, 10], prevep_bestaction: 2\n",
      "tx_loc:[[-200.  -200.    21.5]] not converged until episode: 3\n",
      "Episode 3,\tScore: 4.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 2, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 4.116530895233154\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [2, 1, 3, 0, 4, 15, 5, 14, 6, 13, 7, 12, 8, 11, 9, 10], prevep_bestaction: 2\n",
      "tx_loc:[[-500.  -100.    21.5]] not converged until episode: 4\n",
      "Episode 4,\tScore: 3.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 2, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 5.158302307128906\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [2, 1, 3, 0, 4, 15, 5, 14, 6, 13, 7, 12, 8, 11, 9, 10], prevep_bestaction: 2\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 5\n",
      "Episode 5,\tScore: 5.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 2, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 5.137587070465088\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [2, 1, 3, 0, 4, 15, 5, 14, 6, 13, 7, 12, 8, 11, 9, 10], prevep_bestaction: 2\n",
      "Episode 6,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 0, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 2.065474510192871\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [2, 1, 3, 0, 4, 15, 5, 14, 6, 13, 7, 12, 8, 11, 9, 10], prevep_bestaction: 2\n",
      "Episode 7,\tScore: 4.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 0, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 6.215855598449707\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [0, 15, 1, 14, 2, 13, 3, 12, 4, 11, 5, 10, 6, 9, 7, 8], prevep_bestaction: 0\n",
      "tx_loc:[[-300.  -500.    21.5]] not converged until episode: 8\n",
      "Episode 8,\tScore: 3.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 0, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 5.340137481689453\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [0, 15, 1, 14, 2, 13, 3, 12, 4, 11, 5, 10, 6, 9, 7, 8], prevep_bestaction: 0\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 9\n",
      "Episode 9,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 0, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.062329053878784\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [0, 15, 1, 14, 2, 13, 3, 12, 4, 11, 5, 10, 6, 9, 7, 8], prevep_bestaction: 0\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 10\n",
      "Episode 10,\tScore: 3.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 0, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 3.123403310775757\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [0, 15, 1, 14, 2, 13, 3, 12, 4, 11, 5, 10, 6, 9, 7, 8], prevep_bestaction: 0\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 11\n",
      "Episode 11,\tScore: 5.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 0, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 5.187873363494873\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [0, 15, 1, 14, 2, 13, 3, 12, 4, 11, 5, 10, 6, 9, 7, 8], prevep_bestaction: 0\n",
      "tx_loc:[[-500.  -100.    21.5]] not converged until episode: 12\n",
      "Episode 12,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 0, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 2.055586576461792\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [0, 15, 1, 14, 2, 13, 3, 12, 4, 11, 5, 10, 6, 9, 7, 8], prevep_bestaction: 0\n",
      "Episode 13,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 2, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.056305408477783\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [2, 1, 3, 0, 4, 15, 5, 14, 6, 13, 7, 12, 8, 11, 9, 10], prevep_bestaction: 2\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 14\n",
      "Episode 14,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 2, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.0402355194091797\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [2, 1, 3, 0, 4, 15, 5, 14, 6, 13, 7, 12, 8, 11, 9, 10], prevep_bestaction: 2\n",
      "tx_loc:[[-300.  -100.    21.5]] not converged until episode: 15\n",
      "Episode 15,\tScore: 5.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 2, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 5.102975845336914\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [2, 1, 3, 0, 4, 15, 5, 14, 6, 13, 7, 12, 8, 11, 9, 10], prevep_bestaction: 2\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 16\n",
      "Episode 16,\tScore: 4.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 2, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 6.14125919342041\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [2, 1, 3, 0, 4, 15, 5, 14, 6, 13, 7, 12, 8, 11, 9, 10], prevep_bestaction: 2\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 17\n",
      "Episode 17,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 2, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 1.87625253200531\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [2, 1, 3, 0, 4, 15, 5, 14, 6, 13, 7, 12, 8, 11, 9, 10], prevep_bestaction: 2\n",
      "Episode 18,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 0, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.0407238006591797\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [0, 15, 1, 14, 2, 13, 3, 12, 4, 11, 5, 10, 6, 9, 7, 8], prevep_bestaction: 0\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 19\n",
      "Episode 19,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 0, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.0319628715515137\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [2, 1, 3, 0, 4, 15, 5, 14, 6, 13, 7, 12, 8, 11, 9, 10], prevep_bestaction: 2\n",
      "tx_loc:[[-500.  -500.    21.5]] not converged until episode: 20\n",
      "Episode 20,\tScore: 4.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 2, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 4.058509349822998\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [0, 15, 1, 14, 2, 13, 3, 12, 4, 11, 5, 10, 6, 9, 7, 8], prevep_bestaction: 0\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 21\n",
      "Episode 21,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 0, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.0235190391540527\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [0, 15, 1, 14, 2, 13, 3, 12, 4, 11, 5, 10, 6, 9, 7, 8], prevep_bestaction: 0\n",
      "tx_loc:[[-400.  -300.    21.5]] not converged until episode: 22\n",
      "Episode 22,\tScore: 4.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 0, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 4.074275970458984\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [0, 15, 1, 14, 2, 13, 3, 12, 4, 11, 5, 10, 6, 9, 7, 8], prevep_bestaction: 0\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 23\n",
      "Episode 23,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 0, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.0183603763580322\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [0, 15, 1, 14, 2, 13, 3, 12, 4, 11, 5, 10, 6, 9, 7, 8], prevep_bestaction: 0\n",
      "Episode 24,\tScore: 5.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 2, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 7.004597187042236\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [2, 1, 3, 0, 4, 15, 5, 14, 6, 13, 7, 12, 8, 11, 9, 10], prevep_bestaction: 2\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 25\n",
      "Episode 25,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 2, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.0811543464660645\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [2, 1, 3, 0, 4, 15, 5, 14, 6, 13, 7, 12, 8, 11, 9, 10], prevep_bestaction: 2\n",
      "Episode 26,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.859494924545288\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 27,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.021031141281128\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 28,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.0124461650848389\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-300.  -300.    21.5]] not converged until episode: 29\n",
      "Episode 29,\tScore: 2.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.024282932281494\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 30,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 1.0126830339431763\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 31,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 1.0155788660049438\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -100.    21.5]] not converged until episode: 32\n",
      "Episode 32,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 3.0586495399475098\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 33\n",
      "Episode 33,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 10, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.043555498123169\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-300.  -200.    21.5]] not converged until episode: 34\n",
      "Episode 34,\tScore: 3.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 3.0872321128845215\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-500.  -400.    21.5]] not converged until episode: 35\n",
      "Episode 35,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 10, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 3.0904626846313477\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 36\n",
      "Episode 36,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 3.0726053714752197\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 37\n",
      "Episode 37,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 10, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.027681589126587\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 38,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 1.0202990770339966\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 39,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 1.0190119743347168\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-400.  -300.    21.5]] not converged until episode: 40\n",
      "Episode 40,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.0586016178131104\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -100.    21.5]] not converged until episode: 41\n",
      "Episode 41,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 2.053900957107544\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-400.  -300.    21.5]] not converged until episode: 42\n",
      "Episode 42,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.054311752319336\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 43,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 1.0175728797912598\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-500.  -500.    21.5]] not converged until episode: 44\n",
      "Episode 44,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 10, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 2.033576250076294\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-500.  -500.    21.5]] not converged until episode: 45\n",
      "Episode 45,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 10, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 2.028254985809326\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 46,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 1.0158544778823853\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 47\n",
      "Episode 47,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 10, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.0454490184783936\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 48,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.0132782459259033\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-400.  -300.    21.5]] not converged until episode: 49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 49,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.0358309745788574\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 50,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.009514331817627\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 51,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 2.035024642944336\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 52,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 1.0112080574035645\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-300.  -300.    21.5]] not converged until episode: 53\n",
      "Episode 53,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.014484405517578\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 54,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 1.0086872577667236\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 55,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 1.0089677572250366\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 56\n",
      "Episode 56,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 13, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.039961814880371\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 57\n",
      "Episode 57,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.029144763946533\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 58,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 1.0093494653701782\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 59\n",
      "Episode 59,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 13, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.091822624206543\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-300.  -300.    21.5]] not converged until episode: 60\n",
      "Episode 60,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.013491153717041\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 61\n",
      "Episode 61,\tScore: 2.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.0489425659179688\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 62,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.011992931365967\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -400.    21.5]] not converged until episode: 63\n",
      "Episode 63,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 2.028979778289795\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-100.  -200.    21.5]] not converged until episode: 64\n",
      "Episode 64,\tScore: 3.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 3.0410006046295166\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-100.  -500.    21.5]] not converged until episode: 65\n",
      "Episode 65,\tScore: 4.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 4.138487815856934\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 66\n",
      "Episode 66,\tScore: 3.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 3.0613467693328857\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -400.    21.5]] not converged until episode: 67\n",
      "Episode 67,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 2.0310685634613037\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 68\n",
      "Episode 68,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.036242961883545\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-400.  -300.    21.5]] not converged until episode: 69\n",
      "Episode 69,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.041022300720215\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -400.    21.5]] not converged until episode: 70\n",
      "Episode 70,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 2.0238921642303467\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -500.    21.5]] not converged until episode: 71\n",
      "Episode 71,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 10, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 2.130197763442993\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 72,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 1.0171644687652588\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 73,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 1.0241973400115967\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 74,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 10, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.032726764678955\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-300.  -300.    21.5]] not converged until episode: 75\n",
      "Episode 75,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.029892921447754\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 76\n",
      "Episode 76,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 10, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.0375943183898926\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-500.  -500.    21.5]] not converged until episode: 77\n",
      "Episode 77,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 10, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 2.0296308994293213\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -200.    21.5]] not converged until episode: 78\n",
      "Episode 78,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.0269775390625\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -100.    21.5]] not converged until episode: 79\n",
      "Episode 79,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.029777765274048\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 80,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 1.015008568763733\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-500.  -100.    21.5]] not converged until episode: 81\n",
      "Episode 81,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 2.058481216430664\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -100.    21.5]] not converged until episode: 82\n",
      "Episode 82,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.019242763519287\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 83\n",
      "Episode 83,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.0203347206115723\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 84\n",
      "Episode 84,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.1013736724853516\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-500.  -300.    21.5]] not converged until episode: 85\n",
      "Episode 85,\tScore: 2.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 2.0298752784729004\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-500.  -300.    21.5]] not converged until episode: 86\n",
      "Episode 86,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 2.0290255546569824\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 87,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 1.0129449367523193\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 88,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 1.0102325677871704\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 89,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.0300559997558594\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -400.    21.5]] not converged until episode: 90\n",
      "Episode 90,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 2.028156280517578\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 91\n",
      "Episode 91,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.027984380722046\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 92\n",
      "Episode 92,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.02180552482605\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 93\n",
      "Episode 93,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.020311117172241\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 94,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 12, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.0154566764831543\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 95,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 2.0383152961730957\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-300.  -100.    21.5]] not converged until episode: 96\n",
      "Episode 96,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.014509677886963\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 97\n",
      "Episode 97,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.0208120346069336\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 98\n",
      "Episode 98,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.023047924041748\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-400.  -500.    21.5]] not converged until episode: 99\n",
      "Episode 99,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.0, current_best action: 9, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 2.0246691703796387\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 1.012181282043457\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-200.  -100.    21.5]] not converged until episode: 101\n",
      "Episode 101,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 9, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.019946813583374\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 102,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 1.01304030418396\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-300.  -300.    21.5]] not converged until episode: 103\n",
      "Episode 103,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 9, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.018026113510132\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 104,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 1.0121772289276123\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 105,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 11, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 2.013394594192505\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 106,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 10, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.0139009952545166\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -100.    21.5]] not converged until episode: 107\n",
      "Episode 107,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 11, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.0155014991760254\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -100.    21.5]] not converged until episode: 108\n",
      "Episode 108,\tScore: 2.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 10, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.0139198303222656\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -100.    21.5]] not converged until episode: 109\n",
      "Episode 109,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 10, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.021845579147339\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 110,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 2.0123767852783203\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 111\n",
      "Episode 111,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 10, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.0977344512939453\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 112\n",
      "Episode 112,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 10, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.095872640609741\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-500.  -300.    21.5]] not converged until episode: 113\n",
      "Episode 113,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 11, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 2.0215272903442383\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -100.    21.5]] not converged until episode: 114\n",
      "Episode 114,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 11, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.0148603916168213\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 115,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 1.0098991394042969\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 116\n",
      "Episode 116,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5699999928474426, current_best action: 10, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.07733154296875\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-400.  -500.    21.5]] not converged until episode: 117\n",
      "Episode 117,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5699999928474426, current_best action: 11, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 2.01375412940979\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 118,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5699999928474426, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.0074193477630615\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -500.    21.5]] not converged until episode: 119\n",
      "Episode 119,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5699999928474426, current_best action: 10, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 2.068025588989258\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-300.  -200.    21.5]] not converged until episode: 120\n",
      "Episode 120,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 13, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 2.009927749633789\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-200.  -200.    21.5]] not converged until episode: 121\n",
      "Episode 121,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 13, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.010444164276123\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 122\n",
      "Episode 122,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.49000000953674316, current_best action: 13, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.009185552597046\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 123,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.49000000953674316, current_best action: 11, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.0080013275146484\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 124,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.0057854652404785\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 125,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4399999976158142, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 2.0065877437591553\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 126,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4399999976158142, current_best action: 12, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.0201900005340576\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-200.  -200.    21.5]] not converged until episode: 127\n",
      "Episode 127,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4399999976158142, current_best action: 12, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.0068793296813965\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 128,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4399999976158142, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 1.0059096813201904\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-300.  -100.    21.5]] not converged until episode: 129\n",
      "Episode 129,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 12, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.0090763568878174\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 130\n",
      "Episode 130,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 11, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.00651216506958\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-500.  -100.    21.5]] not converged until episode: 131\n",
      "Episode 131,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 12, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 2.0184736251831055\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 132,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 1.0057591199874878\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 133,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.0057458877563477\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 134,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 1.0060195922851562\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 135,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 1.006245732307434\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 136\n",
      "Episode 136,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3700000047683716, current_best action: 12, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.014331817626953\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-300.  -500.    21.5]] not converged until episode: 137\n",
      "Episode 137,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3700000047683716, current_best action: 9, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.010521411895752\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-300.  -100.    21.5]] not converged until episode: 138\n",
      "Episode 138,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.36000001430511475, current_best action: 12, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.0113444328308105\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 139,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.36000001430511475, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.0058858394622803\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 140,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3700000047683716, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 1.005752444267273\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 141,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.0059802532196045\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-400.  -500.    21.5]] not converged until episode: 142\n",
      "Episode 142,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 9, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 2.0116071701049805\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -500.    21.5]] not converged until episode: 143\n",
      "Episode 143,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3700000047683716, current_best action: 9, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 2.0495429039001465\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 144,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 1.006630539894104\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 145,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 1.0066317319869995\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-300.  -500.    21.5]] not converged until episode: 146\n",
      "Episode 146,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 9, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.009890079498291\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 147\n",
      "Episode 147,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 12, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.013495922088623\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 148,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.0068556070327759\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 149\n",
      "Episode 149,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.0146615505218506\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 150,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 1.0068323612213135\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 151,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 10, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.0122389793395996\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 152,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 1.0059592723846436\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -100.    21.5]] not converged until episode: 153\n",
      "Episode 153,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 9, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.013718605041504\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 154\n",
      "Episode 154,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 10, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.0123372077941895\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 155,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 1.0071659088134766\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 156,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 1.0073883533477783\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 157\n",
      "Episode 157,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 12, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.022216558456421\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 158,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.010194182395935\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 159,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 1.0083022117614746\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 160,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.0111342668533325\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 161,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 1.007771611213684\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -100.    21.5]] not converged until episode: 162\n",
      "Episode 162,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 10, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.013094902038574\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 163\n",
      "Episode 163,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 10, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.0658926963806152\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 164\n",
      "Episode 164,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.0188002586364746\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 165,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3499999940395355, current_best action: 12, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 1.0123454332351685\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 166\n",
      "Episode 166,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3199999928474426, current_best action: 12, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.032045602798462\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-300.  -100.    21.5]] not converged until episode: 167\n",
      "Episode 167,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3199999928474426, current_best action: 12, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.0214180946350098\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 168,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3199999928474426, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.0084428787231445\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 169\n",
      "Episode 169,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3199999928474426, current_best action: 11, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.0157203674316406\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 170,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 1.0098299980163574\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 171,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 10, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.0162177085876465\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 172,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3199999928474426, current_best action: 11, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.0108399391174316\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 173,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3100000023841858, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 2.011104106903076\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 174,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3199999928474426, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 1.0138263702392578\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 175\n",
      "Episode 175,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3199999928474426, current_best action: 12, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.0250284671783447\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 176,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.015203833580017\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 177,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 10, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 2.0230214595794678\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 178,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.0121123790740967\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-400.  -300.    21.5]] not converged until episode: 179\n",
      "Episode 179,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 10, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.0245625972747803\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 180,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 1.0122519731521606\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 181,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 1.0136804580688477\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-300.  -500.    21.5]] not converged until episode: 182\n",
      "Episode 182,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 9, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.0177111625671387\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-300.  -500.    21.5]] not converged until episode: 183\n",
      "Episode 183,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 9, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.0186257362365723\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 184\n",
      "Episode 184,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 9, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.0302181243896484\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 185,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3199999928474426, current_best action: 10, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.0329971313476562\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-500.  -400.    21.5]] not converged until episode: 186\n",
      "Episode 186,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3199999928474426, current_best action: 10, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 2.033777952194214\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-300.  -200.    21.5]] not converged until episode: 187\n",
      "Episode 187,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3100000023841858, current_best action: 10, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 2.0269713401794434\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 188\n",
      "Episode 188,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.30000001192092896, current_best action: 10, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.0321340560913086\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 189\n",
      "Episode 189,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.30000001192092896, current_best action: 10, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.0288493633270264\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-300.  -300.    21.5]] not converged until episode: 190\n",
      "Episode 190,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.30000001192092896, current_best action: 10, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.0225210189819336\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 191,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.30000001192092896, current_best action: 10, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.0158090591430664\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 192,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.30000001192092896, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.0137312412261963\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 193\n",
      "Episode 193,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.30000001192092896, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.0112252235412598\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -100.    21.5]] not converged until episode: 194\n",
      "Episode 194,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.30000001192092896, current_best action: 11, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.008023262023926\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 195\n",
      "Episode 195,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.30000001192092896, current_best action: 11, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.0158629417419434\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 196\n",
      "Episode 196,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.30000001192092896, current_best action: 11, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.020289897918701\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 197,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.30000001192092896, current_best action: 14, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 2.0098607540130615\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -500.    21.5]] not converged until episode: 198\n",
      "Episode 198,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.30000001192092896, current_best action: 11, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.019443988800049\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-200.  -100.    21.5]] not converged until episode: 199\n",
      "Episode 199,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.30000001192092896, current_best action: 14, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.0087621212005615\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 200,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.28999999165534973, current_best action: 12, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.0078134536743164\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 201,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.28999999165534973, current_best action: 13, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.008971691131592\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 202,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.2800000011920929, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.0087175369262695\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -500.    21.5]] not converged until episode: 203\n",
      "Episode 203,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.2800000011920929, current_best action: 9, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 2.0457425117492676\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -500.    21.5]] not converged until episode: 204\n",
      "Episode 204,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.27000001072883606, current_best action: 9, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 2.043657064437866\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 205\n",
      "Episode 205,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.27000001072883606, current_best action: 12, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.010566234588623\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 206\n",
      "Episode 206,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.27000001072883606, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.0090842247009277\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 207,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.27000001072883606, current_best action: 11, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 2.0167183876037598\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 208,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.25999999046325684, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 1.0065555572509766\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 209,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.27000001072883606, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 1.0065139532089233\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-400.  -500.    21.5]] not converged until episode: 210\n",
      "Episode 210,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.27000001072883606, current_best action: 11, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 2.0151777267456055\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -300.    21.5]] not converged until episode: 211\n",
      "Episode 211,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.27000001072883606, current_best action: 13, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.010760545730591\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 212,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.27000001072883606, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 2.00662899017334\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -400.    21.5]] not converged until episode: 213\n",
      "Episode 213,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.27000001072883606, current_best action: 11, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 2.0118746757507324\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 214\n",
      "Episode 214,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.27000001072883606, current_best action: 11, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.007807493209839\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 215,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.27000001072883606, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 1.006556510925293\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -100.    21.5]] not converged until episode: 216\n",
      "Episode 216,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.27000001072883606, current_best action: 13, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 2.0115041732788086\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 217,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.27000001072883606, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 2.0060319900512695\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -300.    21.5]] not converged until episode: 218\n",
      "Episode 218,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.27000001072883606, current_best action: 13, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.007479190826416\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 219,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.27000001072883606, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.0068538188934326\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 220,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.2800000011920929, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 1.0056648254394531\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -500.    21.5]] not converged until episode: 221\n",
      "Episode 221,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.2800000011920929, current_best action: 11, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.0066933631896973\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-400.  -500.    21.5]] not converged until episode: 222\n",
      "Episode 222,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.2800000011920929, current_best action: 11, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 2.0081350803375244\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 223,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.2800000011920929, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 2.0070810317993164\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 224,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.2800000011920929, current_best action: 9, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 2.030165910720825\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 225,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.28999999165534973, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.0062997341156006\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 226,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.28999999165534973, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.0065388679504395\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-300.  -100.    21.5]] not converged until episode: 227\n",
      "Episode 227,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.28999999165534973, current_best action: 12, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.0081305503845215\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-500.  -100.    21.5]] not converged until episode: 228\n",
      "Episode 228,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.2800000011920929, current_best action: 12, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 2.0095131397247314\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 229,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.28999999165534973, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.006425380706787\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-500.  -100.    21.5]] not converged until episode: 230\n",
      "Episode 230,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.28999999165534973, current_best action: 12, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 2.0082848072052\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 231,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.28999999165534973, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 2.008931875228882\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 232,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.28999999165534973, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 1.0064973831176758\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -100.    21.5]] not converged until episode: 233\n",
      "Episode 233,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.28999999165534973, current_best action: 9, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.010315418243408\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 234\n",
      "Episode 234,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.2800000011920929, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.011953353881836\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 235,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.2800000011920929, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 1.0066131353378296\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 236,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.28999999165534973, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 1.006721019744873\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -200.    21.5]] not converged until episode: 237\n",
      "Episode 237,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.28999999165534973, current_best action: 10, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.0073843002319336\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 238\n",
      "Episode 238,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.28999999165534973, current_best action: 10, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.0088095664978027\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 239\n",
      "Episode 239,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.2800000011920929, current_best action: 10, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.0119810104370117\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 240\n",
      "Episode 240,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.27000001072883606, current_best action: 12, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.0131053924560547\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 241,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.25999999046325684, current_best action: 13, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.0108747482299805\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 242,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.27000001072883606, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 1.005856990814209\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 243\n",
      "Episode 243,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.27000001072883606, current_best action: 12, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.0104990005493164\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 244,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.25999999046325684, current_best action: 9, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.008781671524048\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-400.  -300.    21.5]] not converged until episode: 245\n",
      "Episode 245,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.25, current_best action: 14, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.0093231201171875\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 246,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.25, current_best action: 11, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.008087635040283\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 247,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.25999999046325684, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 1.0062047243118286\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 248,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.25, current_best action: 11, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.009453773498535\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 249,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.25999999046325684, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 1.0070161819458008\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 250,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.25999999046325684, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 1.00655198097229\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-500.  -300.    21.5]] not converged until episode: 251\n",
      "Episode 251,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.25999999046325684, current_best action: 11, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 2.0151352882385254\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 252\n",
      "Episode 252,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.25, current_best action: 11, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.011657238006592\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 253,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.25999999046325684, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 1.010908842086792\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-500.  -300.    21.5]] not converged until episode: 254\n",
      "Episode 254,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.25999999046325684, current_best action: 11, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 2.019989013671875\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 255\n",
      "Episode 255,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.25, current_best action: 11, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.0243823528289795\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-500.  -300.    21.5]] not converged until episode: 256\n",
      "Episode 256,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.23999999463558197, current_best action: 11, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 2.020301103591919\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-500.  -300.    21.5]] not converged until episode: 257\n",
      "Episode 257,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.23999999463558197, current_best action: 11, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 2.0188653469085693\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 258,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.23999999463558197, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 1.007919192314148\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 259,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.23000000417232513, current_best action: 11, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.0396595001220703\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 260\n",
      "Episode 260,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.2199999988079071, current_best action: 11, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.012953758239746\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -500.    21.5]] not converged until episode: 261\n",
      "Episode 261,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.20999999344348907, current_best action: 11, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.0131428241729736\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -400.    21.5]] not converged until episode: 262\n",
      "Episode 262,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.20999999344348907, current_best action: 11, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 2.0114123821258545\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 263\n",
      "Episode 263,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.20999999344348907, current_best action: 9, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.0377535820007324\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 264,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.20999999344348907, current_best action: 9, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.012742280960083\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 265,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.20999999344348907, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.0115931034088135\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 266,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.2199999988079071, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 1.008806824684143\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 267,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.23000000417232513, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.0100898742675781\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 268,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.23000000417232513, current_best action: 10, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.012455940246582\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 269,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.23999999463558197, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.010981798171997\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -500.    21.5]] not converged until episode: 270\n",
      "Episode 270,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.23000000417232513, current_best action: 10, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 2.040112018585205\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 271,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.23999999463558197, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.0122989416122437\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-300.  -100.    21.5]] not converged until episode: 272\n",
      "Episode 272,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.23999999463558197, current_best action: 12, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.014583110809326\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-500.  -100.    21.5]] not converged until episode: 273\n",
      "Episode 273,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.23999999463558197, current_best action: 12, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 2.029895544052124\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 274\n",
      "Episode 274,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.23000000417232513, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.0186517238616943\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 275\n",
      "Episode 275,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.23000000417232513, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.018028736114502\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 276\n",
      "Episode 276,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.2199999988079071, current_best action: 10, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.0289628505706787\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 277\n",
      "Episode 277,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.2199999988079071, current_best action: 10, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.011265277862549\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 278,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.23000000417232513, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 1.0080456733703613\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-300.  -400.    21.5]] not converged until episode: 279\n",
      "Episode 279,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.23000000417232513, current_best action: 12, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 2.011068344116211\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 280\n",
      "Episode 280,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.2199999988079071, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.0155014991760254\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 281\n",
      "Episode 281,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.20999999344348907, current_best action: 12, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.021653175354004\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 282\n",
      "Episode 282,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.20999999344348907, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.022730827331543\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 283,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.20999999344348907, current_best action: 9, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 2.017429828643799\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 284,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.2199999988079071, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 1.0080487728118896\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-300.  -300.    21.5]] not converged until episode: 285\n",
      "Episode 285,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.2199999988079071, current_best action: 9, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.014977216720581\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 286,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.23000000417232513, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 1.0094197988510132\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 287,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.23999999463558197, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 1.0082178115844727\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 288,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.23999999463558197, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 2.013676166534424\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-500.  -400.    21.5]] not converged until episode: 289\n",
      "Episode 289,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.23999999463558197, current_best action: 11, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 2.026658535003662\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 290,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.25, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 1.008689522743225\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -100.    21.5]] not converged until episode: 291\n",
      "Episode 291,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.25, current_best action: 13, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 2.0186045169830322\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 292,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.25999999046325684, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 1.009702444076538\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 293,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.27000001072883606, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 1.0088388919830322\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-100.  -500.    21.5]] not converged until episode: 294\n",
      "Episode 294,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.27000001072883606, current_best action: 11, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 2.0178897380828857\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 295,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.27000001072883606, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.0096254348754883\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -500.    21.5]] not converged until episode: 296\n",
      "Episode 296,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.27000001072883606, current_best action: 11, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.033557891845703\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 297,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.27000001072883606, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.0131397247314453\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 298,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.27000001072883606, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 2.0143990516662598\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 299,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.2800000011920929, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 1.0098439455032349\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 300\n",
      "Episode 300,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.2800000011920929, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.019906997680664\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 301,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.28999999165534973, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 1.011183738708496\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 302,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.28999999165534973, current_best action: 11, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.0231003761291504\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 303\n",
      "Episode 303,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.28999999165534973, current_best action: 11, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.0168890953063965\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 304,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.30000001192092896, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 1.0161973237991333\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -500.    21.5]] not converged until episode: 305\n",
      "Episode 305,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.30000001192092896, current_best action: 11, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.028693675994873\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 306,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3100000023841858, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 1.0146974325180054\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 307,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3199999928474426, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 1.0171470642089844\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-100.  -100.    21.5]] not converged until episode: 308\n",
      "Episode 308,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3100000023841858, current_best action: 13, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.0235931873321533\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 309,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3100000023841858, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 1.0147615671157837\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 310\n",
      "Episode 310,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3100000023841858, current_best action: 8, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.025806427001953\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-200.  -200.    21.5]] not converged until episode: 311\n",
      "Episode 311,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3100000023841858, current_best action: 13, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.022202491760254\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 312,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3199999928474426, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 1.0189262628555298\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-300.  -200.    21.5]] not converged until episode: 313\n",
      "Episode 313,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3199999928474426, current_best action: 13, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 2.050395965576172\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -300.    21.5]] not converged until episode: 314\n",
      "Episode 314,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3199999928474426, current_best action: 13, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.046903610229492\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 315,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3199999928474426, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 1.0162452459335327\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 316,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 1.0147427320480347\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -500.    21.5]] not converged until episode: 317\n",
      "Episode 317,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 9, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 2.0244967937469482\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 318,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 1.0146092176437378\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 319,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3499999940395355, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 1.0159451961517334\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-100.  -200.    21.5]] not converged until episode: 320\n",
      "Episode 320,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 11, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.0155820846557617\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -100.    21.5]] not converged until episode: 321\n",
      "Episode 321,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 13, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 2.044384002685547\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 322\n",
      "Episode 322,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.039614677429199\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 323,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3499999940395355, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 1.0191729068756104\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -500.    21.5]] not converged until episode: 324\n",
      "Episode 324,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3499999940395355, current_best action: 9, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 2.03360915184021\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -400.    21.5]] not converged until episode: 325\n",
      "Episode 325,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 11, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 2.038811445236206\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 326,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3499999940395355, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 1.0223761796951294\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 327,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.36000001430511475, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 1.0200371742248535\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 328,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3700000047683716, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 1.025813341140747\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 329\n",
      "Episode 329,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.36000001430511475, current_best action: 11, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.0283570289611816\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 330\n",
      "Episode 330,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.36000001430511475, current_best action: 9, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.043076515197754\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 331,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3700000047683716, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 1.023677110671997\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-300.  -500.    21.5]] not converged until episode: 332\n",
      "Episode 332,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.36000001430511475, current_best action: 9, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.048673152923584\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 333,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3700000047683716, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 1.0366216897964478\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 334,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 1.0373096466064453\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 335,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 1.0316349267959595\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -500.    21.5]] not converged until episode: 336\n",
      "Episode 336,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3700000047683716, current_best action: 9, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 2.066605567932129\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 337,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 1.0305044651031494\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 338,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 1.0497331619262695\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 339,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 1.0340664386749268\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 340,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.043464422225952\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 341,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 1.043015480041504\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 342,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 9, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.09531307220459\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-400.  -300.    21.5]] not converged until episode: 343\n",
      "Episode 343,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 11, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.1337406635284424\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 344,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 1.0783604383468628\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-300.  -300.    21.5]] not converged until episode: 345\n",
      "Episode 345,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 9, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.072957754135132\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 346,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.07346248626709\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 347,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 11, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 2.094667434692383\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 348\n",
      "Episode 348,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 14, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.13746976852417\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 349,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 11, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 1.0537008047103882\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -400.    21.5]] not converged until episode: 350\n",
      "Episode 350,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 11, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 2.0748586654663086\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 351\n",
      "Episode 351,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 9, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.0833215713500977\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 352,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 14, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 2.091108798980713\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 353,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 1.0534594058990479\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 354,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 11, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 2.0706212520599365\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 355,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 10, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.0288710594177246\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 356,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 1.0378941297531128\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 357,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 1.0377668142318726\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 358,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 1.0412486791610718\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 359,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 8, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.0419814586639404\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -100.    21.5]] not converged until episode: 360\n",
      "Episode 360,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 10, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.0280206203460693\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 361,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.0325756072998047\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 362,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 1.0469392538070679\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 363,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4300000071525574, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 1.0498034954071045\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 364\n",
      "Episode 364,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4300000071525574, current_best action: 12, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.059116840362549\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 365,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4300000071525574, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 1.0302276611328125\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 366\n",
      "Episode 366,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 8, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.083113670349121\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-300.  -500.    21.5]] not converged until episode: 367\n",
      "Episode 367,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 8, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.0578746795654297\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 368\n",
      "Episode 368,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 14, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.0791711807250977\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 369\n",
      "Episode 369,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 8, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.059870719909668\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-300.  -300.    21.5]] not converged until episode: 370\n",
      "Episode 370,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 12, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.0615599155426025\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 371,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.0540990829467773\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-100.  -100.    21.5]] not converged until episode: 372\n",
      "Episode 372,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 13, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.0502538681030273\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-100.  -200.    21.5]] not converged until episode: 373\n",
      "Episode 373,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 12, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.035707950592041\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-300.  -300.    21.5]] not converged until episode: 374\n",
      "Episode 374,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 12, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.069150924682617\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-500.  -500.    21.5]] not converged until episode: 375\n",
      "Episode 375,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 12, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 2.090191602706909\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 376\n",
      "Episode 376,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 12, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.0606093406677246\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 377\n",
      "Episode 377,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 10, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.03896164894104\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 378,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 11, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.0396863222122192\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-100.  -200.    21.5]] not converged until episode: 379\n",
      "Episode 379,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 11, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.0252127647399902\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 380,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.0306408405303955\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 381,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 1.0356879234313965\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 382,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 1.0334749221801758\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-400.  -300.    21.5]] not converged until episode: 383\n",
      "Episode 383,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 11, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.0651307106018066\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 384,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 1.0304386615753174\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 385,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4300000071525574, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 1.0406626462936401\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-400.  -300.    21.5]] not converged until episode: 386\n",
      "Episode 386,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 11, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.075648784637451\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 387,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 1.0526862144470215\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 388,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4300000071525574, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 1.025418758392334\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 389\n",
      "Episode 389,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4300000071525574, current_best action: 11, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.055917263031006\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -200.    21.5]] not converged until episode: 390\n",
      "Episode 390,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 8, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.036344289779663\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 391\n",
      "Episode 391,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 11, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.054446220397949\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -100.    21.5]] not converged until episode: 392\n",
      "Episode 392,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 11, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.0477468967437744\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 393,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.0310604572296143\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 394\n",
      "Episode 394,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 8, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.0744550228118896\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 395,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 1.0358335971832275\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 396,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 1.054805874824524\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 397,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4300000071525574, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 1.0502784252166748\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-300.  -100.    21.5]] not converged until episode: 398\n",
      "Episode 398,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4300000071525574, current_best action: 14, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.0574750900268555\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 399\n",
      "Episode 399,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 11, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.0296897888183594\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-100.  -200.    21.5]] not converged until episode: 400\n",
      "Episode 400,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 13, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.0230677127838135\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -500.    21.5]] not converged until episode: 401\n",
      "Episode 401,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 9, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 2.0380537509918213\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 402,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 9, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.0424041748046875\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 403\n",
      "Episode 403,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 9, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.0458219051361084\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 404,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.0269880294799805\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 405,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 1.0306458473205566\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 406,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 9, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 2.045578956604004\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 407,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 1.0278702974319458\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 408,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 1.0251051187515259\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 409\n",
      "Episode 409,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 14, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.1340718269348145\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 410,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 1.0513626337051392\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 411,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 9, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 2.076791763305664\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-400.  -300.    21.5]] not converged until episode: 412\n",
      "Episode 412,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 9, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.059260606765747\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 413,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 13, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 2.0700230598449707\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-500.  -400.    21.5]] not converged until episode: 414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 414,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 9, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 2.056609630584717\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-300.  -500.    21.5]] not converged until episode: 415\n",
      "Episode 415,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 8, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.082041025161743\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 416,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 2.0308942794799805\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 417\n",
      "Episode 417,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 8, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.071437358856201\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -100.    21.5]] not converged until episode: 418\n",
      "Episode 418,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3700000047683716, current_best action: 9, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.0669872760772705\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-500.  -500.    21.5]] not converged until episode: 419\n",
      "Episode 419,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.36000001430511475, current_best action: 9, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 2.060209274291992\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 420\n",
      "Episode 420,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.36000001430511475, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.041064977645874\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 421,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.36000001430511475, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.0392627716064453\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-200.  -100.    21.5]] not converged until episode: 422\n",
      "Episode 422,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.36000001430511475, current_best action: 9, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.0398967266082764\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 423,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3499999940395355, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 2.030158519744873\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 424,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.36000001430511475, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 1.0316253900527954\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 425,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.36000001430511475, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.0297393798828125\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 426,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.36000001430511475, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 1.0303298234939575\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 427\n",
      "Episode 427,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3499999940395355, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.055943489074707\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 428,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3499999940395355, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 1.0237137079238892\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-200.  -100.    21.5]] not converged until episode: 429\n",
      "Episode 429,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3499999940395355, current_best action: 12, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.034067153930664\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 430,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.36000001430511475, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 1.0283950567245483\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 431,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.36000001430511475, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 1.038499116897583\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 432\n",
      "Episode 432,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.36000001430511475, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.0459985733032227\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 433\n",
      "Episode 433,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3499999940395355, current_best action: 10, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.036292314529419\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 434\n",
      "Episode 434,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.0645737648010254\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 435,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 1.039525032043457\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 436\n",
      "Episode 436,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.050534248352051\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 437,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 1.0466535091400146\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 438,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 1.041780710220337\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-100.  -100.    21.5]] not converged until episode: 439\n",
      "Episode 439,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 12, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.0438461303710938\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 440,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 1.0323398113250732\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 441\n",
      "Episode 441,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 10, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.0684735774993896\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-200.  -200.    21.5]] not converged until episode: 442\n",
      "Episode 442,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 12, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.056750774383545\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -200.    21.5]] not converged until episode: 443\n",
      "Episode 443,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 10, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.03950834274292\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 444\n",
      "Episode 444,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3199999928474426, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.060525417327881\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 445,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 1.0364153385162354\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -200.    21.5]] not converged until episode: 446\n",
      "Episode 446,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 10, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.0487821102142334\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 447,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.0576907396316528\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 448,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 12, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.0552096366882324\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 449,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 1.054163932800293\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 450,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3499999940395355, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 1.0323097705841064\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 451,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3499999940395355, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.048943519592285\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 452,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3499999940395355, current_best action: 10, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.0421245098114014\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 453,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3499999940395355, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 1.0499099493026733\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 454\n",
      "Episode 454,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3499999940395355, current_best action: 9, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.1095571517944336\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 455,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.36000001430511475, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 1.043702483177185\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 456,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.36000001430511475, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 1.0528541803359985\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 457\n",
      "Episode 457,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3499999940395355, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.1314289569854736\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -100.    21.5]] not converged until episode: 458\n",
      "Episode 458,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 9, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.0430710315704346\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 459,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3499999940395355, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 1.0786473751068115\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 460\n",
      "Episode 460,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3499999940395355, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.125189781188965\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 461,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3499999940395355, current_best action: 11, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 2.1106531620025635\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 462,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3499999940395355, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.0399432182312012\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-500.  -400.    21.5]] not converged until episode: 463\n",
      "Episode 463,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 11, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 2.118668556213379\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 464\n",
      "Episode 464,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 11, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.0954198837280273\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-400.  -500.    21.5]] not converged until episode: 465\n",
      "Episode 465,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 11, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 2.1493077278137207\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 466,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 2.0635323524475098\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 467,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 2.0716848373413086\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 468,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 2.052560329437256\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 469,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 1.0388067960739136\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 470,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3499999940395355, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 1.0495951175689697\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 471,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3499999940395355, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 1.034870982170105\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 472,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.36000001430511475, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 1.0277857780456543\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -500.    21.5]] not converged until episode: 473\n",
      "Episode 473,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.36000001430511475, current_best action: 12, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 2.0554447174072266\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 474\n",
      "Episode 474,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.36000001430511475, current_best action: 8, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.0498175621032715\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 475\n",
      "Episode 475,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.36000001430511475, current_best action: 12, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.0559451580047607\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 476\n",
      "Episode 476,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.36000001430511475, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.0544304847717285\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 477\n",
      "Episode 477,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.36000001430511475, current_best action: 8, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.0454015731811523\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 478,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.36000001430511475, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 1.0391961336135864\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 479,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3700000047683716, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 1.0216144323349\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 480,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 1.0602924823760986\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-300.  -300.    21.5]] not converged until episode: 481\n",
      "Episode 481,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3700000047683716, current_best action: 9, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.0407702922821045\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-300.  -100.    21.5]] not converged until episode: 482\n",
      "Episode 482,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.36000001430511475, current_best action: 14, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.0548267364501953\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-300.  -200.    21.5]] not converged until episode: 483\n",
      "Episode 483,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.36000001430511475, current_best action: 14, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 2.032161235809326\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 484\n",
      "Episode 484,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3499999940395355, current_best action: 14, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.0965561866760254\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -500.    21.5]] not converged until episode: 485\n",
      "Episode 485,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 9, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 2.0556440353393555\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 486\n",
      "Episode 486,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 9, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.051840305328369\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 487\n",
      "Episode 487,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 9, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.049009323120117\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 488\n",
      "Episode 488,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3199999928474426, current_best action: 12, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.067845344543457\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 489,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 1.0687698125839233\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 490,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 2.0486490726470947\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -500.    21.5]] not converged until episode: 491\n",
      "Episode 491,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 12, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 2.038102149963379\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 492,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 9, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.0311145782470703\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 493,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 1.0237479209899902\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-300.  -500.    21.5]] not converged until episode: 494\n",
      "Episode 494,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 9, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.0458133220672607\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 495,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 1.0244324207305908\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 496\n",
      "Episode 496,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 9, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.0381112098693848\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 497,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 1.0529319047927856\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 498,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 1.056161642074585\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 499\n",
      "Episode 499,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 9, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.0374457836151123\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 500\n",
      "Episode 500,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 8, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.044769763946533\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 501,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 10, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 2.047208070755005\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -100.    21.5]] not converged until episode: 502\n",
      "Episode 502,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 9, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.0342068672180176\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 503\n",
      "Episode 503,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 10, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.0387487411499023\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-200.  -200.    21.5]] not converged until episode: 504\n",
      "Episode 504,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 9, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.0283215045928955\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 505\n",
      "Episode 505,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 8, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.056960105895996\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 506\n",
      "Episode 506,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 8, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.052741765975952\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 507,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.0342800617218018\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -300.    21.5]] not converged until episode: 508\n",
      "Episode 508,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3199999928474426, current_best action: 13, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 2.0593409538269043\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 509,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.0359704494476318\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 510,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.33000001311302185, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 1.0571345090866089\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 511,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3400000035762787, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 1.0285674333572388\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 512,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3499999940395355, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.0312203168869019\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 513\n",
      "Episode 513,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3499999940395355, current_best action: 10, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.052035331726074\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-100.  -200.    21.5]] not converged until episode: 514\n",
      "Episode 514,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3499999940395355, current_best action: 11, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.04931378364563\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 515,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.36000001430511475, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 1.05305016040802\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 516,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3700000047683716, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 1.0597636699676514\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -500.    21.5]] not converged until episode: 517\n",
      "Episode 517,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3700000047683716, current_best action: 9, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 2.0794105529785156\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 518,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.069516897201538\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 519\n",
      "Episode 519,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 11, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.0567848682403564\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 520,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 1.107322335243225\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 521,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 12, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 1.0499294996261597\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 522,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 2.1179027557373047\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 523,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 1.1028972864151\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 524,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 1.0568997859954834\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 525\n",
      "Episode 525,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 11, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.0841357707977295\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 526\n",
      "Episode 526,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 11, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.0802974700927734\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 527\n",
      "Episode 527,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 10, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.089416265487671\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 528\n",
      "Episode 528,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 12, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.1285173892974854\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 529,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 1.1562321186065674\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -500.    21.5]] not converged until episode: 530\n",
      "Episode 530,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 9, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 2.0952420234680176\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 531\n",
      "Episode 531,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 12, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.101058006286621\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 532,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 1.0975236892700195\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 533\n",
      "Episode 533,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.2389230728149414\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 534,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 12, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 2.2722628116607666\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 535,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.0614047050476074\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 536,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.0930447578430176\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 537,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.0625699758529663\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 538\n",
      "Episode 538,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 8, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.1060190200805664\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 539,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 9, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.084412097930908\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 540\n",
      "Episode 540,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.1648459434509277\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 541,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 1.0825881958007812\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 542\n",
      "Episode 542,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 12, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.228963851928711\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 543,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.0738677978515625\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 544,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 1.0819170475006104\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -100.    21.5]] not converged until episode: 545\n",
      "Episode 545,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 11, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.1553311347961426\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 546,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 1.0786917209625244\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 547\n",
      "Episode 547,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 12, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.157205820083618\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 548,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 2.11230206489563\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 549,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 1.100547432899475\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-300.  -500.    21.5]] not converged until episode: 550\n",
      "Episode 550,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 9, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.1345443725585938\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -100.    21.5]] not converged until episode: 551\n",
      "Episode 551,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 11, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.110074520111084\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 552,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.0771244764328003\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-300.  -400.    21.5]] not converged until episode: 553\n",
      "Episode 553,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 9, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 2.1037917137145996\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-400.  -500.    21.5]] not converged until episode: 554\n",
      "Episode 554,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 11, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 2.1002755165100098\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 555,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 1.0807965993881226\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 556\n",
      "Episode 556,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 9, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.0922136306762695\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 557,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 1.0872975587844849\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 558,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 1.105184555053711\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 559,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 9, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 2.0695996284484863\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 560\n",
      "Episode 560,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.175558090209961\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 561\n",
      "Episode 561,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 9, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.06671404838562\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 562,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 1.1343199014663696\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 563,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 13, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 1.0506430864334106\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 564,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 1.1130415201187134\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -400.    21.5]] not converged until episode: 565\n",
      "Episode 565,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 13, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 2.147110939025879\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 566,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 10, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.0861659049987793\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 567\n",
      "Episode 567,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 10, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.077047348022461\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-100.  -100.    21.5]] not converged until episode: 568\n",
      "Episode 568,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 13, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.071606397628784\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 569\n",
      "Episode 569,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.2022368907928467\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 570,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 1.0785706043243408\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 571\n",
      "Episode 571,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 10, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.0687637329101562\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -300.    21.5]] not converged until episode: 572\n",
      "Episode 572,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 13, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.1310033798217773\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 573,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.0621585845947266\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 574,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 1.072083830833435\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 575,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 11, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.0763864517211914\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 576,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.0854771137237549\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 577,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 1.1325535774230957\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 578,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.0845444202423096\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 579,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.101944923400879\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -500.    21.5]] not converged until episode: 580\n",
      "Episode 580,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 9, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 2.1345207691192627\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-100.  -200.    21.5]] not converged until episode: 581\n",
      "Episode 581,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 11, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.123948097229004\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 582,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 1.102872371673584\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 583\n",
      "Episode 583,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 9, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.1361236572265625\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 584,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.116069793701172\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-100.  -200.    21.5]] not converged until episode: 585\n",
      "Episode 585,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 11, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.107607841491699\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-300.  -300.    21.5]] not converged until episode: 586\n",
      "Episode 586,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 10, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.11387300491333\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-500.  -500.    21.5]] not converged until episode: 587\n",
      "Episode 587,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 10, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 2.155928611755371\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 588\n",
      "Episode 588,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 11, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.1409237384796143\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -100.    21.5]] not converged until episode: 589\n",
      "Episode 589,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 11, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.1624884605407715\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 590\n",
      "Episode 590,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 8, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.3337481021881104\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-100.  -100.    21.5]] not converged until episode: 591\n",
      "Episode 591,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 8, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.0900309085845947\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 592\n",
      "Episode 592,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 10, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.0636837482452393\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 593\n",
      "Episode 593,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 8, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.208486557006836\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -200.    21.5]] not converged until episode: 594\n",
      "Episode 594,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 11, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 2.101600170135498\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-100.  -200.    21.5]] not converged until episode: 595\n",
      "Episode 595,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 8, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.086434841156006\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-300.  -500.    21.5]] not converged until episode: 596\n",
      "Episode 596,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 8, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.084717035293579\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-500.  -400.    21.5]] not converged until episode: 597\n",
      "Episode 597,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 14, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 2.046154260635376\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-500.  -300.    21.5]] not converged until episode: 598\n",
      "Episode 598,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3700000047683716, current_best action: 14, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 2.123972177505493\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 599,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 1.162580966949463\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-300.  -100.    21.5]] not converged until episode: 600\n",
      "Episode 600,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 14, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.127605438232422\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 601,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.047587513923645\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 602,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 1.0281249284744263\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 603,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 1.033294439315796\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-300.  -200.    21.5]] not converged until episode: 604\n",
      "Episode 604,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 14, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 2.0555551052093506\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 605,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.096125841140747\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -500.    21.5]] not converged until episode: 606\n",
      "Episode 606,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 9, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 2.0541415214538574\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-500.  -100.    21.5]] not converged until episode: 607\n",
      "Episode 607,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 12, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 2.1284382343292236\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 608\n",
      "Episode 608,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 12, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.1251907348632812\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 609\n",
      "Episode 609,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 9, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.0494375228881836\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 610,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 1.0500046014785767\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 611,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 1.0414127111434937\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 612,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 1.0366840362548828\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 613\n",
      "Episode 613,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.0365943908691406\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -500.    21.5]] not converged until episode: 614\n",
      "Episode 614,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 9, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 2.0401060581207275\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 615,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 1.0329136848449707\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 616,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.0928635597229004\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 617,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 1.0538058280944824\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 618,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.0319290161132812\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 619\n",
      "Episode 619,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.0455431938171387\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 620,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 1.0465339422225952\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 621,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3700000047683716, current_best action: 10, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.0327413082122803\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 622,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 1.029565691947937\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 623\n",
      "Episode 623,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3700000047683716, current_best action: 8, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.064396381378174\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 624,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.36000001430511475, current_best action: 8, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.0361435413360596\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 625,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3700000047683716, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 1.096081256866455\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 626\n",
      "Episode 626,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3700000047683716, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.1370880603790283\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 627\n",
      "Episode 627,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3700000047683716, current_best action: 8, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.047290563583374\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 628\n",
      "Episode 628,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3700000047683716, current_best action: 10, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.065457582473755\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 629,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3700000047683716, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 1.0399879217147827\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 630,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 1.1023600101470947\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 631,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.0699549913406372\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 632,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 1.1181951761245728\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 633,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 1.132623314857483\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-500.  -500.    21.5]] not converged until episode: 634\n",
      "Episode 634,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 12, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 2.1051747798919678\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 635\n",
      "Episode 635,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 9, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.0492396354675293\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 636,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 1.0407707691192627\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -300.    21.5]] not converged until episode: 637\n",
      "Episode 637,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 13, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 2.179858446121216\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -300.    21.5]] not converged until episode: 638\n",
      "Episode 638,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 13, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 2.1761300563812256\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 639,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 1.1315590143203735\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 640,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 1.0590142011642456\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 641,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 1.0618178844451904\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 642,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 1.1305068731307983\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 643,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.0428242683410645\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 644,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.0405986309051514\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 645,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 2.155137062072754\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -200.    21.5]] not converged until episode: 646\n",
      "Episode 646,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 10, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.0544233322143555\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -100.    21.5]] not converged until episode: 647\n",
      "Episode 647,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 13, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 2.3591554164886475\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 648,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 10, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 2.1107678413391113\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -100.    21.5]] not converged until episode: 649\n",
      "Episode 649,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 13, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 2.2981138229370117\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 650,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 1.1410613059997559\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 651,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 1.057456135749817\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 652,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 1.0821882486343384\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 653,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 1.0586609840393066\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-300.  -400.    21.5]] not converged until episode: 654\n",
      "Episode 654,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 9, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 2.106229782104492\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-400.  -500.    21.5]] not converged until episode: 655\n",
      "Episode 655,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 11, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 2.1275758743286133\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 656,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 1.0857232809066772\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 657\n",
      "Episode 657,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 12, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.185242176055908\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-300.  -500.    21.5]] not converged until episode: 658\n",
      "Episode 658,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 8, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.2096774578094482\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 659,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.1573212146759033\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -100.    21.5]] not converged until episode: 660\n",
      "Episode 660,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 11, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.143392324447632\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 661\n",
      "Episode 661,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 8, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.1895880699157715\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 662,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 1.0859785079956055\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-400.  -500.    21.5]] not converged until episode: 663\n",
      "Episode 663,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 11, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 2.12445330619812\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 664,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 1.1582918167114258\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 665,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.062859535217285\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 666,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 1.074696660041809\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 667,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 1.0887640714645386\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 668,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 14, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 1.0816209316253662\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 669,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 1.3282402753829956\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 670,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.1174468994140625\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 671,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 2.1160218715667725\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 672\n",
      "Episode 672,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.1291658878326416\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 673,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 1.1005223989486694\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-500.  -300.    21.5]] not converged until episode: 674\n",
      "Episode 674,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 14, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 2.287414073944092\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -200.    21.5]] not converged until episode: 675\n",
      "Episode 675,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 10, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.0869266986846924\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 676\n",
      "Episode 676,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 14, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.4612345695495605\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-300.  -100.    21.5]] not converged until episode: 677\n",
      "Episode 677,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 14, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.268542766571045\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 678,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 1.3499855995178223\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 679\n",
      "Episode 679,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.3799999952316284, current_best action: 10, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.166978359222412\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 680,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.38999998569488525, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.0722116231918335\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 681,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.1919533014297485\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 682,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 1.1957991123199463\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-300.  -300.    21.5]] not converged until episode: 683\n",
      "Episode 683,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4000000059604645, current_best action: 10, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.1419525146484375\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 684,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 1.1263285875320435\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -500.    21.5]] not converged until episode: 685\n",
      "Episode 685,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 9, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 2.355788469314575\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-300.  -400.    21.5]] not converged until episode: 686\n",
      "Episode 686,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 9, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 2.1917381286621094\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-400.  -300.    21.5]] not converged until episode: 687\n",
      "Episode 687,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4099999964237213, current_best action: 11, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.271510601043701\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 688,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.41999998688697815, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 1.112787127494812\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 689,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4300000071525574, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 1.2128617763519287\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 690\n",
      "Episode 690,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4300000071525574, current_best action: 11, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.21097993850708\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-500.  -400.    21.5]] not converged until episode: 691\n",
      "Episode 691,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4300000071525574, current_best action: 11, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 2.291896343231201\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 692,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4300000071525574, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.1848974227905273\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 693,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4300000071525574, current_best action: 14, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.0976850986480713\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -200.    21.5]] not converged until episode: 694\n",
      "Episode 694,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4300000071525574, current_best action: 11, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 2.1213059425354004\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 695,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4399999976158142, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 1.1047286987304688\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 696,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.44999998807907104, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 1.1315960884094238\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 697\n",
      "Episode 697,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.44999998807907104, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.1117324829101562\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-300.  -100.    21.5]] not converged until episode: 698\n",
      "Episode 698,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.44999998807907104, current_best action: 14, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.140684127807617\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 699,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.44999998807907104, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.1131665706634521\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 700,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.46000000834465027, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.1160809993743896\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 701,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.46000000834465027, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 1.0694749355316162\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 702,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.46000000834465027, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 1.264735221862793\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -200.    21.5]] not converged until episode: 703\n",
      "Episode 703,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.44999998807907104, current_best action: 10, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.062249183654785\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 704,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.46000000834465027, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 1.2121281623840332\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -500.    21.5]] not converged until episode: 705\n",
      "Episode 705,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.46000000834465027, current_best action: 9, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 2.1805009841918945\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 706,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4699999988079071, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.1087199449539185\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 707,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.47999998927116394, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 1.1313493251800537\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 708,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.49000000953674316, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 1.189144492149353\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 709,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 1.3722940683364868\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-200.  -200.    21.5]] not converged until episode: 710\n",
      "Episode 710,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.49000000953674316, current_best action: 12, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.100019931793213\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 711,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.49000000953674316, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 1.0953224897384644\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 712,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.47999998927116394, current_best action: 12, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.069608211517334\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 713,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.49000000953674316, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.1409838199615479\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 714,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.49000000953674316, current_best action: 9, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.1703014373779297\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 715,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.49000000953674316, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 1.1364459991455078\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -200.    21.5]] not converged until episode: 716\n",
      "Episode 716,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.49000000953674316, current_best action: 10, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.0842089653015137\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 717\n",
      "Episode 717,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.47999998927116394, current_best action: 10, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.177706718444824\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 718,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.47999998927116394, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.096342086791992\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 719,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.49000000953674316, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.162304401397705\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 720\n",
      "Episode 720,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.47999998927116394, current_best action: 12, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.338235855102539\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 721,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.49000000953674316, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 1.3738691806793213\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 722,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.49000000953674316, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.1769505739212036\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 723,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 1.1348488330841064\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 724\n",
      "Episode 724,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.2073333263397217\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 725,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.49000000953674316, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.176070213317871\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 726,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 1.0837302207946777\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 727,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 1.6053040027618408\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 728,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 1.1289464235305786\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-200.  -100.    21.5]] not converged until episode: 729\n",
      "Episode 729,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 14, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.101637601852417\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 730,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 1.1530065536499023\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 731,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 1.1575825214385986\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 732\n",
      "Episode 732,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5, current_best action: 9, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.219295024871826\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 733,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 1.0983654260635376\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 734,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 2.004513740539551\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-200.  -100.    21.5]] not converged until episode: 735\n",
      "Episode 735,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 14, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.159839630126953\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 736,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 1.1605545282363892\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 737,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.2922011613845825\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 738,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.2306947708129883\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 739,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 2.227294921875\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 740\n",
      "Episode 740,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 14, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.4280457496643066\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 741,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 10, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.2851195335388184\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 742,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 1.187857747077942\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -200.    21.5]] not converged until episode: 743\n",
      "Episode 743,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 10, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.1939306259155273\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 744\n",
      "Episode 744,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5, current_best action: 10, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.344658851623535\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 745,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 1.1519174575805664\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 746\n",
      "Episode 746,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 9, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.3131582736968994\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-300.  -500.    21.5]] not converged until episode: 747\n",
      "Episode 747,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 9, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.408388137817383\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 748,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.1614062786102295\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 749,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 1.517258644104004\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 750,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 10, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 1.1685144901275635\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 751,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 11, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.153494358062744\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 752,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 1.2215774059295654\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 753,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 1.1863734722137451\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-500.  -300.    21.5]] not converged until episode: 754\n",
      "Episode 754,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 14, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 2.6986355781555176\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-100.  -200.    21.5]] not converged until episode: 755\n",
      "Episode 755,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 11, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.18874454498291\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 756\n",
      "Episode 756,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5, current_best action: 11, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.206251621246338\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 757,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.7902326583862305\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 758,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.3844523429870605\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 759,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 1.3635387420654297\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -500.    21.5]] not converged until episode: 760\n",
      "Episode 760,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 9, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 2.3520803451538086\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 761,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 1.4425394535064697\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -200.    21.5]] not converged until episode: 762\n",
      "Episode 762,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 10, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.2430763244628906\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 763,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 1.195967197418213\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 764\n",
      "Episode 764,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.5097527503967285\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 765,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 1.5013223886489868\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-300.  -100.    21.5]] not converged until episode: 766\n",
      "Episode 766,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 12, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.3908193111419678\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -100.    21.5]] not converged until episode: 767\n",
      "Episode 767,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 10, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.1655378341674805\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-500.  -500.    21.5]] not converged until episode: 768\n",
      "Episode 768,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5, current_best action: 10, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 2.432246685028076\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 769,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.49000000953674316, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.160316228866577\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 770,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.49000000953674316, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 1.2842636108398438\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 771,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 1.1486406326293945\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 772,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.4867358207702637\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 773,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.132590651512146\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-300.  -300.    21.5]] not converged until episode: 774\n",
      "Episode 774,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 12, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.2737350463867188\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 775,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.158767580986023\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 776\n",
      "Episode 776,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 3.042194366455078\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 777,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 1.2454712390899658\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 778,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 1.2872765064239502\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 779,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5400000214576721, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 1.4694865942001343\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-400.  -500.    21.5]] not converged until episode: 780\n",
      "Episode 780,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 11, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 2.813302516937256\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 781,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 1.5517884492874146\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 782,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 1.351231336593628\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 783\n",
      "Episode 783,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 8, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.4061684608459473\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 784,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 1.4146149158477783\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 785,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5400000214576721, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.2790589332580566\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 786,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 1.7453560829162598\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-400.  -500.    21.5]] not converged until episode: 787\n",
      "Episode 787,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 11, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 2.9369821548461914\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 788,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5400000214576721, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.3753695487976074\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-500.  -400.    21.5]] not converged until episode: 789\n",
      "Episode 789,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 11, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 2.7793290615081787\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 790\n",
      "Episode 790,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 11, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.4755754470825195\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -400.    21.5]] not converged until episode: 791\n",
      "Episode 791,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 11, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 2.496408700942993\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 792,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5400000214576721, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 1.5359699726104736\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 793,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 1.2369221448898315\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 794\n",
      "Episode 794,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.638326644897461\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 795,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 1.4651179313659668\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-200.  -100.    21.5]] not converged until episode: 796\n",
      "Episode 796,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5400000214576721, current_best action: 12, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.210808753967285\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 797,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5400000214576721, current_best action: 8, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.1179394721984863\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 798,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.0706812143325806\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 799,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.0633955001831055\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 800\n",
      "Episode 800,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5400000214576721, current_best action: 8, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.1060314178466797\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-100.  -100.    21.5]] not converged until episode: 801\n",
      "Episode 801,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 12, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.06392765045166\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 802,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.0881242752075195\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-300.  -300.    21.5]] not converged until episode: 803\n",
      "Episode 803,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 12, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.224618434906006\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 804\n",
      "Episode 804,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 12, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.601907730102539\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 805,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.3861076831817627\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 806,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 1.075771689414978\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 807,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 1.3793858289718628\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 808,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 1.1806647777557373\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 809,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 1.4209293127059937\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 810,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.3748434782028198\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 811,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 1.0993037223815918\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 812,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.299541473388672\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 813,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 1.3477039337158203\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-200.  -200.    21.5]] not converged until episode: 814\n",
      "Episode 814,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 12, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.0963244438171387\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 815,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 1.1742541790008545\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 816\n",
      "Episode 816,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 8, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.580244541168213\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -200.    21.5]] not converged until episode: 817\n",
      "Episode 817,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 10, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.132798194885254\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 818,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5400000214576721, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 1.3580213785171509\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -200.    21.5]] not converged until episode: 819\n",
      "Episode 819,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 10, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.1075611114501953\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 820,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5400000214576721, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 1.2862393856048584\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 821,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5400000214576721, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.655367136001587\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-500.  -500.    21.5]] not converged until episode: 822\n",
      "Episode 822,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 12, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 2.782048225402832\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 823,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 1.189239740371704\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 824\n",
      "Episode 824,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 12, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.8237481117248535\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 825,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 10, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.3172717094421387\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 826,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 1.3710190057754517\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 827\n",
      "Episode 827,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.6121034622192383\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 828,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.6723124980926514\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 829,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 1.2577524185180664\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 830,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 1.7362241744995117\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 831,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 1.4853894710540771\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 832,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 2.127843141555786\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 833,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.307756781578064\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 834,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.5834217071533203\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 835\n",
      "Episode 835,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.4037437438964844\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 836,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 1.2378957271575928\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 837,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 10, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.207167863845825\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 838,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 2.218759059906006\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 839,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 1.4233874082565308\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 840,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 1.2691106796264648\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -100.    21.5]] not converged until episode: 841\n",
      "Episode 841,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 10, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.155791759490967\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 842,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 1.7683336734771729\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 843,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 1.401015043258667\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 844\n",
      "Episode 844,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 10, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.5579843521118164\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 845\n",
      "Episode 845,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 10, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.454620122909546\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 846,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.5805895328521729\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 847\n",
      "Episode 847,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 9, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.59891414642334\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 848\n",
      "Episode 848,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 9, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.558688163757324\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 849,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.3232421875\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 850,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 1.3305327892303467\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 851,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5400000214576721, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 1.3155113458633423\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 852,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5400000214576721, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 1.3115955591201782\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 853\n",
      "Episode 853,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 14, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 3.9152910709381104\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 854,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5400000214576721, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 1.163651943206787\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-500.  -300.    21.5]] not converged until episode: 855\n",
      "Episode 855,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5400000214576721, current_best action: 14, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 2.868180751800537\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 856,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.2706611156463623\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 857,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 1.2846760749816895\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 858,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 1.301123857498169\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 859,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 1.6243741512298584\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 860,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.684750556945801\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-300.  -400.    21.5]] not converged until episode: 861\n",
      "Episode 861,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 9, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 2.545090436935425\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-300.  -500.    21.5]] not converged until episode: 862\n",
      "Episode 862,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 9, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.6586501598358154\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 863,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 1.2751166820526123\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 864,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 1.2481204271316528\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 865\n",
      "Episode 865,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 10, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.47587513923645\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -200.    21.5]] not converged until episode: 866\n",
      "Episode 866,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 11, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 2.241832971572876\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-300.  -400.    21.5]] not converged until episode: 867\n",
      "Episode 867,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 9, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 2.4333596229553223\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 868\n",
      "Episode 868,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.3401966094970703\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -100.    21.5]] not converged until episode: 869\n",
      "Episode 869,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 9, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.203815221786499\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -100.    21.5]] not converged until episode: 870\n",
      "Episode 870,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5400000214576721, current_best action: 13, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 2.9976353645324707\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-100.  -200.    21.5]] not converged until episode: 871\n",
      "Episode 871,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 8, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.266832113265991\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-500.  -500.    21.5]] not converged until episode: 872\n",
      "Episode 872,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 10, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 2.389242172241211\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 873,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.403280258178711\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 874,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 1.794318437576294\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 875,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.490201711654663\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 876\n",
      "Episode 876,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 12, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.4350202083587646\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 877,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 1.2232964038848877\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 878,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 1.285247802734375\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-300.  -300.    21.5]] not converged until episode: 879\n",
      "Episode 879,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 12, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.3786826133728027\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 880,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 1.4476584196090698\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 881,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 13, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 2.7322559356689453\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 882,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.4985229969024658\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 883\n",
      "Episode 883,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 8, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.2186694145202637\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -400.    21.5]] not converged until episode: 884\n",
      "Episode 884,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 11, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 2.20353364944458\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 885\n",
      "Episode 885,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5, current_best action: 11, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.161129951477051\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 886,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 1.4567985534667969\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 887,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.1332950592041016\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 888,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.2520220279693604\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 889\n",
      "Episode 889,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 8, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.3688933849334717\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 890\n",
      "Episode 890,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 12, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.2595012187957764\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 891,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.2962671518325806\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 892\n",
      "Episode 892,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 8, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.365539073944092\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 893,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 1.2559621334075928\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 894,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 1.3708229064941406\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 895,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.5619513988494873\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 896,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 1.2230775356292725\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 897\n",
      "Episode 897,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 10, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.373610496520996\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 898,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.4460997581481934\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-500.  -500.    21.5]] not converged until episode: 899\n",
      "Episode 899,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 10, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 2.507932662963867\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 900,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.4339317083358765\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 901,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 1.4468199014663696\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-300.  -300.    21.5]] not converged until episode: 902\n",
      "Episode 902,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 12, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.1990420818328857\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 903,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5400000214576721, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 1.2264139652252197\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 904,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5400000214576721, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.207597255706787\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 905,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5400000214576721, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 1.350886344909668\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 906\n",
      "Episode 906,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.451314926147461\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 907,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 1.4886380434036255\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 908,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.432852864265442\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-300.  -200.    21.5]] not converged until episode: 909\n",
      "Episode 909,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 13, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 2.286911725997925\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 910,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.4958202838897705\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 911,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 1.434155821800232\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 912,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 1.3119782209396362\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 913,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.4287829399108887\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 914,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.6003918647766113\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 915,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 1.565643310546875\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 916\n",
      "Episode 916,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.608614444732666\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 917\n",
      "Episode 917,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.6035993099212646\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 918,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 1.5177052021026611\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 919,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.714717388153076\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 920\n",
      "Episode 920,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 10, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.3618245124816895\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 921,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 1.595526933670044\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 922,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.438626289367676\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 923,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 1.2287191152572632\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-500.  -400.    21.5]] not converged until episode: 924\n",
      "Episode 924,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 11, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 2.6925437450408936\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-300.  -100.    21.5]] not converged until episode: 925\n",
      "Episode 925,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 14, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.419665813446045\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 926\n",
      "Episode 926,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 9, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.4630799293518066\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-400.  -300.    21.5]] not converged until episode: 927\n",
      "Episode 927,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 11, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.3911283016204834\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 928,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 1.3702349662780762\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 929,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 2.087798833847046\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 930,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.3542134761810303\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 931,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 13, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.216808319091797\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 932,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 2.2543153762817383\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -300.    21.5]] not converged until episode: 933\n",
      "Episode 933,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.49000000953674316, current_best action: 13, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.2545180320739746\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-300.  -500.    21.5]] not converged until episode: 934\n",
      "Episode 934,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.49000000953674316, current_best action: 9, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.3733949661254883\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 935\n",
      "Episode 935,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.49000000953674316, current_best action: 14, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.548882484436035\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 936\n",
      "Episode 936,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.47999998927116394, current_best action: 9, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.181347370147705\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 937,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.49000000953674316, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 1.2814676761627197\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 938,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.49000000953674316, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 1.1860255002975464\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 939\n",
      "Episode 939,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.47999998927116394, current_best action: 14, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.968971014022827\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 940,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.47999998927116394, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.2663077116012573\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 941,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.49000000953674316, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 2.1218533515930176\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-200.  -200.    21.5]] not converged until episode: 942\n",
      "Episode 942,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.47999998927116394, current_best action: 13, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.1128482818603516\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -300.    21.5]] not converged until episode: 943\n",
      "Episode 943,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4699999988079071, current_best action: 13, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 2.540292501449585\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 944,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4699999988079071, current_best action: 10, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.0688095092773438\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-300.  -300.    21.5]] not converged until episode: 945\n",
      "Episode 945,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4699999988079071, current_best action: 10, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.1408729553222656\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-500.  -500.    21.5]] not converged until episode: 946\n",
      "Episode 946,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.46000000834465027, current_best action: 10, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 2.378635883331299\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 947,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4699999988079071, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 1.118340015411377\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 948,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.47999998927116394, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.3873932361602783\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -200.    21.5]] not converged until episode: 949\n",
      "Episode 949,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4699999988079071, current_best action: 10, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.0864107608795166\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 950,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.46000000834465027, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.2424659729003906\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 951,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.46000000834465027, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 1.148248553276062\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 952,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.46000000834465027, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 1.919852375984192\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 953,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4699999988079071, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 1.2152639627456665\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 954,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4699999988079071, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.5913054943084717\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 955,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.47999998927116394, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 1.6433050632476807\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 956,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.47999998927116394, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.305320382118225\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-300.  -300.    21.5]] not converged until episode: 957\n",
      "Episode 957,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4699999988079071, current_best action: 12, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.4087471961975098\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 958,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4699999988079071, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 1.5091943740844727\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 959,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.46000000834465027, current_best action: 12, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 3.2040581703186035\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 960,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4699999988079071, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 1.957477331161499\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 961,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.47999998927116394, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 1.6643239259719849\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-200.  -100.    21.5]] not converged until episode: 962\n",
      "Episode 962,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.47999998927116394, current_best action: 12, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.363779306411743\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-200.  -100.    21.5]] not converged until episode: 963\n",
      "Episode 963,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4699999988079071, current_best action: 12, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.346987247467041\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 964,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.4699999988079071, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.854224443435669\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 965\n",
      "Episode 965,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4699999988079071, current_best action: 8, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.5319294929504395\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 966\n",
      "Episode 966,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.4699999988079071, current_best action: 12, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 3.3674161434173584\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 967,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.47999998927116394, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.555192470550537\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 968,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.49000000953674316, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.5758558511734009\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 969\n",
      "Episode 969,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.49000000953674316, current_best action: 8, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.557133197784424\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 970,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.49000000953674316, current_best action: 12, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 2.618177652359009\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 971,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 2.038740634918213\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 972,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 1.616443157196045\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 973,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.1296632289886475\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -100.    21.5]] not converged until episode: 974\n",
      "Episode 974,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5, current_best action: 13, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 3.4121201038360596\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 975,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 1.6685402393341064\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-500.  -500.    21.5]] not converged until episode: 976\n",
      "Episode 976,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5, current_best action: 12, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 3.066652297973633\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 977,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 1.3899681568145752\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 978,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.155316948890686\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 979,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 1.7217609882354736\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 980,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5099999904632568, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.1701465845108032\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 981,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 1.6354539394378662\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 982,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 1.8785465955734253\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 983\n",
      "Episode 983,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5199999809265137, current_best action: 10, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.4531407356262207\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 984,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5299999713897705, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.179011344909668\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 985,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5400000214576721, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 1.3007361888885498\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 986,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5400000214576721, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 1.7189862728118896\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 987,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.813437581062317\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-300.  -200.    21.5]] not converged until episode: 988\n",
      "Episode 988,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5400000214576721, current_best action: 13, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 2.6844704151153564\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -400.    21.5]] not converged until episode: 989\n",
      "Episode 989,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5400000214576721, current_best action: 11, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 2.6408066749572754\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 990,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 1.6105952262878418\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 991,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 1.6881985664367676\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 992,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 1.7482986450195312\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 993,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 1.4260445833206177\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 994,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 1.5062506198883057\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -200.    21.5]] not converged until episode: 995\n",
      "Episode 995,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 10, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.4479618072509766\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 996,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 1.7947531938552856\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 997\n",
      "Episode 997,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 12, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 3.2355737686157227\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 998,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 1.7822041511535645\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 999\n",
      "Episode 999,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 10, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 3.0707833766937256\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1000,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 1.9689842462539673\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-200.  -100.    21.5]] not converged until episode: 1001\n",
      "Episode 1001,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 12, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.3970344066619873\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1002,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 1.5906713008880615\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 1003\n",
      "Episode 1003,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 3.0461068153381348\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 1004\n",
      "Episode 1004,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 12, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 3.2407724857330322\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 1005\n",
      "Episode 1005,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5400000214576721, current_best action: 11, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.4998061656951904\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1006,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 1.6514326333999634\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1007,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 1.7958984375\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1008,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 1.24562406539917\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1009,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 2.43906831741333\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1010,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.0969865322113037\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1011,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 1.5099085569381714\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-300.  -500.    21.5]] not converged until episode: 1012\n",
      "Episode 1012,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 9, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.680851936340332\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1013,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.1526278257369995\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1014,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.1504043340682983\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1015,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.6119415760040283\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1016,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 1.766710877418518\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -500.    21.5]] not converged until episode: 1017\n",
      "Episode 1017,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 9, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 2.752472400665283\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1018,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 1.329491138458252\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1019,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5699999928474426, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 1.641740083694458\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1020,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5799999833106995, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 1.2289707660675049\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1021,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5699999928474426, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.2080140113830566\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1022,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5799999833106995, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 1.5106287002563477\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-300.  -100.    21.5]] not converged until episode: 1023\n",
      "Episode 1023,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5699999928474426, current_best action: 14, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 3.3081727027893066\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1024,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5799999833106995, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 1.2998689413070679\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1025,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5799999833106995, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.7608842849731445\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1026,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5899999737739563, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 1.3631694316864014\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1027,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6000000238418579, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 1.7789289951324463\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-400.  -300.    21.5]] not converged until episode: 1028\n",
      "Episode 1028,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5899999737739563, current_best action: 11, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.936755657196045\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1029,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5899999737739563, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 1.3341716527938843\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1030,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5899999737739563, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 1.5191706418991089\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 1031\n",
      "Episode 1031,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5899999737739563, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.7172579765319824\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1032,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6000000238418579, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 1.5231655836105347\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 1033\n",
      "Episode 1033,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6000000238418579, current_best action: 10, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.6326651573181152\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1034,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 1.8624529838562012\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1035,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 1.8964605331420898\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1036,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 1.7046432495117188\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 1037\n",
      "Episode 1037,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 12, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 3.2715179920196533\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1038,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 2.318305492401123\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 1039\n",
      "Episode 1039,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 12, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 3.0981297492980957\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -100.    21.5]] not converged until episode: 1040\n",
      "Episode 1040,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 11, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.695629596710205\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1041,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.006789445877075\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-400.  -500.    21.5]] not converged until episode: 1042\n",
      "Episode 1042,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 11, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 3.3848276138305664\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 1043\n",
      "Episode 1043,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 10, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.6027064323425293\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1044,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 2.667858600616455\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1045,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 2.08980131149292\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1046,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 2.7976744174957275\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1047,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 1.8316876888275146\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1048,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 1.783272385597229\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1049,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 1.2796505689620972\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-400.  -300.    21.5]] not converged until episode: 1050\n",
      "Episode 1050,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 11, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.448072910308838\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1051,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 1.574945330619812\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1052,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 2.500947952270508\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1053,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 2.598944664001465\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1054,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 1.7589216232299805\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1055,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 1.3298166990280151\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -300.    21.5]] not converged until episode: 1056\n",
      "Episode 1056,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 13, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 3.052962303161621\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 1057\n",
      "Episode 1057,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 9, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.280162811279297\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1058,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 2.666738986968994\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1059,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 1.3169440031051636\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1060,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.331862211227417\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1061,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 1.45250403881073\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 1062\n",
      "Episode 1062,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 8, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.3751821517944336\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 1063\n",
      "Episode 1063,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 8, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 3.14959454536438\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1064,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 1.3190202713012695\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 1065\n",
      "Episode 1065,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 14, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.9791646003723145\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-300.  -200.    21.5]] not converged until episode: 1066\n",
      "Episode 1066,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 13, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 2.597759246826172\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1067,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 1.4161219596862793\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1068,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 1.1759319305419922\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1069,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6399999856948853, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 3.347811460494995\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1070,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 1.2052381038665771\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1071,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 1.423689842224121\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1072,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 3.1850357055664062\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1073,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.1881405115127563\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1074,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 3.4026026725769043\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1075,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 1.5789554119110107\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1076,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 1.339299201965332\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 1077\n",
      "Episode 1077,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 8, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 3.021815299987793\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1078,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 1.6966242790222168\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1079,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 3.8863959312438965\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1080,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 1.925798773765564\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1081,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.4097938537597656\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-500.  -400.    21.5]] not converged until episode: 1082\n",
      "Episode 1082,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 11, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 2.9559783935546875\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1083,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 2.8944525718688965\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1084,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 1.9960508346557617\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1085,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 2.172517776489258\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1086,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.236504554748535\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1087,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.315786838531494\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-300.  -200.    21.5]] not converged until episode: 1088\n",
      "Episode 1088,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 13, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 2.7986855506896973\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1089,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.5967376232147217\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1090,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.6681491136550903\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1091,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.903874397277832\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 1092\n",
      "Episode 1092,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6399999856948853, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 3.5435714721679688\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1093,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6399999856948853, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.8496999740600586\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-500.  -400.    21.5]] not converged until episode: 1094\n",
      "Episode 1094,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 11, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 3.4361510276794434\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 1095\n",
      "Episode 1095,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 8, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 4.501564979553223\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1096,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 1.8223637342453003\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 1097\n",
      "Episode 1097,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 3.491842269897461\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1098,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.1302947998046875\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -100.    21.5]] not converged until episode: 1099\n",
      "Episode 1099,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 13, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 3.711143732070923\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1100,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.778761863708496\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-200.  -100.    21.5]] not converged until episode: 1101\n",
      "Episode 1101,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 12, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 3.0100746154785156\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-300.  -300.    21.5]] not converged until episode: 1102\n",
      "Episode 1102,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 12, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 3.2931089401245117\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1103,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 2.3444011211395264\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-200.  -100.    21.5]] not converged until episode: 1104\n",
      "Episode 1104,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 12, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.922985792160034\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 1105\n",
      "Episode 1105,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 10, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.7858548164367676\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1106,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 1.7768797874450684\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1107,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 1.7966068983078003\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1108,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 1.9147398471832275\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1109,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 3.436779499053955\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1110,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 3.4189696311950684\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1111,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 3.017491340637207\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1112,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.219346761703491\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -400.    21.5]] not converged until episode: 1113\n",
      "Episode 1113,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 11, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 3.089085340499878\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -200.    21.5]] not converged until episode: 1114\n",
      "Episode 1114,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6000000238418579, current_best action: 11, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 3.1884326934814453\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1115,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6000000238418579, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.769901752471924\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-500.  -400.    21.5]] not converged until episode: 1116\n",
      "Episode 1116,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5899999737739563, current_best action: 11, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 3.515704870223999\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1117,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6000000238418579, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 1.7793307304382324\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 1118\n",
      "Episode 1118,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5899999737739563, current_best action: 14, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 3.5439860820770264\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1119,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5899999737739563, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.068776845932007\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-300.  -500.    21.5]] not converged until episode: 1120\n",
      "Episode 1120,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5799999833106995, current_best action: 9, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 3.0529708862304688\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1121,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5899999737739563, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 1.8206408023834229\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1122,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5899999737739563, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 3.4800684452056885\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1123,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6000000238418579, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.484163522720337\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1124,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6000000238418579, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.890474796295166\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1125,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 1.9740409851074219\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1126,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 1.890929102897644\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 1127\n",
      "Episode 1127,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6000000238418579, current_best action: 14, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 3.3459866046905518\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1128,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.4900434017181396\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1129,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 1.7633421421051025\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 1130\n",
      "Episode 1130,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6000000238418579, current_best action: 9, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 3.2872426509857178\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1131,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 1.7482874393463135\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -200.    21.5]] not converged until episode: 1132\n",
      "Episode 1132,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6000000238418579, current_best action: 11, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 2.5703177452087402\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-300.  -300.    21.5]] not converged until episode: 1133\n",
      "Episode 1133,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6000000238418579, current_best action: 10, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.6733968257904053\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1134,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6000000238418579, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.059687614440918\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1135,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6000000238418579, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.123652935028076\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1136,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6000000238418579, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.47346830368042\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1137,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6000000238418579, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.4291138648986816\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1138,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6000000238418579, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 1.776248812675476\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1139,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 2.673616647720337\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1140,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.250434160232544\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1141,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.649479627609253\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1142,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 1.6382226943969727\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1143,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6399999856948853, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 3.2306485176086426\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1144,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.516734004020691\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1145,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 1.9542423486709595\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1146,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.822152853012085\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-300.  -200.    21.5]] not converged until episode: 1147\n",
      "Episode 1147,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6399999856948853, current_best action: 13, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 2.9812417030334473\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1148,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 2.746227502822876\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1149,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 3.848982334136963\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-300.  -400.    21.5]] not converged until episode: 1150\n",
      "Episode 1150,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 9, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 2.892517328262329\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -100.    21.5]] not converged until episode: 1151\n",
      "Episode 1151,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 11, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.5904667377471924\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1152,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 1.9227350950241089\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1153,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.188960552215576\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -100.    21.5]] not converged until episode: 1154\n",
      "Episode 1154,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 13, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 4.610381126403809\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1155,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 1.7831037044525146\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1156,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 1.6892070770263672\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1157,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 1.5062024593353271\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 1158\n",
      "Episode 1158,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 8, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 4.591485023498535\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1159,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 3.544151544570923\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1160,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 13, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.4232468605041504\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1161,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 13, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 1.4446574449539185\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1162,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.4770379066467285\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1163,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 11, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.594959259033203\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1164,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.3748345375061035\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1165,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 3.8161261081695557\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-200.  -200.    21.5]] not converged until episode: 1166\n",
      "Episode 1166,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 13, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.999696731567383\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1167,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 2.3510122299194336\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1168,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 1.9358959197998047\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-100.  -200.    21.5]] not converged until episode: 1169\n",
      "Episode 1169,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 11, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 3.3800549507141113\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-300.  -200.    21.5]] not converged until episode: 1170\n",
      "Episode 1170,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6000000238418579, current_best action: 13, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 3.402526378631592\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 1171\n",
      "Episode 1171,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5899999737739563, current_best action: 9, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 3.6302907466888428\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1172,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5899999737739563, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.8298872709274292\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 1173\n",
      "Episode 1173,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5799999833106995, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 4.286592960357666\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 1174\n",
      "Episode 1174,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5699999928474426, current_best action: 9, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 3.4644594192504883\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1175,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5699999928474426, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.042537212371826\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -100.    21.5]] not converged until episode: 1176\n",
      "Episode 1176,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 11, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.813065767288208\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 1177\n",
      "Episode 1177,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 9, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.6773223876953125\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1178,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.223543167114258\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 1179\n",
      "Episode 1179,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 8, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 3.819014549255371\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1180,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 1.855207920074463\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 1181\n",
      "Episode 1181,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5400000214576721, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 3.386197566986084\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1182,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 2.4526526927948\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1183,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.145843505859375\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1184,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 1.7374541759490967\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1185,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 2.676564931869507\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1186,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 2.5864803791046143\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1187,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.604120135307312\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1188,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5699999928474426, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.0104923248291016\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -400.    21.5]] not converged until episode: 1189\n",
      "Episode 1189,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 11, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 3.093656539916992\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -400.    21.5]] not converged until episode: 1190\n",
      "Episode 1190,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 11, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 3.011247158050537\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1191,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 1.7662891149520874\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 1192\n",
      "Episode 1192,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 9, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 3.176405906677246\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 1193\n",
      "Episode 1193,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 3.1167104244232178\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 1194\n",
      "Episode 1194,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 12, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 3.4538981914520264\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-500.  -500.    21.5]] not converged until episode: 1195\n",
      "Episode 1195,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 12, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 3.178112030029297\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1196,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.550000011920929, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 1.7537506818771362\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1197,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.171722173690796\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1198,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5600000023841858, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.0413119792938232\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1199,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5699999928474426, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.274066925048828\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1200,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5699999928474426, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.7516231536865234\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 1201\n",
      "Episode 1201,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5699999928474426, current_best action: 14, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 3.155540943145752\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1202,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5799999833106995, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.847097635269165\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 1203\n",
      "Episode 1203,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5699999928474426, current_best action: 8, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 3.917543888092041\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1204,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5799999833106995, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.2413933277130127\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-500.  -500.    21.5]] not converged until episode: 1205\n",
      "Episode 1205,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5799999833106995, current_best action: 10, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 3.019127368927002\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-300.  -500.    21.5]] not converged until episode: 1206\n",
      "Episode 1206,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.5699999928474426, current_best action: 9, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 3.3927576541900635\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1207,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5699999928474426, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 1.6275832653045654\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1208,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5699999928474426, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 1.8655116558074951\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1209,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5799999833106995, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.69124698638916\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1210,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5799999833106995, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.2344563007354736\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1211,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5899999737739563, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.8969390392303467\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1212,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.5899999737739563, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.2030739784240723\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1213,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6000000238418579, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.2884117364883423\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1214,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 1.763097882270813\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-300.  -100.    21.5]] not converged until episode: 1215\n",
      "Episode 1215,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 14, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 3.158935070037842\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1216,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 3.057583808898926\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1217,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 1.7891806364059448\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 1218\n",
      "Episode 1218,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 10, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.5482864379882812\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1219,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6000000238418579, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 2.7268478870391846\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1220,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 1.94289231300354\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1221,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 1.4949407577514648\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1222,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 1.8195080757141113\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1223,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.3106911182403564\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1224,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 1.6254634857177734\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1225,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 3.9890990257263184\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1226,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6100000143051147, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 1.633315086364746\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1227,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 1.8895750045776367\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1228,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 1.6716388463974\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1229,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6200000047683716, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.6612039804458618\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1230,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 1.6066147089004517\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1231,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 2.2440414428710938\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1232,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6399999856948853, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 1.7791354656219482\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1233,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.308426856994629\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -100.    21.5]] not converged until episode: 1234\n",
      "Episode 1234,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6399999856948853, current_best action: 13, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 4.519683837890625\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1235,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6399999856948853, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.506887435913086\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-400.  -500.    21.5]] not converged until episode: 1236\n",
      "Episode 1236,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 11, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 3.439852714538574\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1237,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6399999856948853, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 1.9668978452682495\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1238,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6399999856948853, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.191345691680908\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1239,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6399999856948853, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 2.428337574005127\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 1240\n",
      "Episode 1240,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 3.2686543464660645\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1241,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.0728776454925537\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1242,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 1.6406099796295166\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1243,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.59709095954895\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1244,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 1.605756402015686\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1245,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.568310499191284\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1246,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6399999856948853, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 4.879621505737305\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1247,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.049532890319824\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -300.    21.5]] not converged until episode: 1248\n",
      "Episode 1248,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 13, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 3.5449113845825195\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1249,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 5.592263221740723\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1250,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 3.074009418487549\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1251,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 3.070132255554199\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-500.  -400.    21.5]] not converged until episode: 1252\n",
      "Episode 1252,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 11, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 3.864304542541504\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1253,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 3.1886987686157227\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1254,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 3.1188254356384277\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1255,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 4.424745559692383\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1256,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.106271743774414\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -400.    21.5]] not converged until episode: 1257\n",
      "Episode 1257,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6399999856948853, current_best action: 11, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 3.1448824405670166\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1258,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 1.836743950843811\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 1259\n",
      "Episode 1259,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 11, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.809922695159912\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1260,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 3.448622226715088\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1261,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 3.000286340713501\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1262,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 1.6437486410140991\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 1263\n",
      "Episode 1263,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 8, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 4.725153923034668\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-500.  -500.    21.5]] not converged until episode: 1264\n",
      "Episode 1264,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6399999856948853, current_best action: 12, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 3.9319281578063965\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1265,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.199960708618164\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1266,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 1.4861195087432861\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1267,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.316768169403076\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1268,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.8700926303863525\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1269,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 2.1273436546325684\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1270,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.6133337020874023\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1271,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6899999976158142, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 2.868072509765625\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1272,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6899999976158142, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.2446820735931396\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1273,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 2.794919729232788\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1274,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 2.8302669525146484\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1275,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 2.953606605529785\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-500.  -500.    21.5]] not converged until episode: 1276\n",
      "Episode 1276,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 10, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 4.266739845275879\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1277,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 14, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 3.313882827758789\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1278,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.5763754844665527\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 1279\n",
      "Episode 1279,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 12, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.8417153358459473\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1280,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 3.0878686904907227\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1281,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 3.2511773109436035\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1282,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 2.54512357711792\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1283,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 4.22213077545166\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1284,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6899999976158142, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 3.7064008712768555\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1285,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6899999976158142, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 3.5969462394714355\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -500.    21.5]] not converged until episode: 1286\n",
      "Episode 1286,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 9, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 5.269541263580322\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1287,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 10, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 1.9157848358154297\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1288,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 3.3867993354797363\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1289,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6899999976158142, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 4.989411354064941\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1290,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.9181294441223145\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1291,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6899999976158142, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 3.926368236541748\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1292,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 2.486265182495117\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1293,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 3.142159938812256\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1294,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 2.9348440170288086\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1295,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.7112207412719727\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 1296\n",
      "Episode 1296,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 8, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 3.686288833618164\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1297,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6899999976158142, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.830044746398926\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1298,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6899999976158142, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 1.7744567394256592\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1299,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6899999976158142, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.1639013290405273\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1300,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6899999976158142, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 2.715463876724243\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1301,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 1.7843109369277954\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-300.  -200.    21.5]] not converged until episode: 1302\n",
      "Episode 1302,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6899999976158142, current_best action: 13, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 2.794426441192627\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1303,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 2.862600326538086\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1304,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.0592360496520996\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 1305\n",
      "Episode 1305,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 14, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 5.3576507568359375\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1306,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.0795798301696777\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -200.    21.5]] not converged until episode: 1307\n",
      "Episode 1307,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 10, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.906912088394165\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1308,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.59320068359375\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1309,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 2.991492748260498\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1310,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.319422960281372\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1311,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.497502326965332\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1312,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 2.667672634124756\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1313,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.845045566558838\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1314,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 4.929841995239258\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1315,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 1.7959511280059814\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1316,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 3.051514148712158\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1317,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 1.8835923671722412\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1318,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 3.035061836242676\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1319,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.5697379112243652\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1320,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.0948166847229004\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1321,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.3327951431274414\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1322,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 3.0572900772094727\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1323,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 3.8442211151123047\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1324,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.193903684616089\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1325,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 3.334773063659668\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1326,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.2937841415405273\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1327,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 4.637294769287109\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1328,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.3026671409606934\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -400.    21.5]] not converged until episode: 1329\n",
      "Episode 1329,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 11, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 4.076316833496094\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1330,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.5234599113464355\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1331,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.5319924354553223\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1332,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 3.2767534255981445\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -100.    21.5]] not converged until episode: 1333\n",
      "Episode 1333,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 13, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 4.936324119567871\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 1334\n",
      "Episode 1334,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 4.788856506347656\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1335,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 2.7454867362976074\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1336,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.5262644290924072\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1337,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 2.2624831199645996\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1338,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 2.678446054458618\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1339,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.757843255996704\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1340,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 5.5490875244140625\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1341,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.8721566200256348\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1342,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 3.673830509185791\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -300.    21.5]] not converged until episode: 1343\n",
      "Episode 1343,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 13, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 3.519200325012207\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-300.  -500.    21.5]] not converged until episode: 1344\n",
      "Episode 1344,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 9, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 4.886656761169434\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1345,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 3.810812473297119\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1346,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 4.896182060241699\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1347,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.184013843536377\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1348,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 5.716259956359863\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1349,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.7312021255493164\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1350,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 2.7370145320892334\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1351,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 8.527793884277344\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 1352\n",
      "Episode 1352,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 9, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 4.982542037963867\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1353,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.7392308712005615\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1354,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.757643699645996\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1355,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 1.9490470886230469\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1356,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 2.134127616882324\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1357,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.4734930992126465\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1358,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.950601577758789\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1359,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.5747437477111816\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1360,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 3.8946893215179443\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1361,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 3.335611581802368\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -100.    21.5]] not converged until episode: 1362\n",
      "Episode 1362,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 11, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 3.0521113872528076\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1363,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.8207807540893555\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1364,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 6.769647598266602\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1365,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.9200692176818848\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1366,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 2.5045242309570312\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1367,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 3.1905465126037598\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1368,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 4.692279815673828\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1369,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 3.619481325149536\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1370,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 5.524280548095703\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1371,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 8.042203903198242\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 1372\n",
      "Episode 1372,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 8, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 4.514494895935059\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1373,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 6.391725540161133\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1374,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.625319480895996\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 1375\n",
      "Episode 1375,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 5.763876438140869\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1376,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.2672362327575684\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-300.  -100.    21.5]] not converged until episode: 1377\n",
      "Episode 1377,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 14, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 7.208423614501953\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1378,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 4.962556838989258\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1379,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.6148786544799805\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 1380\n",
      "Episode 1380,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 7.284293174743652\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1381,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 3.3926069736480713\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1382,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 11, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 3.523146629333496\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1383,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 7.460691452026367\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1384,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.2107410430908203\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-500.  -400.    21.5]] not converged until episode: 1385\n",
      "Episode 1385,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 11, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 6.168310642242432\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1386,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 4.269533157348633\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1387,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 8.661949157714844\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1388,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 7.052335739135742\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-300.  -500.    21.5]] not converged until episode: 1389\n",
      "Episode 1389,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 9, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 3.7171971797943115\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 1390\n",
      "Episode 1390,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 9, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 3.4361701011657715\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-500.  -400.    21.5]] not converged until episode: 1391\n",
      "Episode 1391,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 11, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 4.70580530166626\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 1392\n",
      "Episode 1392,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 8, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 5.616824626922607\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1393,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 1.9545978307724\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1394,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 4.475841522216797\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1395,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 4.3075456619262695\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1396,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 4.085445404052734\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 1397\n",
      "Episode 1397,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 5.767697334289551\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 1398\n",
      "Episode 1398,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 10, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 5.487231731414795\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-200.  -100.    21.5]] not converged until episode: 1399\n",
      "Episode 1399,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 14, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 3.8650002479553223\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1400,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 3.6882708072662354\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-300.  -300.    21.5]] not converged until episode: 1401\n",
      "Episode 1401,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 12, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 4.259954452514648\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1402,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 1.8683303594589233\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1403,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.066509962081909\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1404,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 3.5620193481445312\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1405,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 7.157060146331787\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1406,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 6.8930864334106445\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1407,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 3.2582287788391113\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1408,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.30831241607666\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1409,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.9759373664855957\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -200.    21.5]] not converged until episode: 1410\n",
      "Episode 1410,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 10, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 3.2811167240142822\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1411,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 3.3396170139312744\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1412,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 3.776308536529541\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-300.  -500.    21.5]] not converged until episode: 1413\n",
      "Episode 1413,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 9, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 4.349595069885254\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1414,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 3.0809173583984375\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-500.  -500.    21.5]] not converged until episode: 1415\n",
      "Episode 1415,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 10, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 6.3155341148376465\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-400.  -300.    21.5]] not converged until episode: 1416\n",
      "Episode 1416,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 11, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 4.088514804840088\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1417,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6899999976158142, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 3.6482362747192383\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1418,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6899999976158142, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 5.782617568969727\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1419,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6899999976158142, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 4.478771686553955\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 1420\n",
      "Episode 1420,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 8, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 4.083540916442871\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1421,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.4910786151885986\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1422,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.3995018005371094\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1423,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.069605827331543\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1424,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 3.581650495529175\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 1425\n",
      "Episode 1425,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 14, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 4.824237823486328\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1426,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 4.8742265701293945\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1427,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.7327990531921387\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1428,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 3.989072322845459\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1429,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.6360561847686768\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1430,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 2.576084613800049\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-500.  -500.    21.5]] not converged until episode: 1431\n",
      "Episode 1431,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 12, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 6.635316848754883\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1432,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 5.555608749389648\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1433,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 4.284142017364502\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1434,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6899999976158142, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 4.353161811828613\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 1435\n",
      "Episode 1435,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 4.1146135330200195\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 1436\n",
      "Episode 1436,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 5.976964950561523\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1437,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 3.8653175830841064\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1438,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 2.6863832473754883\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1439,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 5.045529365539551\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1440,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 3.4990921020507812\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1441,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 3.8069911003112793\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1442,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 3.6033811569213867\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1443,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 3.4488685131073\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1444,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.3290648460388184\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1445,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 2.804385185241699\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 1446\n",
      "Episode 1446,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 3.791442394256592\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1447,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 4.396729469299316\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1448,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 5.198529243469238\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1449,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 7.119185447692871\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1450,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 4.0954484939575195\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1451,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.591921091079712\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1452,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.3090360164642334\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1453,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.6523094177246094\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1454,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 4.661039352416992\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1455,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 4.905882835388184\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1456,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 4.4648332595825195\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1457,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 5.778368949890137\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-500.  -500.    21.5]] not converged until episode: 1458\n",
      "Episode 1458,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 10, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 4.710940361022949\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-500.  -500.    21.5]] not converged until episode: 1459\n",
      "Episode 1459,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 10, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 4.5123090744018555\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1460,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.513209104537964\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1461,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 3.8905913829803467\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1462,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 12, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 3.014138698577881\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1463,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 7.184579849243164\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1464,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 5.261631488800049\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-300.  -100.    21.5]] not converged until episode: 1465\n",
      "Episode 1465,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6399999856948853, current_best action: 12, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 3.470982551574707\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-300.  -300.    21.5]] not converged until episode: 1466\n",
      "Episode 1466,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 12, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 4.561932563781738\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1467,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6399999856948853, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.407883882522583\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1468,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6399999856948853, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 3.0173027515411377\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 1469\n",
      "Episode 1469,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 6.725569725036621\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1470,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 2.8798208236694336\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1471,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 4.008538722991943\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1472,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6399999856948853, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.6424765586853027\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1473,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6399999856948853, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.252220630645752\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 1474\n",
      "Episode 1474,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 4.188848495483398\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1475,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 3.519253730773926\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1476,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6299999952316284, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 4.542732238769531\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1477,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6399999856948853, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 5.836094856262207\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1478,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 4.309206485748291\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1479,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.792163372039795\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1480,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 4.457043170928955\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 1481\n",
      "Episode 1481,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 11, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 3.7522687911987305\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1482,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.7674689292907715\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1483,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 9, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 3.2327444553375244\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-300.  -200.    21.5]] not converged until episode: 1484\n",
      "Episode 1484,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6399999856948853, current_best action: 13, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 4.19859504699707\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1485,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 2.250913619995117\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1486,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 4.19995641708374\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 1487\n",
      "Episode 1487,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6399999856948853, current_best action: 14, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 7.768221378326416\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1488,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6399999856948853, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.659555673599243\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-300.  -500.    21.5]] not converged until episode: 1489\n",
      "Episode 1489,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6399999856948853, current_best action: 9, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 4.3074469566345215\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1490,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 3.0900979042053223\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1491,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.844282627105713\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1492,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 2.2464447021484375\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-500.  -500.    21.5]] not converged until episode: 1493\n",
      "Episode 1493,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 10, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 5.681274890899658\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-500.  -500.    21.5]] not converged until episode: 1494\n",
      "Episode 1494,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 10, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 5.524738311767578\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1495,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.9750685691833496\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 1496\n",
      "Episode 1496,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6499999761581421, current_best action: 9, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 4.291357517242432\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1497,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 3.111812114715576\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1498,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 2.8978686332702637\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1499,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 3.2126708030700684\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1500,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 12, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 2.178945541381836\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1501,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 4.053786754608154\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 1502\n",
      "Episode 1502,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 3.6675949096679688\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1503,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 3.0416712760925293\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1504,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 3.374387502670288\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -300.    21.5]] not converged until episode: 1505\n",
      "Episode 1505,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 13, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 4.030640602111816\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -500.    21.5]] not converged until episode: 1506\n",
      "Episode 1506,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 9, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 5.94005012512207\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1507,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.3603644371032715\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1508,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.5062437057495117\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1509,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.624077320098877\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1510,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 2.6173672676086426\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-400.  -500.    21.5]] not converged until episode: 1511\n",
      "Episode 1511,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 11, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 4.20150089263916\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1512,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.7868800163269043\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1513,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.5584869384765625\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1514,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.486236572265625\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1515,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 2.8579840660095215\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1516,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6899999976158142, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 4.407063961029053\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1517,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.657921314239502\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1518,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 4.057779312133789\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1519,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.3853201866149902\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -100.    21.5]] not converged until episode: 1520\n",
      "Episode 1520,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 9, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 3.480501174926758\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -100.    21.5]] not converged until episode: 1521\n",
      "Episode 1521,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6899999976158142, current_best action: 13, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 4.7753167152404785\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1522,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6899999976158142, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 3.0863394737243652\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1523,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6899999976158142, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 7.639455795288086\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1524,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6899999976158142, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.5214195251464844\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 1525\n",
      "Episode 1525,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6899999976158142, current_best action: 8, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 6.386465549468994\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1526,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 3.2208681106567383\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1527,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 7.604528427124023\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1528,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 4.40608549118042\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1529,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 4.076054573059082\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 1530\n",
      "Episode 1530,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 11, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 3.7469308376312256\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 1531\n",
      "Episode 1531,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 14, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 3.9518237113952637\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1532,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 3.0407795906066895\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1533,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 6.14721155166626\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1534,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 6.891728401184082\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1535,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 4.693732261657715\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1536,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 4.586940765380859\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1537,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.358919382095337\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-400.  -500.    21.5]] not converged until episode: 1538\n",
      "Episode 1538,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 11, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 4.3186492919921875\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1539,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 3.6337833404541016\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 1540\n",
      "Episode 1540,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 9, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 3.554802894592285\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 1541\n",
      "Episode 1541,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 8, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 5.319059371948242\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1542,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 5.470071792602539\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1543,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 2.505309820175171\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1544,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 2.311629056930542\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1545,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.74043607711792\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1546,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 5.788979530334473\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1547,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.216306447982788\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1548,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 7.5247087478637695\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 1549\n",
      "Episode 1549,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 5.525028228759766\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1550,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.1975183486938477\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1551,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 3.223037004470825\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1552,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 2.416344165802002\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1553,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.4725515842437744\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1554,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 3.2152950763702393\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1555,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.7658770084381104\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1556,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.855398654937744\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1557,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6600000262260437, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.722054958343506\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1558,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6700000166893005, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 3.9184935092926025\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1559,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 5.221856117248535\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1560,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6800000071525574, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 2.9884631633758545\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1561,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.6899999976158142, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 2.790595293045044\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1562,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.026111602783203\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1563,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 3.0528368949890137\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1564,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 3.375295639038086\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1565,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 3.907637596130371\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1566,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 5.548050880432129\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1567,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 2.913425922393799\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1568,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 4.194681644439697\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1569,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 7.982240676879883\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1570,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 4.681002616882324\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1571,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.2041468620300293\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1572,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 3.7846362590789795\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1573,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 10, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 1.922875165939331\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1574,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 3.385507106781006\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1575,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.8932948112487793\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1576,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 3.6253092288970947\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1577,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 4.716792106628418\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1578,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 7.4142303466796875\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 1579\n",
      "Episode 1579,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 8, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 7.092844486236572\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 1580\n",
      "Episode 1580,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 8, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 6.692497253417969\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1581,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 3.6995251178741455\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1582,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 3.0650813579559326\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1583,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.7732229232788086\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1584,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.3337650299072266\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1585,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 5.109868049621582\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1586,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 12, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 3.3695273399353027\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1587,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 3.4365592002868652\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1588,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 5.040623188018799\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 1589\n",
      "Episode 1589,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 12, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 4.416139602661133\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1590,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 2.484306812286377\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1591,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 4.05894660949707\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1592,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 5.477541923522949\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1593,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 4.396780967712402\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1594,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 3.304377794265747\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1595,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 3.5839953422546387\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1596,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 5.077673435211182\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1597,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 3.658060312271118\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1598,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 13, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 4.23110294342041\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1599,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 3.563100814819336\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1600,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 4.175210952758789\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1601,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 4.18595552444458\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1602,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 4.086933135986328\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -500.    21.5]] not converged until episode: 1603\n",
      "Episode 1603,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 9, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 5.983393669128418\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1604,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 5.180700778961182\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-300.  -200.    21.5]] not converged until episode: 1605\n",
      "Episode 1605,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 13, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 5.602860450744629\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1606,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 3.9982261657714844\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1607,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 4.846932411193848\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -300.    21.5]] not converged until episode: 1608\n",
      "Episode 1608,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 13, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 4.936324596405029\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1609,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 3.987830638885498\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1610,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 4.7250165939331055\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1611,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 6.760128498077393\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 1612\n",
      "Episode 1612,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 7.736342430114746\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1613,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 5.110743045806885\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 1614\n",
      "Episode 1614,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 9, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 5.099440574645996\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-300.  -500.    21.5]] not converged until episode: 1615\n",
      "Episode 1615,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 9, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 4.943196773529053\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1616,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 4.176841735839844\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1617,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 4.488095760345459\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1618,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 5.21073055267334\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1619,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 4.185944557189941\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 1620\n",
      "Episode 1620,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 3.937537670135498\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1621,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 4.6939544677734375\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1622,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 10, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 3.07963228225708\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 1623\n",
      "Episode 1623,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 14, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 4.391820430755615\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1624,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 4.375051498413086\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1625,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 3.882852554321289\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1626,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.713519811630249\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1627,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 4.257500171661377\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1628,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 5.688004016876221\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1629,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 5.045535087585449\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1630,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 4.589962959289551\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1631,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 3.30220365524292\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1632,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 4.403451919555664\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1633,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 2.2331295013427734\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 1634\n",
      "Episode 1634,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 10, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 6.310155391693115\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1635,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 5.11169958114624\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1636,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 4.188796520233154\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1637,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.6096854209899902\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1638,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 4.873908519744873\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1639,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 5.297257423400879\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1640,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 3.7183756828308105\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1641,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7900000214576721, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 5.1592278480529785\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1642,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7900000214576721, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 5.749964714050293\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1643,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7900000214576721, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 4.4891157150268555\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 1644\n",
      "Episode 1644,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 4.205986976623535\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1645,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 4.018054485321045\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1646,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 4.8550920486450195\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1647,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 10.618708610534668\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-300.  -100.    21.5]] not converged until episode: 1648\n",
      "Episode 1648,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 14, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 4.499058723449707\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1649,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 4.1019287109375\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1650,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 5.386129379272461\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1651,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 9.144088745117188\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1652,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 11.472043991088867\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1653,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 4.756261348724365\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-300.  -200.    21.5]] not converged until episode: 1654\n",
      "Episode 1654,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 11, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 4.348416328430176\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1655,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 5.755084991455078\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-400.  -500.    21.5]] not converged until episode: 1656\n",
      "Episode 1656,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 11, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 4.789478302001953\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1657,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 5.614377975463867\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1658,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 5.828433990478516\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1659,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 4.751460552215576\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1660,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 11, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.1742303371429443\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1661,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 9.707645416259766\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1662,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 9.608070373535156\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1663,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 3.685654640197754\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1664,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 8.89125919342041\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1665,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 3.931321620941162\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1666,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 4.084871292114258\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1667,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 7.453696250915527\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1668,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 3.03472900390625\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1669,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 3.3897757530212402\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1670,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 9.320658683776855\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1671,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 4.254080772399902\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1672,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 4.907781600952148\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1673,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 5.869143009185791\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1674,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.675419807434082\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1675,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 8.004292488098145\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 1676\n",
      "Episode 1676,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 8, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 10.115468978881836\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1677,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 10.145647048950195\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1678,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 6.705414772033691\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1679,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.6823058128356934\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 1680\n",
      "Episode 1680,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 8, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 5.327630043029785\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1681,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 2.7010560035705566\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1682,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 5.313715934753418\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1683,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 6.037606239318848\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1684,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 5.336401462554932\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 1685\n",
      "Episode 1685,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 10, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 3.8413496017456055\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -200.    21.5]] not converged until episode: 1686\n",
      "Episode 1686,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 10, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 4.197159767150879\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1687,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 8.087688446044922\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-500.  -500.    21.5]] not converged until episode: 1688\n",
      "Episode 1688,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 12, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 8.845224380493164\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1689,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 10, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 6.23151159286499\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -200.    21.5]] not converged until episode: 1690\n",
      "Episode 1690,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 10, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 3.8337900638580322\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1691,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 6.33792781829834\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -200.    21.5]] not converged until episode: 1692\n",
      "Episode 1692,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 10, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 3.1677207946777344\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1693,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 6.07032585144043\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1694,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 2.2994275093078613\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1695,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 5.671888828277588\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1696,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.6524171829223633\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1697,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.9232141971588135\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1698,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 4.183730125427246\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1699,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 5.080504417419434\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1700,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 3.3636488914489746\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1701,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 3.6568613052368164\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1702,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 8.082576751708984\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1703,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 3.578131914138794\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1704,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 4.713956832885742\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1705,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 3.3370373249053955\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1706,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 4.552663803100586\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1707,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 5.536614894866943\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1708,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 3.9202418327331543\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1709,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 6.267568588256836\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1710,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 5.39832067489624\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-500.  -500.    21.5]] not converged until episode: 1711\n",
      "Episode 1711,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 10, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 7.392989158630371\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1712,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 4.548722743988037\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1713,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 4.8552141189575195\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1714,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 3.087571144104004\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-300.  -100.    21.5]] not converged until episode: 1715\n",
      "Episode 1715,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 14, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 8.391705513000488\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-300.  -200.    21.5]] not converged until episode: 1716\n",
      "Episode 1716,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 13, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 3.8312172889709473\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 1717\n",
      "Episode 1717,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 14, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 8.225285530090332\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1718,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 3.792337417602539\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1719,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.2215518951416016\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1720,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.667583465576172\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1721,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.9227964878082275\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1722,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 3.2206246852874756\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 1723\n",
      "Episode 1723,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 12, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 8.034626960754395\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 1724\n",
      "Episode 1724,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 4.644946575164795\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 1725\n",
      "Episode 1725,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 10, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 7.177971839904785\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1726,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 5.015524864196777\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1727,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 3.272919178009033\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1728,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 3.5106661319732666\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1729,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 3.7718124389648438\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 1730\n",
      "Episode 1730,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 6.387126922607422\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1731,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 5.454852104187012\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1732,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 3.8832647800445557\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1733,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 6.046712875366211\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1734,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 4.569498538970947\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-500.  -500.    21.5]] not converged until episode: 1735\n",
      "Episode 1735,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 12, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 5.127910614013672\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1736,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 3.555044651031494\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1737,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 3.5031354427337646\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1738,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 3.210031509399414\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1739,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 5.247354507446289\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1740,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 3.847102403640747\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-500.  -500.    21.5]] not converged until episode: 1741\n",
      "Episode 1741,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 10, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 4.527059555053711\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1742,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 2.9819722175598145\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1743,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 7.556384086608887\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1744,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 3.1053991317749023\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1745,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 3.4575631618499756\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1746,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 3.1640779972076416\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 1747\n",
      "Episode 1747,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 9, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 4.605983734130859\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 1748\n",
      "Episode 1748,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.699999988079071, current_best action: 14, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 7.418684482574463\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1749,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 8.127119064331055\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1750,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 9.194005966186523\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1751,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 3.832156181335449\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1752,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 3.6092567443847656\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1753,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7099999785423279, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 4.0507941246032715\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1754,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 3.671074151992798\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1755,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 5.27740478515625\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1756,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 4.358981132507324\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1757,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 3.72727108001709\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -300.    21.5]] not converged until episode: 1758\n",
      "Episode 1758,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 13, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 4.41290283203125\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1759,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 5.077548980712891\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1760,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 5.374014377593994\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1761,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 4.1455159187316895\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1762,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.7862424850463867\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1763,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 3.14959979057312\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1764,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 4.149620532989502\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1765,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 3.7848329544067383\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1766,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 6.510473728179932\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1767,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 4.154815196990967\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1768,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 2.9193313121795654\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1769,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 4.314841270446777\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1770,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 5.984918594360352\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1771,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 3.824441909790039\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1772,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 3.9881772994995117\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1773,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 4.067241668701172\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1774,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.663775682449341\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1775,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 3.0702550411224365\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 1776\n",
      "Episode 1776,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 4.776102066040039\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1777,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 5.1446051597595215\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1778,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 4.495383262634277\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1779,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 5.584315299987793\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1780,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 4.172796249389648\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1781,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 3.022620677947998\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1782,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 4.348456382751465\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1783,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.3920698165893555\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1784,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 5.5023932456970215\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1785,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 4.890469551086426\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1786,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 4.992473602294922\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1787,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 5.2213053703308105\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1788,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7900000214576721, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 9.696395874023438\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1789,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.800000011920929, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 5.826704978942871\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1790,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8100000023841858, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 9.450496673583984\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1791,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8100000023841858, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 4.966192245483398\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1792,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8199999928474426, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 5.01483154296875\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1793,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8199999928474426, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 6.618287086486816\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1794,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8199999928474426, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 3.0151636600494385\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1795,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8199999928474426, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 3.2483761310577393\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1796,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8199999928474426, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 5.577462196350098\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1797,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8199999928474426, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.507486343383789\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1798,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 5.753033638000488\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1799,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 4.468947410583496\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1800,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 3.668875217437744\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1801,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 4.779842853546143\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1802,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 3.319512367248535\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1803,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 9.718779563903809\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1804,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 5.931302070617676\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 1805\n",
      "Episode 1805,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8199999928474426, current_best action: 10, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 3.8930234909057617\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1806,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8199999928474426, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 8.405370712280273\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1807,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8199999928474426, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 5.035429000854492\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1808,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8199999928474426, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 7.558477401733398\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1809,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8199999928474426, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 5.3354010581970215\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1810,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8199999928474426, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 5.57932186126709\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1811,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 11.311753273010254\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1812,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 6.009902477264404\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1813,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 3.7208807468414307\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1814,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 6.527841567993164\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1815,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 3.4134302139282227\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1816,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 7.213924884796143\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 1817\n",
      "Episode 1817,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 8, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 5.064426422119141\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1818,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 7.336248397827148\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1819,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 5.163657188415527\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1820,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 7.970305919647217\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1821,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 6.936636447906494\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1822,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 5.612829685211182\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1823,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 5.946420192718506\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1824,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 5.396617889404297\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1825,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 9.195178985595703\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1826,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 3.5476300716400146\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1827,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 7.908357620239258\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 1828\n",
      "Episode 1828,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 7.8163042068481445\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1829,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 2.5576846599578857\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1830,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 5.023738384246826\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1831,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 9.612436294555664\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1832,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 3.0310990810394287\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1833,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 5.729119300842285\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1834,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 3.687412738800049\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1835,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 6.326061725616455\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1836,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 5.808412551879883\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1837,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 3.4780755043029785\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1838,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 6.663238048553467\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1839,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 5.185327529907227\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1840,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 10.050371170043945\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1841,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 3.794909954071045\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1842,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 3.951425075531006\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1843,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 4.918964385986328\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1844,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 3.4143128395080566\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1845,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 3.5447590351104736\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1846,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 7.134961128234863\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1847,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 5.039369583129883\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 1848\n",
      "Episode 1848,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 5.195096015930176\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1849,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 4.569865703582764\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1850,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 4.0742692947387695\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1851,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 4.856531143188477\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1852,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 5.908329963684082\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1853,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 6.432244777679443\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1854,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 4.919848918914795\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1855,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 3.028625011444092\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1856,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 3.1814138889312744\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 1857\n",
      "Episode 1857,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 5.254605293273926\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 1858\n",
      "Episode 1858,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 9, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 7.068593978881836\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1859,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 6.676949501037598\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 1860\n",
      "Episode 1860,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 11, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 5.960977554321289\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1861,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 3.174954891204834\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1862,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 7.872844696044922\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1863,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 6.127459526062012\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -300.    21.5]] not converged until episode: 1864\n",
      "Episode 1864,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 13, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 6.677829742431641\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1865,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 5.158483505249023\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1866,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 3.601375102996826\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1867,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 7.822449684143066\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1868,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 9.506905555725098\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1869,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 5.177431106567383\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1870,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 3.290497064590454\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1871,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 4.113252639770508\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1872,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 5.909703254699707\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1873,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 4.484163284301758\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1874,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 8.156278610229492\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 1875\n",
      "Episode 1875,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 8, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 6.366837501525879\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1876,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 4.335939884185791\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1877,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.6104023456573486\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-300.  -300.    21.5]] not converged until episode: 1878\n",
      "Episode 1878,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 12, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 4.060525894165039\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1879,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.2934751510620117\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1880,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 3.058131217956543\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1881,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 3.356769561767578\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 1882\n",
      "Episode 1882,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 7.084456920623779\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1883,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 5.549710273742676\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1884,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 9.00684928894043\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1885,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 4.7586774826049805\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1886,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 4.6386871337890625\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1887,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 6.809765815734863\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1888,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 8.633993148803711\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 1889\n",
      "Episode 1889,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8199999928474426, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 9.431549072265625\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1890,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8100000023841858, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 5.723903656005859\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1891,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8100000023841858, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 3.8966307640075684\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1892,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8100000023841858, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 6.177487373352051\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1893,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8100000023841858, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 5.053175926208496\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1894,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8100000023841858, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 6.218027114868164\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 1895\n",
      "Episode 1895,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.800000011920929, current_best action: 14, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 5.551389694213867\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 1896\n",
      "Episode 1896,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7900000214576721, current_best action: 9, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 10.101375579833984\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1897,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 5.512392044067383\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1898,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 6.980973243713379\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1899,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 6.738340854644775\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1900,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 6.120433807373047\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1901,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 4.058706283569336\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 1902\n",
      "Episode 1902,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 5.428585052490234\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1903,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 6.458937644958496\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1904,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 6.375354290008545\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1905,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 7.009581565856934\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 1906\n",
      "Episode 1906,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 9, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 8.251249313354492\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1907,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 4.149850845336914\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -500.    21.5]] not converged until episode: 1908\n",
      "Episode 1908,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 9, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 6.316313743591309\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1909,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 6.970022201538086\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1910,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 4.522521018981934\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1911,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 5.251809120178223\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1912,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 5.093891143798828\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1913,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 7.005176067352295\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1914,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 4.851072788238525\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1915,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 7.814464092254639\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1916,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 5.512234687805176\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1917,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 7.590024948120117\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1918,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 2.6749141216278076\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1919,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.322252035140991\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1920,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 3.525972604751587\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1921,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 6.009113788604736\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1922,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 3.8222386837005615\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 1923\n",
      "Episode 1923,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 4.663446426391602\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1924,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 4.665022850036621\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1925,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 6.6772260665893555\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1926,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 7.883724689483643\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1927,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 6.7356672286987305\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1928,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 2.847003936767578\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1929,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 6.732709884643555\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1930,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 5.852404594421387\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1931,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 4.0590620040893555\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1932,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 7.46433162689209\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1933,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 6.343295097351074\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1934,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 5.457104206085205\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1935,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 7.8845367431640625\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1936,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 5.344328880310059\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1937,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 5.71182918548584\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1938,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 5.016107082366943\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1939,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 8.461068153381348\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1940,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 5.5286712646484375\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1941,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 5.90244722366333\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1942,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 6.4256911277771\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1943,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7900000214576721, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 8.81378173828125\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1944,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7900000214576721, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 7.921581268310547\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1945,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7900000214576721, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 7.702098846435547\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1946,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7900000214576721, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 8.268571853637695\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1947,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7900000214576721, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 6.026909351348877\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1948,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.800000011920929, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 5.355140686035156\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1949,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7900000214576721, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 4.124055862426758\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1950,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7900000214576721, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 7.967304229736328\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1951,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7900000214576721, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 9.10863208770752\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1952,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7900000214576721, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 6.887590408325195\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1953,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7900000214576721, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 10.361498832702637\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1954,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.800000011920929, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 9.833873748779297\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1955,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7900000214576721, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 4.3874287605285645\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1956,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7900000214576721, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 4.5049848556518555\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1957,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.800000011920929, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 4.476759433746338\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1958,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.800000011920929, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 4.573708534240723\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1959,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.800000011920929, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 9.758152961730957\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1960,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8100000023841858, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 4.253470420837402\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1961,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8100000023841858, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.6364550590515137\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1962,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8100000023841858, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 5.296320915222168\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1963,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8100000023841858, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 4.5693440437316895\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1964,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8199999928474426, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 4.4356255531311035\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1965,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8199999928474426, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 6.045265197753906\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1966,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8199999928474426, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 6.659095764160156\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1967,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8199999928474426, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 9.196939468383789\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1968,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8199999928474426, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 9.083812713623047\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1969,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8199999928474426, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 4.833040237426758\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1970,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8199999928474426, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 5.12864875793457\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1971,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 4.5690083503723145\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1972,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 5.282283782958984\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1973,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 5.187417030334473\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1974,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 9.842670440673828\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 1975,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 5.062605857849121\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1976,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 11.55374813079834\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1977,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.3712291717529297\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1978,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 3.827220916748047\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1979,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 9.93634033203125\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 1980\n",
      "Episode 1980,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 7.878162384033203\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1981,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 10.670232772827148\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1982,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 5.331766128540039\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1983,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 10.189859390258789\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1984,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 4.919041633605957\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1985,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 10.455358505249023\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1986,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 7.822781562805176\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1987,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 10.168213844299316\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1988,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 5.223554611206055\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1989,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 4.1744465827941895\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1990,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 7.022176265716553\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1991,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 4.610023498535156\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 1992\n",
      "Episode 1992,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 14, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 5.625701904296875\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1993,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 3.900851011276245\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 1994,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 7.392209529876709\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 1995,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 7.476757049560547\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 1996,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 6.4758782386779785\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 1997,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 3.170686721801758\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 1998,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 6.704960823059082\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 1999,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 8.2674560546875\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2000,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 7.973459720611572\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2001,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 8.089693069458008\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2002,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 4.003794193267822\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2003,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 4.8243818283081055\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2004,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 8.535005569458008\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2005,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 6.356925010681152\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2006,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 3.9055542945861816\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2007,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 9.932700157165527\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2008,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 11.015329360961914\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2009,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 9.73361587524414\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2010,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 4.253411293029785\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2011,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 7.202431678771973\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2012,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 9.440958023071289\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2013,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 3.735628843307495\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2014,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 6.126080513000488\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2015,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 9.647985458374023\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2016,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 10.535516738891602\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 2017\n",
      "Episode 2017,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 6.807194232940674\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2018,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 4.717037677764893\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2019,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 4.848854064941406\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2020,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 3.3543806076049805\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2021,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 6.249339580535889\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2022,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 8.903779029846191\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2023,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 3.5884413719177246\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2024,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 5.215346336364746\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2025,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 8.424349784851074\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2026,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 8.624701499938965\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2027,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 7.057872772216797\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2028,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 7.759182929992676\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2029,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 5.321284770965576\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2030,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 6.941265106201172\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2031,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 10.381665229797363\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2032,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 10.036191940307617\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2033,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 8.248908996582031\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2034,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 10.36470890045166\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2035,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 10.434107780456543\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2036,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 6.372841835021973\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2037,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 6.518093109130859\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2038,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 5.676423072814941\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2039,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 6.3775458335876465\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2040,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 6.550991058349609\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2041,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 7.751456260681152\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2042,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 7.172677993774414\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2043,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 7.567785739898682\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2044,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 6.611911773681641\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2045,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 8.042718887329102\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2046,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 8.286746978759766\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2047,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 8.11813735961914\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2048,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 3.985927104949951\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2049,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 11.473628997802734\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2050,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 5.858682155609131\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2051,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 7.619089126586914\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 2052\n",
      "Episode 2052,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 8, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 9.531967163085938\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2053,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 7.0072736740112305\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2054,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 3.912235736846924\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -300.    21.5]] not converged until episode: 2055\n",
      "Episode 2055,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 13, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 5.511089324951172\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2056,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 7.411599159240723\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 2057\n",
      "Episode 2057,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 5.01638126373291\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2058,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 4.933697700500488\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 2059\n",
      "Episode 2059,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 9, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 9.6998929977417\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2060,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 10.079120635986328\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2061,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 7.125060081481934\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2062,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 10.292633056640625\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2063,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 3.5975184440612793\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 2064\n",
      "Episode 2064,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 9, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 5.534845352172852\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 2065\n",
      "Episode 2065,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 6.15350341796875\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2066,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 4.536386013031006\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 2067\n",
      "Episode 2067,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 9, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 10.054758071899414\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2068,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 5.727541923522949\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2069,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 3.8344180583953857\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2070,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 3.4865126609802246\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2071,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 8.583417892456055\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2072,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 4.81721305847168\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2073,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 4.383030414581299\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2074,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 6.817944526672363\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2075,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 7.011730194091797\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2076,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 2.7235841751098633\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2077,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 6.8296427726745605\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2078,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 7.2393693923950195\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 2079\n",
      "Episode 2079,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 6.925243377685547\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2080,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 3.1941609382629395\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2081,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 10.429607391357422\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2082,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 5.754597187042236\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2083,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 4.282851219177246\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2084,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 8.971561431884766\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2085,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 11.80441951751709\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2086,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 7.372889995574951\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2087,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 7.931968688964844\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2088,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 4.06461763381958\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2089,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 4.575821876525879\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2090,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 7.281648635864258\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2091,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 7.890802383422852\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2092,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 7.157277584075928\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2093,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 7.132084369659424\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2094,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 8.35853385925293\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2095,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 7.622974395751953\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2096,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 4.452953338623047\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2097,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 5.002891540527344\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2098,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 7.654027938842773\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2099,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 6.104701519012451\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2100,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 8.797623634338379\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2101,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 5.556702613830566\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2102,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 8.483410835266113\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2103,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 6.914937973022461\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2104,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 2.7561187744140625\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2105,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 7.833247184753418\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2106,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 5.399872779846191\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2107,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 5.091259479522705\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2108,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 9.291382789611816\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2109,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 8.567022323608398\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2110,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 9.31442642211914\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2111,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 7.496670722961426\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2112,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 7.956338882446289\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2113,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 7.314565658569336\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2114,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 6.811418533325195\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2115,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 4.613802909851074\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2116,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 4.777679920196533\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2117,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 3.495450973510742\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2118,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 5.296675682067871\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2119,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 4.23252010345459\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2120,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 9.42226505279541\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2121,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 9.865772247314453\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2122,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 4.3453898429870605\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2123,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 6.883461952209473\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2124,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 9.146142959594727\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2125,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 2.3580193519592285\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2126,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 4.222518444061279\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2127,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 6.7212042808532715\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2128,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 3.5400686264038086\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2129,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 5.15846586227417\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2130,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 8.843658447265625\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2131,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 7.924832344055176\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2132,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 4.869916915893555\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2133,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 6.827420234680176\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2134,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 9.221416473388672\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2135,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 8.541707992553711\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2136,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 6.612586498260498\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2137,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 6.9814653396606445\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2138,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 8.234992027282715\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2139,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 8.79594612121582\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2140,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 9.556253433227539\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2141,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 5.8126115798950195\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2142,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 8.097987174987793\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2143,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 9.202362060546875\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2144,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 7.892905235290527\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2145,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 6.793481826782227\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2146,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 7.166452884674072\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2147,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 8.846993446350098\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2148,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 8.561209678649902\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 2149\n",
      "Episode 2149,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8199999928474426, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 8.461557388305664\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2150,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8199999928474426, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 4.304281234741211\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2151,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8199999928474426, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 8.896125793457031\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2152,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 7.560345649719238\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2153,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 7.90604305267334\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2154,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 6.314572334289551\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2155,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 4.048618316650391\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2156,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 5.860138893127441\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2157,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 4.459335803985596\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2158,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 5.051182746887207\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2159,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 5.020895957946777\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2160,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 5.688290596008301\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2161,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 10.486845970153809\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2162,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 4.730287551879883\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2163,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 7.349457740783691\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2164,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 5.12488317489624\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2165,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 5.846931457519531\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2166,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 6.126851558685303\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2167,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 4.57889461517334\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2168,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 5.663780212402344\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2169,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 6.526952743530273\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2170,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 5.748028755187988\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2171,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 7.420409202575684\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2172,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 3.9061763286590576\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2173,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 6.548904895782471\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2174,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 5.668985366821289\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2175,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 8.657268524169922\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2176,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 9.528979301452637\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2177,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 9.411539077758789\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2178,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 9.076441764831543\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2179,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 6.9585161209106445\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2180,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 8.062044143676758\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2181,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 12.901200294494629\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2182,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 12.95969295501709\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2183,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 5.539432048797607\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2184,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 5.1830949783325195\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2185,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 4.746162414550781\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2186,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 13.057586669921875\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2187,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 3.26455020904541\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2188,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 4.864264488220215\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2189,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 7.244621753692627\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2190,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 7.392604827880859\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2191,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 9.940195083618164\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2192,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 7.835978984832764\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2193,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 5.118529319763184\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2194,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 7.660694122314453\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2195,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 10.227485656738281\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2196,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 6.969923973083496\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2197,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 8.09112548828125\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2198,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 4.194938659667969\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2199,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 10.33782958984375\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2200,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 5.23714542388916\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2201,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 6.013785362243652\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2202,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 10.7633695602417\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2203,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 5.072902679443359\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2204,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 8.689661979675293\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2205,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 5.906155586242676\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2206,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 9.919681549072266\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2207,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 5.609535217285156\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2208,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 7.084269046783447\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2209,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 10.018951416015625\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2210,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 6.224250316619873\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2211,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 6.950307846069336\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2212,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 8.156895637512207\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2213,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 9.057367324829102\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2214,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 4.277222156524658\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2215,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 8.201066017150879\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2216,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 12.350253105163574\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2217,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 12.361326217651367\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2218,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 6.463884353637695\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2219,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 11.337320327758789\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2220,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 8.673592567443848\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2221,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 6.849607944488525\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2222,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 8.704645156860352\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2223,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 8.243362426757812\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2224,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 7.779965877532959\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2225,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 10.01087760925293\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2226,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 9.26854419708252\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2227,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 5.522529602050781\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2228,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 6.66988468170166\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2229,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 6.485877513885498\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2230,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 9.72143268585205\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2231,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 9.4949369430542\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2232,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 11.110025405883789\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2233,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 9.627584457397461\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2234,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 7.216796875\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2235,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 8.97123908996582\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2236,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 5.029716491699219\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2237,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 7.485846519470215\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2238,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 7.722153663635254\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2239,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 6.296200275421143\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2240,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 5.581727504730225\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2241,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.581963539123535\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2242,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 6.329176902770996\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2243,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 9.120342254638672\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2244,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 5.564451694488525\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2245,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 9.370933532714844\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-300.  -100.    21.5]] not converged until episode: 2246\n",
      "Episode 2246,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 14, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 6.507457733154297\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 2247\n",
      "Episode 2247,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 5.451996803283691\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2248,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 9.979839324951172\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2249,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 9.970541000366211\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2250,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 6.725198745727539\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2251,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 9.395050048828125\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2252,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 10.06280517578125\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2253,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 9.977649688720703\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2254,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 5.262556552886963\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2255,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 10.093185424804688\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2256,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 4.019340515136719\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2257,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 3.7915549278259277\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2258,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 6.4440765380859375\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2259,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 12.314512252807617\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2260,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 9.479413986206055\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2261,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 5.115274429321289\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2262,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 5.060945987701416\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2263,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 10.010483741760254\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2264,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 11.182340621948242\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2265,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 6.198604583740234\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2266,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 3.303447961807251\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2267,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 6.310795783996582\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2268,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 9.277861595153809\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2269,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 11.242302894592285\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2270,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 6.566978454589844\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2271,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 11.198732376098633\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2272,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 6.461643695831299\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2273,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 7.941456317901611\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2274,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 9.81417179107666\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2275,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 11.66876220703125\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2276,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 5.204924583435059\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2277,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 4.166574954986572\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2278,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 5.58976936340332\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2279,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 5.54617166519165\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2280,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 3.614442825317383\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2281,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 7.814797401428223\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-300.  -200.    21.5]] not converged until episode: 2282\n",
      "Episode 2282,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 6.029668807983398\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2283,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 4.917463302612305\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2284,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 10.579084396362305\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2285,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 7.98481559753418\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2286,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 4.025684833526611\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2287,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 11.173161506652832\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2288,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 5.986824035644531\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2289,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 6.070249557495117\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2290,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 12.427188873291016\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2291,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 5.3057379722595215\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2292,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 3.460808277130127\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2293,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 8.600775718688965\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2294,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 6.569375991821289\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2295,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 8.399724960327148\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2296,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 8.509392738342285\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2297,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 3.8340258598327637\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2298,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 11.831860542297363\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2299,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 9.494379043579102\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2300,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 6.826175689697266\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2301,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 5.358043193817139\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2302,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 9.311569213867188\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2303,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 12.15803337097168\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2304,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 6.688817501068115\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2305,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 3.6131222248077393\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2306,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 3.726017951965332\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 2307\n",
      "Episode 2307,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 11.166030883789062\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2308,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 9.867097854614258\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2309,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 10.875574111938477\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2310,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 8.84511947631836\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2311,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 10.531730651855469\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2312,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 9.898724555969238\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2313,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 4.506643295288086\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2314,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 4.925955295562744\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2315,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 5.162328720092773\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2316,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 10.938668251037598\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2317,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 3.8449466228485107\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2318,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 7.725672721862793\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2319,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 11.385409355163574\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2320,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 6.555955410003662\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2321,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 9.93055534362793\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2322,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 6.031230926513672\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2323,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 8.850011825561523\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2324,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 6.86807918548584\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2325,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 8.15992259979248\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2326,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 9.333003997802734\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2327,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 3.98213529586792\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2328,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 9.309280395507812\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2329,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 4.2804694175720215\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2330,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 10.020376205444336\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2331,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 7.012850284576416\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2332,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 8.355504989624023\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2333,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 9.550069808959961\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2334,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 9.614740371704102\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2335,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 10.951848983764648\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2336,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 7.437847137451172\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2337,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 10.900871276855469\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2338,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 11.06740951538086\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2339,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 10.931476593017578\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2340,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 6.038266181945801\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2341,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 11.125846862792969\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2342,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 11.304874420166016\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2343,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 8.103301048278809\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2344,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 8.285604476928711\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2345,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 11.163558959960938\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2346,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 10.78493881225586\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2347,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 11.90264892578125\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2348,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 10.189153671264648\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2349,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 10.427836418151855\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2350,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 10.47966194152832\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2351,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 11.58731460571289\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2352,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 12.347591400146484\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2353,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 6.595963001251221\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2354,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 9.32058048248291\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2355,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 11.988737106323242\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2356,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 9.853063583374023\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2357,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 10.959474563598633\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2358,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 8.473855972290039\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2359,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 10.862287521362305\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2360,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 11.042850494384766\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2361,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.003623008728027\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2362,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 9.923149108886719\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2363,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 11.990368843078613\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2364,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 7.177562236785889\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2365,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 8.80080795288086\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2366,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 5.611916542053223\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2367,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 7.031139373779297\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2368,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 10.614616394042969\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2369,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 11.844592094421387\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2370,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 6.6658806800842285\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2371,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 11.318147659301758\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2372,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 6.257349967956543\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2373,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 6.475856781005859\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2374,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 8.88612174987793\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2375,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 2.720334053039551\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2376,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 6.394407272338867\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2377,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 11.909832000732422\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2378,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 12.122904777526855\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2379,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 9.520944595336914\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2380,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 10.538482666015625\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2381,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 11.367406845092773\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2382,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 10.967479705810547\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2383,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 10.434179306030273\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2384,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 8.398002624511719\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2385,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 4.414328098297119\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2386,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 11.28880500793457\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2387,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 7.487983703613281\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2388,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 6.599498748779297\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2389,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 6.138034343719482\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2390,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 11.458903312683105\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2391,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 10.391529083251953\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2392,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 11.031571388244629\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2393,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 12.229162216186523\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2394,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 8.016176223754883\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2395,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 5.928815841674805\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2396,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 10.639345169067383\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2397,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.324552536010742\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2398,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 9.693883895874023\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2399,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 8.147200584411621\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2400,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 9.219789505004883\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 2401\n",
      "Episode 2401,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 9, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 6.771638870239258\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2402,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 9.902033805847168\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2403,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 8.254222869873047\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2404,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 7.017176151275635\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2405,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 6.231929779052734\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2406,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 8.65591049194336\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2407,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 8.964859008789062\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 2408\n",
      "Episode 2408,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 14, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 7.9757232666015625\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2409,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.33973503112793\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2410,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 12.73509693145752\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2411,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 7.393048286437988\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2412,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 6.278532028198242\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2413,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 11.234349250793457\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2414,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 11.704996109008789\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2415,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 7.2511091232299805\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2416,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 6.076662540435791\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2417,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 9.502065658569336\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2418,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 5.284221649169922\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2419,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.925936698913574\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2420,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 12.222938537597656\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2421,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 9.290246963500977\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-200.  -100.    21.5]] not converged until episode: 2422\n",
      "Episode 2422,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 12, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 5.939330101013184\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2423,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 5.8583149909973145\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2424,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 6.826823711395264\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 2425\n",
      "Episode 2425,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 14.394309997558594\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 2426\n",
      "Episode 2426,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.63754940032959\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2427,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 8.74737548828125\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2428,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 11.36739730834961\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2429,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 11, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 4.805971622467041\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2430,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 11.095247268676758\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2431,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 5.6512250900268555\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 2432\n",
      "Episode 2432,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 7.475766181945801\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -300.    21.5]] not converged until episode: 2433\n",
      "Episode 2433,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 13, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 15.668974876403809\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2434,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 4.131622314453125\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2435,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 7.819032192230225\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2436,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 7.047465801239014\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2437,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 7.4271135330200195\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2438,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 5.403287410736084\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2439,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 5.1816816329956055\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -300.    21.5]] not converged until episode: 2440\n",
      "Episode 2440,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 13, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 11.6739501953125\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2441,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 10.239789962768555\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2442,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.328862190246582\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2443,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 12.190077781677246\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2444,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 10.431787490844727\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2445,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 9.56513786315918\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2446,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 11, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 7.406200885772705\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -100.    21.5]] not converged until episode: 2447\n",
      "Episode 2447,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 13, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 7.053535461425781\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2448,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 4.750143051147461\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2449,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.033476829528809\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2450,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 5.862071990966797\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2451,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 6.229189872741699\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2452,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 7.928400039672852\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-500.  -400.    21.5]] not converged until episode: 2453\n",
      "Episode 2453,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 11, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 12.852362632751465\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -300.    21.5]] not converged until episode: 2454\n",
      "Episode 2454,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8199999928474426, current_best action: 13, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 6.473811626434326\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2455,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8199999928474426, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 6.524054527282715\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2456,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8100000023841858, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 4.594667434692383\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2457,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8100000023841858, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 2.825126886367798\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2458,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8100000023841858, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 7.964257717132568\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2459,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8100000023841858, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 4.675284385681152\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2460,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8100000023841858, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 7.698138236999512\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2461,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8100000023841858, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 11.420963287353516\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2462,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8100000023841858, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 8.92568588256836\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2463,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8100000023841858, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 8.613670349121094\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2464,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8100000023841858, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 8.131453514099121\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2465,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8100000023841858, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 12.472556114196777\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 2466\n",
      "Episode 2466,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.800000011920929, current_best action: 10, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 14.159748077392578\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2467,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7900000214576721, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 5.136378288269043\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2468,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7900000214576721, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.286319732666016\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2469,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 5.707647323608398\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 2470\n",
      "Episode 2470,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 12, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 14.008759498596191\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2471,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 11.119913101196289\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2472,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 12, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 3.8870744705200195\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 2473\n",
      "Episode 2473,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 7.501511573791504\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2474,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 5.934757709503174\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2475,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 10.391340255737305\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2476,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 13.35734748840332\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2477,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 12.498543739318848\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2478,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.78872299194336\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2479,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 5.308145523071289\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2480,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 4.880276679992676\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2481,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 5.784538745880127\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2482,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 7.236270427703857\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2483,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 13.975099563598633\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2484,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 4.149870872497559\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2485,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 5.300198554992676\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2486,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 5.678079605102539\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2487,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 9.761761665344238\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2488,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 3.4845480918884277\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2489,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 9.289953231811523\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-300.  -100.    21.5]] not converged until episode: 2490\n",
      "Episode 2490,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 14, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 9.70386791229248\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 2491\n",
      "Episode 2491,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 8.726874351501465\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2492,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 12.275181770324707\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2493,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 8.984307289123535\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 2494\n",
      "Episode 2494,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 14, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 9.663189888000488\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2495,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 5.424935340881348\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2496,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 7.934199333190918\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2497,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 10.032573699951172\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2498,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 13.702256202697754\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2499,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 5.510659217834473\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2500,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 5.742066383361816\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2501,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 6.869974613189697\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2502,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 5.8318047523498535\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2503,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 4.770808219909668\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2504,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 11.286484718322754\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2505,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 11.214783668518066\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2506,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 11.758892059326172\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2507,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 7.312872886657715\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2508,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 8.605049133300781\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2509,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 7.741275310516357\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2510,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 10.425726890563965\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -100.    21.5]] not converged until episode: 2511\n",
      "Episode 2511,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7200000286102295, current_best action: 13, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 7.294363975524902\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2512,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 10.644828796386719\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2513,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.214714050292969\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2514,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 5.857858180999756\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2515,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 4.600719928741455\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2516,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 10.4743070602417\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2517,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 9.705999374389648\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2518,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 10.287611961364746\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2519,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 6.568380355834961\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2520,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 12.101629257202148\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2521,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7300000190734863, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 8.38096809387207\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2522,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 5.145834922790527\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2523,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7400000095367432, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 11.135103225708008\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2524,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.75, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 8.93234634399414\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2525,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 4.965604305267334\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2526,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7599999904632568, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 5.380424499511719\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2527,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 7.363485813140869\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2528,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 7.053235054016113\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2529,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 9.81534194946289\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2530,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 6.179049491882324\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2531,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7699999809265137, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 5.221381664276123\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2532,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 8.96288776397705\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2533,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7900000214576721, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 9.765002250671387\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2534,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7900000214576721, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 8.897419929504395\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2535,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7900000214576721, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 12.46173095703125\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2536,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7900000214576721, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 8.730792999267578\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2537,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.7799999713897705, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 6.113433361053467\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2538,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7900000214576721, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 9.475273132324219\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2539,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.7900000214576721, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 5.099880695343018\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2540,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.800000011920929, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 12.444465637207031\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2541,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.800000011920929, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 12.39156723022461\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2542,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.800000011920929, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 7.826724529266357\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2543,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.800000011920929, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 5.1430559158325195\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2544,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.800000011920929, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 6.45953369140625\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2545,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.800000011920929, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 7.227370262145996\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2546,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8100000023841858, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 10.561975479125977\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2547,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8199999928474426, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 12.451898574829102\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2548,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8199999928474426, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 10.400886535644531\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2549,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8199999928474426, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 9.97323989868164\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2550,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 11.839250564575195\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2551,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 8.324917793273926\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2552,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8299999833106995, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 4.2986555099487305\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2553,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8399999737739563, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 10.348066329956055\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2554,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 9.263650894165039\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2555,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8500000238418579, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 10.515166282653809\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2556,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 8.021002769470215\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2557,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 9.171152114868164\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2558,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 12.732358932495117\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2559,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 9.290881156921387\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2560,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 6.550357818603516\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2561,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 6.387467861175537\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2562,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 8.25433349609375\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2563,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 5.048835754394531\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2564,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 7.934558868408203\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2565,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 12.854867935180664\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2566,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 5.493080139160156\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2567,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 11.820544242858887\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2568,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 13.314132690429688\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2569,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 11.455652236938477\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2570,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 7.864009857177734\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2571,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 7.245144844055176\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2572,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 11.797954559326172\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2573,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 6.382195472717285\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2574,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 11.860940933227539\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2575,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 6.183389663696289\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2576,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 12.73639965057373\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2577,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 11.18562126159668\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2578,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 6.569046497344971\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2579,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 8.022546768188477\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2580,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 8.164328575134277\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2581,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 11.319368362426758\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2582,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 11.250677108764648\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2583,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 11.308889389038086\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2584,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 7.265542030334473\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2585,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 6.023268222808838\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-100.  -200.    21.5]] not converged until episode: 2586\n",
      "Episode 2586,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 10, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 4.3004961013793945\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2587,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 9.863656044006348\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2588,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 5.365194320678711\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2589,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 5.235858917236328\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2590,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 12.583294868469238\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2591,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 4.940157890319824\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2592,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 4.999202728271484\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2593,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 5.834366321563721\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2594,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 5.662386894226074\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2595,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 8.472013473510742\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2596,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 8.330574035644531\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2597,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 11.752013206481934\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2598,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 5.946890830993652\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2599,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 9.006095886230469\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2600,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 8.464244842529297\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2601,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 5.528720855712891\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2602,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 3.526721715927124\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2603,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 8.135979652404785\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2604,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 5.911011695861816\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2605,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 12.24320125579834\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2606,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 9.927877426147461\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2607,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 6.640268325805664\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 2608\n",
      "Episode 2608,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 8, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 12.39039421081543\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2609,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 12.747283935546875\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2610,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 7.0349836349487305\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2611,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 13.981952667236328\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2612,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 6.730634689331055\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2613,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 10.565446853637695\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2614,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 8.156606674194336\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2615,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 11.947025299072266\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 2616\n",
      "Episode 2616,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 6.700929164886475\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2617,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 6.058235168457031\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2618,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 7.698591232299805\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2619,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 7.025676250457764\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2620,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 7.870758056640625\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2621,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 6.05204963684082\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2622,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 8.60737419128418\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2623,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 9.419955253601074\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2624,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 6.053368091583252\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2625,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 11.591148376464844\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2626,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 8.114619255065918\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 2627\n",
      "Episode 2627,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 5.963055610656738\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2628,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 8.608917236328125\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2629,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 8.478540420532227\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2630,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 6.047268390655518\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2631,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 8.401961326599121\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2632,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 9.368680000305176\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2633,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 9.499078750610352\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2634,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 10.847267150878906\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2635,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 10.914163589477539\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2636,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 9.384302139282227\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2637,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 8.847562789916992\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2638,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 12.336909294128418\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2639,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 11.187088012695312\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2640,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 10.236681938171387\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2641,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 5.513473987579346\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2642,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.12646770477295\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 2643\n",
      "Episode 2643,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 9, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 6.793412685394287\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2644,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 11.492919921875\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2645,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 8.550186157226562\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2646,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 9.893627166748047\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2647,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.431411743164062\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2648,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 6.316019058227539\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2649,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 12.096603393554688\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2650,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 7.2865071296691895\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2651,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 8.352436065673828\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2652,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.57061767578125\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2653,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 10.818775177001953\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2654,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 10.614240646362305\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2655,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 10.279397964477539\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2656,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 9.677095413208008\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2657,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 5.717850685119629\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2658,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 7.041504383087158\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2659,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.8220796585083\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2660,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 6.048442840576172\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2661,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 5.347409725189209\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2662,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 12.089517593383789\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2663,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 11.949230194091797\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2664,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 7.882925987243652\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2665,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 11.09111499786377\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2666,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 7.820328712463379\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2667,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 9.554851531982422\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2668,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 9.456695556640625\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2669,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 11.053810119628906\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2670,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 7.033300399780273\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2671,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 5.445847511291504\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2672,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 11.18617057800293\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2673,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 10.2028226852417\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2674,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 10.874689102172852\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2675,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 9.111917495727539\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2676,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 5.255401611328125\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2677,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 9.104802131652832\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2678,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 8.277382850646973\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2679,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 12.361818313598633\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2680,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 7.620891094207764\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2681,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 8.075130462646484\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2682,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.649564743041992\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2683,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 12.225642204284668\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2684,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 10.905928611755371\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2685,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 10.82273006439209\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2686,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 11.360416412353516\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2687,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 10.7903470993042\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2688,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 9.141697883605957\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2689,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 8.777433395385742\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2690,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 11.67764663696289\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2691,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 7.965016841888428\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2692,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 10.127762794494629\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2693,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 12.465264320373535\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2694,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 11.723334312438965\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2695,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 5.4799981117248535\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2696,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 10.282780647277832\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2697,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 5.445034980773926\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2698,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 5.1851654052734375\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2699,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 7.81045389175415\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2700,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 10.582636833190918\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2701,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 8.67615032196045\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2702,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 11.716983795166016\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2703,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 8.133872985839844\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2704,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 12.42056655883789\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2705,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 5.57769775390625\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2706,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 10.950551986694336\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2707,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.179084777832031\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2708,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 11.917060852050781\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 2709\n",
      "Episode 2709,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 9.933406829833984\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2710,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 8.161121368408203\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2711,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 11.885398864746094\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2712,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 6.8249921798706055\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2713,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 11.772106170654297\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2714,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 10.322790145874023\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2715,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 8.027576446533203\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2716,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 10.58528995513916\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2717,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 6.731146812438965\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2718,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 5.670377254486084\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2719,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 12.058338165283203\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2720,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 7.535562515258789\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2721,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 12.032636642456055\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2722,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 9.59603500366211\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 2723\n",
      "Episode 2723,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 9, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 7.621988773345947\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2724,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 7.7454352378845215\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2725,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 12.597237586975098\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2726,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 9.79347038269043\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2727,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 10.915314674377441\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2728,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 12.705498695373535\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2729,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 10.036080360412598\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2730,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 11.092729568481445\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2731,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 9.16602897644043\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2732,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 9.275033950805664\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2733,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 9.501535415649414\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2734,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 10.531750679016113\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2735,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 11.98214054107666\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2736,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 5.227356910705566\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2737,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 8.326964378356934\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2738,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 5.572825908660889\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2739,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 5.59613561630249\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2740,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 8.239583969116211\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2741,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 10.84710693359375\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2742,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 11.139806747436523\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2743,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 11.811655044555664\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2744,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 5.80208683013916\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2745,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 11.138673782348633\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2746,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 4.519364356994629\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2747,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.049687385559082\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2748,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.19052505493164\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2749,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 7.8380045890808105\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2750,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 7.458172798156738\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2751,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 11.485176086425781\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2752,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 11.526643753051758\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2753,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 5.842897415161133\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2754,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 6.390356540679932\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2755,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 11.848583221435547\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2756,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 7.894207954406738\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2757,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 10.710258483886719\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2758,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 11.200807571411133\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2759,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 12.74881649017334\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2760,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 9.469606399536133\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 2761\n",
      "Episode 2761,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 8, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 9.029891014099121\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2762,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 9.721363067626953\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-300.  -200.    21.5]] not converged until episode: 2763\n",
      "Episode 2763,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 13, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 5.774523735046387\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2764,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 5.226789951324463\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2765,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 7.014213562011719\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2766,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 9.673563003540039\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2767,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 11.760424613952637\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2768,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 12.831710815429688\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2769,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 9.496538162231445\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2770,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 10.816015243530273\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2771,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 13.175241470336914\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2772,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 7.100431442260742\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2773,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 11.631786346435547\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2774,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 10.881927490234375\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2775,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 4.618188381195068\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2776,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 11.616225242614746\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2777,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 7.575189590454102\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2778,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.510534286499023\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2779,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 4.2692131996154785\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2780,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 8.280233383178711\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2781,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 5.547642707824707\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2782,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 9.866243362426758\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2783,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 13.22828483581543\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2784,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 8.003629684448242\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2785,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 5.57993221282959\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2786,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 7.103670597076416\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2787,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 8.14736557006836\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2788,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 12.235082626342773\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2789,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 9.930212020874023\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2790,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 10.22677230834961\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2791,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 11.969128608703613\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2792,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 11.30177116394043\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2793,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 11.794659614562988\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2794,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 11.618091583251953\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2795,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 10.756241798400879\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2796,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 12.662989616394043\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2797,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 12.782581329345703\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2798,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 5.230783939361572\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2799,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 7.664366722106934\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2800,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 12.891809463500977\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2801,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 10.925851821899414\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2802,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 10.97999095916748\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2803,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 7.234419822692871\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2804,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 8.744651794433594\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2805,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 11.407258987426758\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2806,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.60069465637207\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2807,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 11.075493812561035\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2808,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 10.004678726196289\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2809,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.551797866821289\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2810,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 13.519574165344238\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2811,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 11.916543960571289\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2812,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 9.730466842651367\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2813,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 11.73768424987793\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2814,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 12.598913192749023\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2815,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 12.141319274902344\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2816,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 6.05810546875\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2817,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 4.38674259185791\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2818,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 4.672450542449951\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2819,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 11.38730239868164\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2820,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 12.033045768737793\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2821,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 9.722234725952148\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2822,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 8.782262802124023\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2823,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 9.821393966674805\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2824,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 6.055504322052002\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2825,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 8.570218086242676\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2826,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 9.921372413635254\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2827,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 11.006908416748047\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2828,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 6.358987808227539\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2829,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 9.07774543762207\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2830,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 9.468109130859375\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2831,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 6.830071449279785\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2832,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 7.962253570556641\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2833,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 11.675069808959961\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2834,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 13.274128913879395\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2835,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 12.849821090698242\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2836,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 12.260391235351562\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2837,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 10.714537620544434\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2838,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 8.090396881103516\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2839,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 8.301321029663086\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2840,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 12.270971298217773\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2841,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 11.39634895324707\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2842,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.557882308959961\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2843,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 12.075326919555664\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2844,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 9.731866836547852\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2845,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.43425178527832\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2846,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 12.40129280090332\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2847,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.812312126159668\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2848,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 11.372304916381836\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2849,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 13.249532699584961\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2850,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 5.823687553405762\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2851,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 11.736139297485352\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2852,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 12.121757507324219\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2853,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 9.899200439453125\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2854,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 11.978351593017578\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2855,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 11.91009521484375\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2856,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 10.200282096862793\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2857,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 10.244409561157227\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 2858\n",
      "Episode 2858,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 7.676191329956055\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2859,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 10.709874153137207\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2860,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 6.070534706115723\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2861,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 5.704865455627441\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2862,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 13.558597564697266\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2863,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 12.48599624633789\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2864,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 13.49376106262207\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2865,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 11.941991806030273\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2866,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 11.20876693725586\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2867,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 6.120425701141357\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2868,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 10.623676300048828\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2869,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 5.775134086608887\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2870,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 10.999439239501953\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-300.  -200.    21.5]] not converged until episode: 2871\n",
      "Episode 2871,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 13, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 6.700618743896484\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2872,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 5.828944206237793\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2873,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 13.447007179260254\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2874,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 6.371699810028076\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2875,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 8.673212051391602\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2876,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 5.847928524017334\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2877,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.08681869506836\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2878,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 6.917492866516113\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-300.  -300.    21.5]] not converged until episode: 2879\n",
      "Episode 2879,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 10, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 6.772256851196289\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 2880\n",
      "Episode 2880,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 9, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 11.328338623046875\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2881,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 4.311171054840088\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2882,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 7.4306840896606445\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2883,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 11.548957824707031\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2884,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 11.721588134765625\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2885,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 6.102785587310791\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2886,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 12, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 6.786795616149902\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2887,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 8.33535099029541\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2888,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 10.206571578979492\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2889,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.103645324707031\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-300.  -300.    21.5]] not converged until episode: 2890\n",
      "Episode 2890,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 12, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 11.113983154296875\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-400.  -500.    21.5]] not converged until episode: 2891\n",
      "Episode 2891,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 11, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.608160972595215\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -400.    21.5]] not converged until episode: 2892\n",
      "Episode 2892,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 12, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 11.0633544921875\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2893,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.13735294342041\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2894,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.516728401184082\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2895,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 4.332074165344238\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2896,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.535858154296875\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2897,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 5.703853607177734\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2898,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 6.462013244628906\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2899,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 8.594778060913086\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2900,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.558619499206543\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2901,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.59837532043457\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2902,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 10.645450592041016\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2903,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.446017265319824\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 2904\n",
      "Episode 2904,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 14.341659545898438\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 2905\n",
      "Episode 2905,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.622221946716309\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2906,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 9.041399002075195\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2907,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 12.551460266113281\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2908,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 12.594690322875977\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2909,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.832809448242188\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2910,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 4.804320335388184\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2911,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.756621360778809\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2912,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 13.747501373291016\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2913,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.957040786743164\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2914,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 5.068807601928711\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2915,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.184192657470703\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2916,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 7.904796600341797\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2917,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 5.056177616119385\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2918,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.075815200805664\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2919,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 12.831323623657227\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2920,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.519643783569336\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2921,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 9.212066650390625\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2922,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 7.401134490966797\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2923,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.722825050354004\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2924,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 7.897739410400391\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2925,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 12.487565040588379\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2926,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 12.432403564453125\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2927,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 9.71965217590332\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2928,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 4.252388954162598\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2929,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 7.8046441078186035\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2930,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 13.685627937316895\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2931,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 11.79310131072998\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2932,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.979297637939453\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2933,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 9.497699737548828\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2934,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 13.822192192077637\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2935,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 8.691075325012207\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2936,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 13.814964294433594\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2937,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 13.403611183166504\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2938,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 5.624073028564453\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2939,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 8.089364051818848\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2940,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 8.399751663208008\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2941,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 11.447811126708984\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2942,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 9.156770706176758\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2943,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 13.067898750305176\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2944,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 10.850526809692383\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2945,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 9.663196563720703\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2946,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 12.207019805908203\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2947,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.516007423400879\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2948,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 13.521078109741211\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2949,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8600000143051147, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 10.654363632202148\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2950,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 10.70766830444336\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2951,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.181733131408691\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2952,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 12.543275833129883\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2953,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.153889656066895\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2954,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 12.137823104858398\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2955,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.168476104736328\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2956,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 11.075693130493164\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2957,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.57989501953125\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2958,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.456818580627441\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2959,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 12.209619522094727\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2960,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.199238777160645\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2961,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 9.718563079833984\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2962,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 11.282201766967773\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2963,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.60325813293457\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2964,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 13.35171127319336\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 2965,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 5.773684024810791\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2966,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 5.7912397384643555\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2967,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 5.286879539489746\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2968,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 12.401629447937012\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2969,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 6.755393028259277\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2970,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 13.162023544311523\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2971,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 8.19949722290039\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2972,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 7.170966148376465\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2973,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 9.357025146484375\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2974,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 9.265563011169434\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2975,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 10.323381423950195\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2976,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 10.86770248413086\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2977,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 6.485263824462891\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2978,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.412652969360352\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2979,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 3.338397741317749\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2980,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.92451286315918\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2981,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 7.0953369140625\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2982,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 13.880415916442871\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2983,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 4.859477519989014\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2984,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 6.430553436279297\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 2985,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 6.7521185874938965\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2986,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 13.87790298461914\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2987,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 13.76841926574707\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2988,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 13.830121994018555\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2989,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 13.460197448730469\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2990,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 8.036436080932617\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2991,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.247171401977539\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 2992,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 8.375932693481445\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2993,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 12.694450378417969\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 2994,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 6.81544303894043\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-300.  -200.    21.5]] not converged until episode: 2995\n",
      "Episode 2995,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 9.062793731689453\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2996,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 13.06662368774414\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 2997,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 5.725916862487793\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 2998,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.904474258422852\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 2999,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.08793830871582\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3000,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.255569458007812\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3001,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 11.24989128112793\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3002,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.126737594604492\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3003,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 6.085628509521484\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3004,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 12.102989196777344\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3005,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 12.0294828414917\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3006,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 11.129288673400879\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3007,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 6.774846076965332\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-400.  -200.    21.5]] not converged until episode: 3008\n",
      "Episode 3008,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 12, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.730697631835938\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3009,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.514689445495605\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "tx_loc:[[-200.  -100.    21.5]] not converged until episode: 3010\n",
      "Episode 3010,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 11, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 7.7699809074401855\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3011,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 11.249670028686523\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3012,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 6.182358264923096\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3013,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 12.481155395507812\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3014,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 11.961792945861816\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3015,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 6.548553943634033\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 3016\n",
      "Episode 3016,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 9, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.041139602661133\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3017,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 9.091720581054688\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3018,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 5.245685577392578\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3019,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 11.649331092834473\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3020,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 4.690354347229004\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3021,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 6.34993839263916\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3022,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.73674488067627\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3023,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 9.24380874633789\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3024,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 6.712449550628662\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3025,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 10.511995315551758\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3026,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 7.6541547775268555\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3027,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 10.001508712768555\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3028,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 4.806439399719238\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3029,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 9.155159950256348\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3030,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.27347183227539\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3031,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 10.097387313842773\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3032,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 12.473098754882812\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3033,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 11.405926704406738\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3034,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 8.18213939666748\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3035,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 13.089730262756348\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3036,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 10.446097373962402\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3037,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 7.10972785949707\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3038,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 11.712362289428711\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3039,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 7.978658676147461\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3040,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 10.84046745300293\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3041,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 6.804115295410156\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3042,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 8.780323028564453\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3043,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 8.465812683105469\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3044,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 9.407255172729492\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3045,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 9.823567390441895\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3046,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 12.869224548339844\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3047,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 12.781684875488281\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3048,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 10.227596282958984\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3049,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 6.075204849243164\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3050,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.181593894958496\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3051,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 12.753623962402344\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3052,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 12.896561622619629\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3053,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 8.105098724365234\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3054,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 6.838571071624756\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3055,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.016469955444336\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3056,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 11.579217910766602\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3057,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 10.976449966430664\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3058,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 10.541860580444336\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3059,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 9.86896800994873\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3060,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.436874389648438\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3061,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 11.747088432312012\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3062,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 10.041325569152832\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3063,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 11.146926879882812\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3064,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 6.6289753913879395\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3065,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 11.257171630859375\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3066,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 10.692709922790527\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3067,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 11.1038179397583\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3068,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 8.393989562988281\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3069,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 11.444539070129395\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3070,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 10.52742862701416\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3071,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 11.044960021972656\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3072,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 11.05644702911377\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3073,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 9.791438102722168\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3074,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 9.059083938598633\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3075,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 11.512880325317383\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3076,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 11.843770027160645\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3077,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 12.165964126586914\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3078,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 11.268183708190918\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3079,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 11.394730567932129\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3080,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 12.437995910644531\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3081,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 11.77600383758545\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3082,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 12.883650779724121\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3083,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 7.588546276092529\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3084,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 12.770633697509766\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3085,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 9.069890022277832\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3086,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 7.218074321746826\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3087,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 12.301183700561523\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3088,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 9.289834976196289\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3089,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 11.049882888793945\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3090,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 12.262344360351562\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3091,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 8.838604927062988\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3092,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 12.371849060058594\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3093,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 12.801544189453125\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3094,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.7194242477417\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-100.  -400.    21.5]] not converged until episode: 3095\n",
      "Episode 3095,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 9, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 9.2200288772583\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3096,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 10.82413101196289\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3097,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 9.900840759277344\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3098,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.514703750610352\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3099,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 11.806556701660156\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3100,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 11.717377662658691\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3101,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 12.024574279785156\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3102,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 9.54689884185791\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3103,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 8.950754165649414\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3104,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 8.939762115478516\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3105,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 9.60569953918457\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3106,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 10.598146438598633\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3107,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 11.348783493041992\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3108,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 6.2719621658325195\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3109,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 9.058197021484375\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3110,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 11.582328796386719\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3111,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 11.609256744384766\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3112,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 10.173004150390625\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3113,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 9.415800094604492\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3114,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 8.778413772583008\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3115,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 6.971719264984131\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3116,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 7.358862400054932\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3117,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 9.069175720214844\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3118,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 10.727407455444336\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 3119\n",
      "Episode 3119,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 8.065295219421387\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3120,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 13.221017837524414\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3121,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.745121002197266\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3122,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 8.733068466186523\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3123,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 12.441452980041504\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3124,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 10.704646110534668\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3125,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 11.868447303771973\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3126,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 9.092048645019531\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3127,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 13.716802597045898\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3128,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.29942512512207\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3129,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 11.896034240722656\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3130,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.274575233459473\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3131,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 11.72896957397461\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3132,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 10.856552124023438\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3133,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 12.853281021118164\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3134,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.409957885742188\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3135,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.287446975708008\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3136,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.316474914550781\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3137,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 10.754859924316406\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3138,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.554826736450195\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3139,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 6.786867141723633\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3140,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 6.558563232421875\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3141,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 12.464057922363281\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3142,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 12.784229278564453\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3143,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 11.592265129089355\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3144,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 10.235790252685547\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3145,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.395990371704102\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3146,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 11.101078987121582\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3147,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 9.569633483886719\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3148,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 12.429534912109375\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3149,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 13.38870620727539\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3150,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 12.290987014770508\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3151,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 12.624141693115234\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3152,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.821969985961914\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3153,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 5.930874824523926\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3154,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 8.665496826171875\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3155,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 12.938766479492188\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3156,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 6.95026159286499\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3157,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 12.613638877868652\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3158,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.349496841430664\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3159,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 13.964353561401367\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3160,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 5.706753730773926\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3161,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 5.727838039398193\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3162,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 8.828694343566895\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3163,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 7.223175048828125\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3164,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 11.079136848449707\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3165,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 8.448175430297852\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3166,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 13.916410446166992\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3167,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 12.740429878234863\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3168,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 12.937137603759766\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3169,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 10.9657621383667\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3170,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 10.846820831298828\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3171,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 10.85073471069336\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3172,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 5.348521709442139\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3173,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 10.795228958129883\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3174,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 10.848955154418945\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3175,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 11.09259033203125\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3176,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 11.35584831237793\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3177,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 9.454398155212402\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3178,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 10.04408073425293\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3179,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 10.041034698486328\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3180,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 12.146904945373535\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3181,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 12.149335861206055\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3182,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.561212539672852\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3183,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 8.676216125488281\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3184,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 10.99901008605957\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3185,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 13.361465454101562\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3186,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 10.005422592163086\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3187,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.898265838623047\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3188,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 7.7155609130859375\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3189,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 9.660329818725586\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3190,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 11.499187469482422\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3191,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 12.49774169921875\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3192,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 12.701770782470703\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3193,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 12.692961692810059\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3194,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 12.874217987060547\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3195,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 12.624545097351074\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3196,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 12.67176628112793\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3197,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.827982902526855\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3198,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 9.587162017822266\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3199,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 7.991852283477783\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3200,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 10.469963073730469\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3201,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 12.505483627319336\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3202,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 6.793981552124023\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3203,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.061786651611328\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3204,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 10.421815872192383\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3205,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 10.399611473083496\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3206,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 11.911310195922852\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3207,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 12.934391021728516\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3208,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 8.592121124267578\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3209,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 11.767234802246094\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3210,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 8.184524536132812\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3211,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 11.759078025817871\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3212,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 8.931012153625488\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3213,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 9.334578514099121\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3214,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 9.107839584350586\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3215,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 12.922080993652344\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3216,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 13.15152359008789\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3217,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 10.057147979736328\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3218,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 13.81944751739502\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3219,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 10.027914047241211\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3220,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 13.794502258300781\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3221,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 10.61872386932373\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3222,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 10.48135757446289\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3223,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 12.695520401000977\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3224,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 13.93571662902832\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3225,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 11.546001434326172\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3226,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 13.020639419555664\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3227,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 11.88955307006836\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3228,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 8.642009735107422\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3229,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 6.863460540771484\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3230,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.378425598144531\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3231,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.476876258850098\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3232,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 13.019521713256836\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3233,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 10.604620933532715\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3234,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.695854187011719\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3235,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.516698837280273\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3236,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 12.87221908569336\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3237,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 12.985501289367676\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3238,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.380825996398926\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3239,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 13.007452011108398\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3240,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 8.589406967163086\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3241,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.830911636352539\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3242,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 12.742890357971191\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3243,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.526955604553223\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3244,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 9.135345458984375\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3245,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.098138809204102\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3246,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.717550277709961\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3247,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.092376708984375\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3248,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.308089256286621\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3249,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.41219425201416\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3250,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.41707992553711\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3251,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 9.289979934692383\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3252,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 8.631023406982422\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3253,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 13.22010612487793\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3254,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.443585395812988\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3255,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 9.574642181396484\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3256,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 9.579797744750977\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3257,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.306435585021973\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3258,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.572736740112305\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3259,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 10.697566986083984\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3260,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 10.378419876098633\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3261,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 9.081737518310547\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3262,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 10.037474632263184\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3263,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 10.245723724365234\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3264,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 13.24305534362793\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3265,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 10.460498809814453\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3266,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 10.738640785217285\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3267,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 10.608431816101074\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3268,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.38209342956543\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3269,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.356438636779785\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3270,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 11.478620529174805\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3271,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 13.169944763183594\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3272,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 13.971851348876953\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3273,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 13.965514183044434\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3274,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 13.181665420532227\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3275,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 9.728835105895996\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3276,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 11.043327331542969\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3277,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 13.603845596313477\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3278,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 11.340376853942871\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3279,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 12.764459609985352\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3280,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 11.485234260559082\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3281,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 12.806008338928223\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3282,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 9.636781692504883\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3283,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 13.654458045959473\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3284,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 11.839869499206543\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3285,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 12.836301803588867\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3286,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 7.979145050048828\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3287,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 13.344738006591797\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3288,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 9.901525497436523\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3289,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 13.620084762573242\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3290,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.818150520324707\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3291,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.289813995361328\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3292,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 12.273246765136719\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3293,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.547147750854492\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3294,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.17451286315918\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3295,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.038345336914062\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3296,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.882722854614258\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3297,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 12.560466766357422\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3298,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 12.552396774291992\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3299,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 12.953758239746094\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3300,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 7.728191375732422\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3301,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.397491455078125\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3302,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 12.447025299072266\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3303,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.09421157836914\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3304,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 12.798068046569824\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3305,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 6.601602554321289\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3306,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 9.277715682983398\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3307,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.689391136169434\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3308,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 8.924488067626953\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3309,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.576254844665527\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3310,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 12.965875625610352\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3311,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 11.845917701721191\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3312,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 10.804488182067871\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3313,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 13.716683387756348\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3314,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 8.871170043945312\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3315,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 11.216057777404785\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3316,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.042352676391602\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3317,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 8.950934410095215\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3318,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 12.958517074584961\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3319,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.247810363769531\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3320,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 11.173583984375\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3321,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 12.31795883178711\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3322,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 11.34791374206543\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3323,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.64075756072998\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3324,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 12.740245819091797\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3325,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 13.314126014709473\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3326,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 12.711055755615234\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3327,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 10.631519317626953\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3328,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 4.63868522644043\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3329,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 11.790252685546875\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3330,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.905052185058594\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3331,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 12.602084159851074\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3332,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 10.933859825134277\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3333,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 9.888144493103027\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3334,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 12.390850067138672\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3335,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 10.29640007019043\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3336,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 11.058056831359863\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3337,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 12.936311721801758\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3338,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 11.186029434204102\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3339,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 11.431109428405762\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3340,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 9.181024551391602\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3341,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.1788911819458\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3342,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 13.097281455993652\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3343,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 7.417304039001465\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3344,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 8.068612098693848\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3345,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 7.2856245040893555\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3346,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.049100875854492\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3347,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 13.97750473022461\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3348,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 8.977986335754395\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3349,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 12.65507698059082\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3350,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 12.600849151611328\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3351,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 12.675816535949707\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3352,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.205827713012695\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3353,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.094427108764648\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3354,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 13.253866195678711\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3355,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 13.35403823852539\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3356,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.858671188354492\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3357,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 5.25447940826416\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3358,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 5.989626407623291\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3359,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.873676300048828\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3360,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 11.138261795043945\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3361,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 11.9091796875\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3362,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.077754020690918\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3363,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.981980323791504\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3364,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.237459182739258\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3365,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 10.397538185119629\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3366,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 13.831364631652832\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3367,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 11.990703582763672\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3368,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 13.859601020812988\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3369,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 12.778925895690918\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3370,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 11.540731430053711\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3371,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 11.559066772460938\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3372,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 11.615472793579102\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3373,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.845134735107422\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3374,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 11.057703018188477\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3375,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 8.867666244506836\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3376,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.540778160095215\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3377,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 11.896981239318848\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3378,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 12.277450561523438\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3379,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 13.167424201965332\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3380,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 12.862907409667969\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3381,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 13.551774024963379\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3382,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 13.342328071594238\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3383,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 8.429828643798828\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3384,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.280601501464844\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3385,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 11.70222282409668\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3386,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 9.132162094116211\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3387,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.256087303161621\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3388,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.166131973266602\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3389,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 10.870288848876953\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3390,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 8.831974029541016\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3391,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 13.332813262939453\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3392,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 9.891695022583008\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3393,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 5.552611827850342\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3394,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 13.975828170776367\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3395,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 9.779291152954102\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3396,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 11.86650562286377\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3397,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 6.312789440155029\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3398,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 13, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 4.470351696014404\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3399,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.076269149780273\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-300.  -200.    21.5]] not converged until episode: 3400\n",
      "Episode 3400,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 13, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 7.635710716247559\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3401,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 10.914567947387695\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3402,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.143442153930664\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3403,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 5.5297770500183105\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3404,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 11.55002212524414\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3405,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.16236686706543\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3406,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 5.596170425415039\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3407,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 6.862130641937256\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3408,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 11.9275541305542\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3409,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 10.200359344482422\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3410,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.373296737670898\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3411,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 9.918159484863281\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3412,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.115724563598633\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3413,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 13.310927391052246\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3414,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 11.461057662963867\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3415,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 12.90120792388916\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3416,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 11.93182373046875\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3417,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.05058479309082\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3418,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 10.96054458618164\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3419,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.195399284362793\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3420,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 14.12126636505127\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3421,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.281444549560547\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3422,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 11.825641632080078\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3423,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 8.532447814941406\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3424,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 13.112394332885742\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3425,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 9.930020332336426\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3426,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 9.023748397827148\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3427,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 10.118474006652832\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3428,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.665680885314941\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "tx_loc:[[-200.  -100.    21.5]] not converged until episode: 3429\n",
      "Episode 3429,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 12, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 6.045984268188477\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3430,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 12.806051254272461\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3431,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 11.783452987670898\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3432,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 8.664464950561523\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3433,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.299829483032227\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3434,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 12.099319458007812\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3435,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 8.908116340637207\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3436,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 12.09907341003418\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3437,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 6.558143615722656\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3438,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 12.964154243469238\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3439,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.411317825317383\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3440,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 10.677337646484375\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3441,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.484228134155273\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3442,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 12.892295837402344\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3443,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 11.635924339294434\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3444,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 5.8700947761535645\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3445,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 11.319540023803711\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3446,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 4.839230060577393\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3447,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 10.663564682006836\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "tx_loc:[[-500.  -200.    21.5]] not converged until episode: 3448\n",
      "Episode 3448,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 14, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 12.65876579284668\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3449,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.0982084274292\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3450,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 6.631153583526611\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3451,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 12.74118709564209\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3452,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.030927658081055\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3453,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.339661598205566\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3454,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 4.269984722137451\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3455,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 5.547995567321777\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3456,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 3.988339424133301\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3457,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 13.062763214111328\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 3458\n",
      "Episode 3458,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 14.889139175415039\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3459,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 9.99134635925293\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3460,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 7.0516462326049805\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3461,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 4.691980361938477\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3462,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.046722412109375\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3463,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 12.854129791259766\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3464,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 6.644515514373779\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3465,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 8.278406143188477\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3466,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 12.920646667480469\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3467,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 4.798624038696289\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3468,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.353906631469727\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3469,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.577296257019043\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3470,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.835678100585938\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3471,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.721474647521973\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3472,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 9.144819259643555\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3473,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 4.481412410736084\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3474,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 9.307374954223633\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3475,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 8.742067337036133\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3476,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 11.967369079589844\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3477,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 13.199849128723145\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3478,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 5.2928056716918945\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3479,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.244915962219238\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3480,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.02842903137207\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3481,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 9.08188247680664\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3482,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.231917381286621\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3483,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 6.741104602813721\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3484,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.025491714477539\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-400.  -100.    21.5]] not converged until episode: 3485\n",
      "Episode 3485,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 13, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 9.919095993041992\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3486,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 5.933163642883301\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3487,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 11.877603530883789\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3488,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.875004768371582\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "tx_loc:[[-200.  -300.    21.5]] not converged until episode: 3489\n",
      "Episode 3489,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 9, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.330718994140625\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3490,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 10.278905868530273\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3491,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 12.813192367553711\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3492,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 11.734945297241211\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3493,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 13.095389366149902\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3494,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 13.082435607910156\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3495,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.526177406311035\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3496,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 7.9518537521362305\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3497,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 4.809776306152344\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3498,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.023282051086426\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3499,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 8.370100021362305\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3500,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 13.477916717529297\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3501,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 8.230810165405273\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3502,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 9.677864074707031\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "tx_loc:[[-500.  -300.    21.5]] not converged until episode: 3503\n",
      "Episode 3503,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 13, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.348642349243164\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3504,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.228557586669922\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3505,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 13.492406845092773\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3506,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 6.673423767089844\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3507,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.814187049865723\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3508,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 4.678771018981934\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3509,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 12.184406280517578\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3510,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.986940383911133\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3511,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 10.341520309448242\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3512,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 12.447869300842285\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3513,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 6.103963851928711\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3514,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.620155334472656\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3515,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 14.22136116027832\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-200.  -500.    21.5]] not converged until episode: 3516\n",
      "Episode 3516,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 8, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 9.433679580688477\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3517,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.11141586303711\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3518,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.388886451721191\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3519,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 10.235038757324219\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3520,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 13.498510360717773\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3521,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 8.779842376708984\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3522,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 10.502312660217285\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3523,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.036957740783691\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3524,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 7.153487682342529\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "tx_loc:[[-200.  -400.    21.5]] not converged until episode: 3525\n",
      "Episode 3525,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 10, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.443126678466797\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3526,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.670389175415039\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3527,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 12.081615447998047\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3528,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.621232032775879\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3529,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.611836433410645\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3530,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 13.947036743164062\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3531,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 6.611351013183594\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3532,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 13.123221397399902\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3533,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.477951049804688\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3534,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 11.423559188842773\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3535,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 8.582677841186523\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3536,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8700000047683716, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.300353050231934\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3537,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 9, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 4.339087963104248\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3538,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 10.253628730773926\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3539,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 11.399715423583984\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3540,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 4.203311920166016\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3541,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 12.122879028320312\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3542,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.254680633544922\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3543,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 9.122444152832031\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3544,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 11.833771705627441\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3545,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 12.917957305908203\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3546,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 12.952632904052734\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3547,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8799999952316284, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 8.747060775756836\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3548,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 8.095033645629883\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3549,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8899999856948853, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.452537536621094\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3550,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.662277221679688\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3551,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.230175971984863\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3552,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 9.958581924438477\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3553,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.850407600402832\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3554,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.8999999761581421, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.510501861572266\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3555,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 6.302135467529297\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3556,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 11.757963180541992\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3557,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9100000262260437, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 7.1018195152282715\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3558,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 14.096282958984375\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3559,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 7.957928657531738\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3560,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.075691223144531\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3561,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 11.00981330871582\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3562,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 5.740626811981201\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3563,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.980563163757324\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3564,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.72846794128418\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3565,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.932123184204102\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3566,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 12.757073402404785\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3567,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 11.398185729980469\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3568,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.859611511230469\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3569,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 9.661895751953125\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3570,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 11.873617172241211\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3571,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 12.883443832397461\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3572,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 13.189315795898438\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3573,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9200000166893005, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.976175308227539\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3574,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.641845703125\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3575,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 11.025115013122559\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3576,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 12.910930633544922\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3577,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 10.935541152954102\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3578,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 13.583699226379395\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3579,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 11.759739875793457\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3580,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 13.437056541442871\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3581,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 11.937263488769531\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3582,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 9.374624252319336\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3583,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 11.133305549621582\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3584,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9300000071525574, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.455768585205078\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3585,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 5.265138626098633\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3586,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 11.894891738891602\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3587,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 10.025710105895996\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3588,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9399999976158142, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 12.744436264038086\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3589,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 11.63252067565918\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3590,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 11.663180351257324\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3591,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.513395309448242\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3592,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 12.241922378540039\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3593,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.339022636413574\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3594,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 12.831535339355469\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3595,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.305448532104492\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3596,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.054254531860352\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3597,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 8.664665222167969\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3598,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 6.346968650817871\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3599,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.177139282226562\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3600,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.949999988079071, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 12.773126602172852\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3601,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 12.459890365600586\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3602,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9599999785423279, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.014204025268555\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3603,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.29815673828125\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3604,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.20751953125\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3605,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.167252540588379\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3606,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 9.212310791015625\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3607,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 7.250094413757324\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3608,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.743898391723633\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3609,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.40928840637207\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3610,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 13.457907676696777\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3611,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 8.767873764038086\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3612,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 13.196975708007812\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3613,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 12.583784103393555\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3614,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 7.5739641189575195\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3615,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9700000286102295, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 13.176210403442383\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3616,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 11.527021408081055\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3617,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 13.674107551574707\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3618,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 12.139610290527344\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3619,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 12.695043563842773\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3620,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 10.05463981628418\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3621,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 10.352463722229004\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3622,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 13.946474075317383\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3623,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 9.905285835266113\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3624,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 9.942804336547852\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3625,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 10.898277282714844\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3626,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 9.531806945800781\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3627,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.973417282104492\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3628,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 13.993329048156738\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3629,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 8.41547966003418\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3630,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 9.12016487121582\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3631,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 11.984115600585938\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3632,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 11.969710350036621\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3633,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 11.48617172241211\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3634,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.168861389160156\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3635,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 13.526487350463867\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3636,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 13.491072654724121\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3637,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.094762802124023\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3638,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 9.586409568786621\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3639,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 9.122152328491211\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3640,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 13.551430702209473\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3641,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 12.153953552246094\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3642,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 9.52200698852539\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3643,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.472103118896484\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3644,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.151449203491211\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3645,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 7.585231781005859\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3646,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.507286071777344\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3647,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.74450969696045\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3648,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.239648818969727\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3649,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 13.795022964477539\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3650,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.556413650512695\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3651,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.98945426940918\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3652,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 11.035928726196289\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3653,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 12.981452941894531\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3654,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 11.61611557006836\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3655,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 9.496892929077148\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3656,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 10.091297149658203\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3657,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 10.13800048828125\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3658,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 10.857666015625\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3659,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.975481986999512\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3660,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.84136962890625\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3661,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.056818008422852\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3662,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 9.211446762084961\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3663,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.698260307312012\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3664,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 10.35140609741211\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3665,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 12.715279579162598\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3666,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 10.32250690460205\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3667,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 10.383394241333008\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3668,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.659015655517578\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3669,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 10.516681671142578\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3670,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.018375396728516\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3671,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.835651397705078\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3672,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 9.524105072021484\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3673,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 10.327220916748047\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3674,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 6.330293655395508\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3675,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.669550895690918\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3676,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.649215698242188\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3677,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.699066162109375\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3678,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 12.41231918334961\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3679,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 8.581521987915039\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3680,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 12.458113670349121\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3681,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 13.998350143432617\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3682,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 10.559528350830078\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3683,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 9.162749290466309\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3684,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.855008125305176\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3685,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 12.564983367919922\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3686,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 13.034563064575195\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3687,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.943763732910156\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3688,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 10.587267875671387\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3689,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 12.121798515319824\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3690,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.032857894897461\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3691,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.085519790649414\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3692,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 8.653514862060547\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3693,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.791337966918945\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3694,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.135223388671875\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3695,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 11.512471199035645\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3696,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 13.641170501708984\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3697,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 9.963253021240234\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3698,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.530984878540039\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3699,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.925912857055664\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3700,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 13.481101989746094\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3701,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.404281616210938\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3702,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 11.624794960021973\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3703,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.846698760986328\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3704,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 5.41010046005249\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3705,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.462736129760742\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3706,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 13.942582130432129\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3707,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 11.822922706604004\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3708,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 8.200481414794922\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3709,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 10.445124626159668\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3710,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 10.431807518005371\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3711,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 10.10590934753418\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3712,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 10.824243545532227\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3713,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.373055458068848\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3714,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 10.864940643310547\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3715,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.052871704101562\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3716,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.06521224975586\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3717,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 8.042398452758789\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3718,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 8.164800643920898\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3719,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 11.517271995544434\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3720,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.930776596069336\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3721,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.820889472961426\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3722,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.847444534301758\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3723,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.041830062866211\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3724,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 10.940135955810547\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3725,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.750955581665039\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3726,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.13200569152832\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3727,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 10.895611763000488\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3728,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 8.398595809936523\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3729,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.139822006225586\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3730,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 11.71352767944336\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3731,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 11.031651496887207\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3732,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 13.62729549407959\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3733,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 13.310201644897461\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3734,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 8.998775482177734\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3735,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 9.208881378173828\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3736,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 11.372716903686523\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3737,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.306741714477539\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3738,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.105387687683105\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3739,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.736077308654785\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3740,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.106847763061523\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3741,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 10.643356323242188\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3742,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 13.950468063354492\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3743,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 12.530617713928223\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3744,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 11.28515625\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3745,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.253364562988281\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3746,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 11.290946006774902\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3747,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.238260269165039\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3748,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 10.885717391967773\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3749,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 11.317455291748047\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3750,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 10.967329025268555\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3751,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.695435523986816\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3752,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 13.465370178222656\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3753,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 11.901344299316406\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3754,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 13.982858657836914\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3755,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 10.308338165283203\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3756,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 10.56126880645752\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3757,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.364612579345703\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3758,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 13.500720024108887\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3759,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.234861373901367\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3760,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 13.516075134277344\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3761,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.416023254394531\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3762,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.959732055664062\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3763,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 13.847711563110352\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3764,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 12.130942344665527\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3765,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.289728164672852\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3766,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.252217292785645\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3767,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 9.946075439453125\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3768,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 9.64920425415039\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3769,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 11.4616060256958\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3770,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 9.900879859924316\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3771,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 9.005863189697266\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3772,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.087008476257324\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3773,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 9.89946460723877\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3774,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 11.853729248046875\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3775,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 12.356939315795898\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3776,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.777117729187012\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3777,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 11.585737228393555\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3778,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 11.042681694030762\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3779,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 11.692595481872559\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3780,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.262823104858398\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3781,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 12.178157806396484\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3782,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 10.382097244262695\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3783,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 10.56812858581543\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3784,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.27564811706543\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3785,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.328469276428223\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3786,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 11.865129470825195\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3787,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.65257453918457\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3788,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.064126968383789\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3789,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 10.445852279663086\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3790,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.595840454101562\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3791,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 13.387654304504395\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3792,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 12.372356414794922\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3793,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 8.243099212646484\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3794,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 13.84084701538086\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3795,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 13.754663467407227\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3796,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.616776466369629\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3797,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.84273910522461\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3798,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 8.758198738098145\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3799,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.047098159790039\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3800,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.050291061401367\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3801,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.430912017822266\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3802,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 12.733770370483398\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3803,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.675148010253906\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3804,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.486084938049316\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3805,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 11.19639778137207\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3806,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.646343231201172\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3807,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.504304885864258\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3808,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 11.093626022338867\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3809,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 11.177119255065918\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3810,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 11.308042526245117\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3811,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.052241325378418\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3812,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 11.378201484680176\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3813,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.220186233520508\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3814,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.299736022949219\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3815,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 11.617384910583496\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3816,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 13.670902252197266\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3817,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.486210823059082\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3818,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.170005798339844\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3819,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 9.721689224243164\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3820,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 9.772208213806152\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3821,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 10.760421752929688\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3822,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 11.522956848144531\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3823,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 8.651729583740234\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3824,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.09050178527832\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3825,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 12.085317611694336\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3826,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.224662780761719\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3827,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.151702880859375\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3828,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 11.563036918640137\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3829,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 11.704339981079102\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3830,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.166821479797363\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3831,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.764141082763672\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3832,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.153837203979492\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3833,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 12.621315956115723\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3834,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.153575897216797\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3835,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.184154510498047\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3836,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.250813484191895\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3837,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 13.712579727172852\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3838,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.721207618713379\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3839,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.232955932617188\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3840,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 11.856010437011719\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3841,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.35890007019043\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3842,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.530191421508789\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3843,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 11.636341094970703\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3844,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.667047500610352\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3845,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.137202262878418\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3846,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 9.973420143127441\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3847,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 11.451862335205078\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3848,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 10.750347137451172\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3849,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 11.740660667419434\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3850,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.14442253112793\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3851,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 11.72220230102539\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3852,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.989192008972168\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3853,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.649465560913086\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3854,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.077799797058105\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3855,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.142814636230469\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3856,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.723928451538086\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3857,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 10.11899185180664\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3858,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.441509246826172\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3859,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 11.90570068359375\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3860,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 11.222042083740234\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3861,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.534714698791504\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3862,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 12.160423278808594\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3863,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.096819877624512\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3864,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.952625274658203\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3865,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 11.754233360290527\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3866,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 11.811948776245117\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3867,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 10.16630744934082\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3868,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.944082260131836\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3869,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.699636459350586\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3870,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.452041625976562\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3871,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 11.10865592956543\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3872,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 13.901622772216797\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3873,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 11.89555835723877\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3874,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.808266639709473\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3875,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 10.569283485412598\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3876,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 13.372761726379395\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3877,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.0182466506958\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3878,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 10.74365234375\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3879,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.17467212677002\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3880,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.36455249786377\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3881,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.239238739013672\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3882,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.855945587158203\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3883,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.168654441833496\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3884,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.105123519897461\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3885,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.657957077026367\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3886,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.842188835144043\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3887,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.670185089111328\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3888,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.977436065673828\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3889,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 13.697134971618652\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3890,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 9.881274223327637\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3891,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 10.161298751831055\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3892,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 10.769678115844727\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3893,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 10.164321899414062\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3894,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.858846664428711\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3895,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.783055305480957\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3896,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.587876319885254\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3897,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.32063102722168\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3898,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.07834529876709\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3899,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 11.380242347717285\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3900,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 8.577869415283203\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3901,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.800948143005371\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3902,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 11.071725845336914\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3903,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.10804557800293\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3904,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.252838134765625\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3905,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 9.768278121948242\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3906,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 11.396005630493164\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3907,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 11.085281372070312\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3908,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.202856063842773\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3909,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 11.15414810180664\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3910,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.513757705688477\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3911,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.154064178466797\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3912,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.176360130310059\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3913,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 11.458578109741211\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3914,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 11.758708000183105\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3915,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 8.779817581176758\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3916,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.587285995483398\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3917,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 12.78465461730957\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3918,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.402499198913574\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3919,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 11.961336135864258\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3920,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.737903594970703\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3921,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.103036880493164\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3922,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.357234954833984\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3923,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.254343032836914\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3924,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 10.691292762756348\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3925,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 11.704127311706543\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3926,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 10.803482055664062\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3927,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.69464111328125\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3928,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 12.814868927001953\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3929,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.15652084350586\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3930,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.702521324157715\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3931,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.684365272521973\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3932,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 10.969318389892578\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3933,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.208285331726074\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3934,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.02902603149414\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3935,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 12.656628608703613\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3936,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.231351852416992\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3937,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 13.987808227539062\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3938,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.243539810180664\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3939,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.23870849609375\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3940,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.336408615112305\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3941,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 13.81539535522461\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3942,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.088512420654297\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3943,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.023445129394531\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3944,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 11.165781021118164\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3945,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.3518705368042\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3946,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.110921859741211\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3947,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.243480682373047\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3948,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 9.085160255432129\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3949,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.581426620483398\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3950,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.774117469787598\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3951,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.508123397827148\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3952,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.460410118103027\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3953,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 10.542872428894043\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3954,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.135354995727539\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3955,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.192436218261719\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3956,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 12.519074440002441\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3957,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 10.81252384185791\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3958,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 11.478832244873047\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3959,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.08588695526123\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3960,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.980627059936523\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3961,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 11.63786506652832\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3962,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.301763534545898\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3963,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 11.769585609436035\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3964,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 11.087379455566406\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3965,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.307791709899902\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3966,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 9.530839920043945\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3967,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.901473999023438\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3968,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 10.087753295898438\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3969,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 12.242348670959473\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3970,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.444145202636719\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3971,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.015152931213379\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3972,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 12.23944091796875\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3973,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.559488296508789\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3974,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 11.813726425170898\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3975,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.54697322845459\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3976,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.07571029663086\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3977,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.672935485839844\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3978,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.527515411376953\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3979,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 9.527441024780273\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3980,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 11.6669340133667\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3981,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.725353240966797\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3982,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.328439712524414\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3983,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 12.298320770263672\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3984,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.755217552185059\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3985,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.446470260620117\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3986,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 10.521949768066406\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3987,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 12.355234146118164\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 3988,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 11.806205749511719\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3989,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 10.231950759887695\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3990,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 10.529287338256836\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 3991,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 11.158946990966797\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3992,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.364286422729492\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 3993,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.448042869567871\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 3994,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.52235221862793\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 3995,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 11.875579833984375\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3996,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.839481353759766\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3997,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 12.89695930480957\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 3998,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 12.047075271606445\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 3999,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.084420204162598\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4000,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 12.713655471801758\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4001,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.043203353881836\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4002,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 12.981891632080078\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4003,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 9.842550277709961\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4004,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 10.517980575561523\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4005,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 14.240455627441406\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4006,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 12.753305435180664\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4007,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.799570083618164\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4008,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 11.60670280456543\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4009,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 11.928302764892578\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4010,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.369564056396484\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4011,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.685973167419434\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4012,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.442781448364258\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4013,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.422183990478516\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4014,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.137660026550293\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4015,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 13.427051544189453\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4016,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.728832244873047\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4017,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.461283683776855\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4018,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.289676666259766\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4019,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 11.354229927062988\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4020,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 11.522544860839844\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4021,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.971590042114258\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4022,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 12.86503791809082\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4023,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 8.02856159210205\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4024,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 5.489777565002441\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4025,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.456539154052734\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4026,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 11.20753288269043\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4027,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.81685733795166\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4028,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.478696823120117\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4029,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.52017593383789\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4030,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.357494354248047\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4031,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 11.890241622924805\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4032,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 11.412580490112305\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4033,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 12.926145553588867\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4034,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 11.161542892456055\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4035,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.146820068359375\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4036,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.557649612426758\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4037,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.489275932312012\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4038,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 13.751724243164062\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4039,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 11.430371284484863\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4040,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.236690521240234\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4041,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 12.887548446655273\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4042,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.021102905273438\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4043,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.465814590454102\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4044,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 14.084895133972168\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4045,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 6.057966232299805\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4046,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 7.531683921813965\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4047,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 11.997085571289062\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4048,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 11.135662078857422\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4049,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.827535629272461\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4050,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.43358039855957\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4051,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.049596786499023\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4052,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.887439727783203\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4053,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 13.909988403320312\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4054,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 10.191068649291992\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4055,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.612543106079102\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4056,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 12.265243530273438\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4057,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 12.941362380981445\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4058,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 9.133550643920898\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4059,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 11.583824157714844\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4060,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.572696685791016\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4061,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 11.59229850769043\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4062,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 10.992460250854492\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4063,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.426519393920898\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4064,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 8.386106491088867\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4065,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.749077796936035\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4066,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.009308815002441\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4067,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 10.150004386901855\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4068,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.659674644470215\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4069,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.298465728759766\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4070,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.864452362060547\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4071,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 6.123130798339844\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4072,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 12.897476196289062\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4073,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 10.30998706817627\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4074,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 13.916082382202148\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4075,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 11.63956069946289\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "tx_loc:[[-100.  -300.    21.5]] not converged until episode: 4076\n",
      "Episode 4076,\tScore: 0.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 8, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.792960166931152\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4077,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 13.852770805358887\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4078,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.839685440063477\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4079,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.602062225341797\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4080,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.147102355957031\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4081,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 14.44660758972168\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4082,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.131881713867188\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4083,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.722735404968262\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4084,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.637235641479492\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4085,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 13.446009635925293\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4086,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 4.947885513305664\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4087,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 12.295912742614746\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4088,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.270416259765625\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4089,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 9.822359085083008\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4090,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.284643173217773\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4091,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 7.696984767913818\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4092,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 8.676725387573242\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4093,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.538949966430664\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4094,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 10.715030670166016\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4095,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 12.505058288574219\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4096,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 8.799532890319824\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4097,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.882488250732422\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4098,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 13.80843734741211\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4099,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 11.968317031860352\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4100,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 5.223627090454102\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4101,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.408872604370117\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4102,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.227858543395996\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4103,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 10.617128372192383\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4104,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 12.95302677154541\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4105,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 10.708444595336914\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4106,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.59799861907959\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4107,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.369019508361816\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4108,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 9.569097518920898\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4109,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.417841911315918\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4110,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.684956550598145\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4111,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.861980438232422\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4112,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.228673934936523\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4113,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.013636589050293\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4114,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.04165267944336\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4115,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 13.801467895507812\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4116,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.144622802734375\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4117,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.456363677978516\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4118,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.391748428344727\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4119,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 10.614653587341309\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4120,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 8.172101974487305\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4121,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.97220230102539\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4122,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.34025764465332\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4123,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 13.831127166748047\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4124,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.242737770080566\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4125,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.927852630615234\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4126,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 10.46037769317627\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4127,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.137617111206055\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4128,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.41659927368164\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4129,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.091757774353027\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4130,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.420188903808594\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4131,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.016145706176758\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4132,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 13.996528625488281\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4133,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.503321647644043\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4134,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 11.72213363647461\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4135,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.493021011352539\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4136,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.271970748901367\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4137,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 11.050691604614258\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4138,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.924068450927734\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4139,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.556205749511719\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4140,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.348396301269531\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4141,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 11.419258117675781\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4142,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.393871307373047\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4143,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 13.941461563110352\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4144,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.99018669128418\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4145,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 10.924629211425781\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4146,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.416061401367188\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4147,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 11.596094131469727\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4148,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 11.791728973388672\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4149,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.990551948547363\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4150,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.630264282226562\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4151,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 11.65135669708252\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4152,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 9.913324356079102\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4153,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 10.287673950195312\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4154,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.02204418182373\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4155,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 10.775371551513672\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4156,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.213973999023438\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4157,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 11.513139724731445\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4158,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.156534194946289\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4159,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 11.42121696472168\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4160,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 12.725496292114258\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4161,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.919050216674805\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4162,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.082592010498047\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4163,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9800000190734863, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 11.355571746826172\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4164,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 12.794754028320312\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4165,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.4971342086792\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4166,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 11.864891052246094\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4167,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.327407836914062\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4168,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.313855171203613\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4169,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.383098602294922\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4170,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.48935317993164\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4171,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.531803131103516\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4172,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 12.863142967224121\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4173,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.241897583007812\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4174,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 12.89052963256836\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4175,\tScore: 1.00, eps: 0.5, moving avg_rwd: 0.9900000095367432, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 11.680818557739258\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4176,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 9.8385009765625\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4177,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.101401329040527\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4178,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 13.776408195495605\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4179,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 10.793020248413086\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4180,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.257454872131348\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4181,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 9.911795616149902\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4182,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 13.905845642089844\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4183,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 12.98715591430664\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4184,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.300501823425293\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4185,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.292470932006836\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4186,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.615130424499512\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4187,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 11.544352531433105\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4188,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 10.261972427368164\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4189,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.330012321472168\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4190,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 12.178060531616211\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4191,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.403703689575195\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4192,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.648587226867676\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4193,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.315715789794922\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4194,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.396031379699707\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4195,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 12.717727661132812\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4196,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.650675773620605\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4197,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.356768608093262\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4198,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.580121994018555\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4199,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.250039100646973\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4200,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.616472244262695\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4201,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.046119689941406\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4202,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.182883262634277\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4203,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.268596649169922\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4204,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.719682693481445\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4205,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.930486679077148\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4206,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.474212646484375\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4207,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.08049201965332\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4208,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.323183059692383\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4209,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.727333068847656\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4210,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.243810653686523\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4211,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 10.599574089050293\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4212,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.06800651550293\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4213,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.752843856811523\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4214,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 12.35455322265625\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4215,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.550661087036133\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4216,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.10483169555664\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4217,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.639871597290039\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4218,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 12.563380241394043\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4219,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 10.420541763305664\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4220,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.198758125305176\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4221,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.235690116882324\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4222,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.059439659118652\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4223,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 11.215641021728516\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4224,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 11.786396980285645\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4225,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 11.847766876220703\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4226,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.495049476623535\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4227,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.791044235229492\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4228,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.468561172485352\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4229,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.661043167114258\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4230,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.377697944641113\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4231,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.514274597167969\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4232,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.828010559082031\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4233,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.026296615600586\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4234,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 10.982399940490723\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4235,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.078529357910156\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4236,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.051346778869629\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4237,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 10.035037994384766\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4238,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 11.61494255065918\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4239,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.328564643859863\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4240,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.557313919067383\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4241,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 11.228053092956543\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4242,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.349737167358398\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4243,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.68447494506836\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4244,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.009499549865723\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4245,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.33624267578125\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4246,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.02371597290039\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4247,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 12.593013763427734\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4248,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 12.632268905639648\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4249,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.520933151245117\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4250,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.121646881103516\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4251,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 11.932520866394043\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4252,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.316228866577148\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4253,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 11.838638305664062\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4254,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 11.865845680236816\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4255,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.506158828735352\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4256,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.20417594909668\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4257,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.037290573120117\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4258,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 13.972087860107422\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4259,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.902921676635742\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4260,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.329483985900879\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4261,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.26107120513916\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4262,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.49127197265625\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4263,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.315099716186523\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4264,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 12.109600067138672\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4265,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 12.110240936279297\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4266,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.314016342163086\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4267,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.86457347869873\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4268,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.857587814331055\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4269,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.909143447875977\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4270,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 12.28103256225586\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4271,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.840648651123047\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4272,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.120199203491211\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4273,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.819509506225586\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4274,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.983497619628906\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4275,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.309097290039062\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4276,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 12.211134910583496\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4277,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 11.370306968688965\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4278,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.224193572998047\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4279,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.52914810180664\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4280,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 12.421634674072266\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4281,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.221516609191895\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4282,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.121326446533203\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4283,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.524603843688965\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4284,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.561330795288086\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4285,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.132566452026367\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4286,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.47719955444336\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4287,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.335870742797852\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4288,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.732067108154297\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4289,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.04214859008789\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4290,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.726114273071289\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4291,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 11.161871910095215\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4292,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.320684432983398\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4293,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 11.923955917358398\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4294,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.610352516174316\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4295,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.608841896057129\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4296,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.459403038024902\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4297,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.210653305053711\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4298,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.03407096862793\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4299,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.332723617553711\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4300,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.454019546508789\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4301,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.88880729675293\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4302,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.066083908081055\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4303,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.420435905456543\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4304,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.785978317260742\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4305,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.186763763427734\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4306,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.328864097595215\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4307,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.296957015991211\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4308,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.181303024291992\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4309,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.025005340576172\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4310,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.44796085357666\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4311,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.364551544189453\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4312,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.998189926147461\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4313,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.626721382141113\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4314,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.290043830871582\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4315,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.692981719970703\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4316,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.315998077392578\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4317,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.995737075805664\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4318,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.443533897399902\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4319,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.004634857177734\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4320,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.444866180419922\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4321,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.049928665161133\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4322,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 13.93109130859375\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4323,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.444265365600586\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4324,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 14.013131141662598\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4325,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 14.025272369384766\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4326,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.445734024047852\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4327,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 13.924365997314453\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4328,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.997556686401367\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4329,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 10.804222106933594\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4330,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.960116386413574\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4331,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.867774963378906\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4332,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 10.525965690612793\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4333,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.602285385131836\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4334,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.743183135986328\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4335,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.102972030639648\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4336,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.41673469543457\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4337,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.644535064697266\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4338,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 12.53339958190918\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4339,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.11220645904541\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4340,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.409902572631836\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4341,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.343730926513672\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4342,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.725635528564453\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4343,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 12.902200698852539\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4344,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 11.210968017578125\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4345,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.077012062072754\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4346,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.129243850708008\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4347,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.087809562683105\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4348,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 11.949674606323242\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4349,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.02053451538086\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4350,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.731108665466309\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4351,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.639318466186523\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4352,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.149324417114258\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4353,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 12.719733238220215\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4354,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.35898208618164\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4355,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 12.216805458068848\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4356,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 11.10369873046875\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4357,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.64549446105957\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4358,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 10.916139602661133\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4359,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 11.736382484436035\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4360,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 9.530061721801758\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4361,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.601249694824219\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4362,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 10.716996192932129\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4363,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.693655967712402\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4364,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.191208839416504\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4365,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.193026542663574\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4366,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.592890739440918\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4367,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 10.402336120605469\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4368,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 9.519381523132324\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4369,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 11.738046646118164\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4370,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.130304336547852\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4371,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 13.802760124206543\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4372,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.20302963256836\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4373,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.188770294189453\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4374,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 11.880398750305176\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4375,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.244653701782227\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4376,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.542289733886719\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4377,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.746770858764648\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4378,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.13149642944336\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4379,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 13.998682022094727\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4380,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.275289535522461\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4381,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.03782844543457\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4382,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.086101531982422\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4383,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.652261734008789\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4384,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.143792152404785\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4385,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.191574096679688\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4386,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.371550559997559\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4387,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.176736831665039\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4388,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 13.983579635620117\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4389,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 9.598381042480469\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4390,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.11674690246582\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4391,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.284339904785156\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4392,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.80329418182373\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4393,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.47201156616211\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4394,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.222665786743164\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4395,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.325507164001465\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4396,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.076942443847656\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4397,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.740026473999023\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4398,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.203208923339844\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4399,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 11.983241081237793\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4400,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.429384231567383\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4401,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 13.805899620056152\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4402,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 11.70796012878418\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4403,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.771573066711426\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4404,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.315836906433105\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4405,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.522355079650879\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4406,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 11.673102378845215\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4407,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 11.11606502532959\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4408,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.75253677368164\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4409,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.751922607421875\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4410,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.371048927307129\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4411,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 13.969104766845703\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4412,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.289018630981445\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4413,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.671675682067871\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4414,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.305025100708008\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4415,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.459941864013672\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4416,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.60952377319336\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4417,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.015464782714844\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4418,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.291295051574707\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4419,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.263781547546387\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4420,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.181645393371582\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4421,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.738778114318848\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4422,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.012088775634766\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4423,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 12.901418685913086\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4424,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 12.859258651733398\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4425,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.278114318847656\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4426,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 11.512067794799805\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4427,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.82084846496582\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4428,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.456340789794922\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4429,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 11.491556167602539\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4430,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.870035171508789\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4431,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.42352294921875\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4432,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.056879043579102\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4433,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.0294189453125\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4434,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.370999336242676\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4435,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.220928192138672\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4436,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.426080703735352\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4437,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.320955276489258\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4438,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.000574111938477\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4439,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.477691650390625\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4440,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.001437187194824\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4441,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.993834495544434\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4442,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.391304969787598\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4443,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.123600006103516\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4444,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.288461685180664\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4445,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.581682205200195\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4446,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.115945816040039\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4447,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 10.653229713439941\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4448,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.117658615112305\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4449,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.124247550964355\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4450,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.726712226867676\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4451,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.115713119506836\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4452,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.636492729187012\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4453,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.004932403564453\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4454,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.640008926391602\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4455,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 10.566288948059082\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4456,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.879373550415039\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4457,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.346405029296875\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4458,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.651739120483398\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4459,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.787727355957031\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4460,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.83991813659668\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4461,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.239486694335938\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4462,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.56374740600586\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4463,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.401885986328125\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4464,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.044477462768555\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4465,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.85600471496582\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4466,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.858087539672852\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4467,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.276491165161133\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4468,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.500100135803223\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4469,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.413785934448242\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4470,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.220224380493164\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4471,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.33883285522461\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4472,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 11.958978652954102\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4473,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.211091995239258\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4474,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.726470947265625\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4475,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.1884765625\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4476,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.596694946289062\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4477,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.368549346923828\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4478,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.645414352416992\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4479,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.884025573730469\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4480,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.099260330200195\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4481,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.643733978271484\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4482,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.381099700927734\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4483,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.689838409423828\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4484,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.642637252807617\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4485,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.259960174560547\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4486,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 12.656116485595703\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4487,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.365419387817383\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4488,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 12.219776153564453\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4489,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 12.671968460083008\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4490,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.438735961914062\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4491,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.64431381225586\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4492,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.781458854675293\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4493,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.150907516479492\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4494,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.120882034301758\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4495,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 12.41915225982666\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4496,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 11.593061447143555\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4497,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.178534507751465\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4498,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.074853897094727\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4499,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.773138046264648\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4500,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 12.435997009277344\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4501,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.10842514038086\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4502,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.657849311828613\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4503,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.168102264404297\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4504,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.323728561401367\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4505,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.15182113647461\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4506,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.335803031921387\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4507,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 14.157448768615723\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4508,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.248579025268555\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4509,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.287088394165039\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4510,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 10.415958404541016\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4511,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.241254806518555\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4512,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 12.480865478515625\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4513,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.392685890197754\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4514,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.882669448852539\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4515,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.269445419311523\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4516,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.082000732421875\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4517,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.217205047607422\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4518,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.665031433105469\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4519,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.152928352355957\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4520,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.228492736816406\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4521,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.374540328979492\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4522,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.271635055541992\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4523,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.925981521606445\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4524,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.174363136291504\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4525,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.992703437805176\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4526,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.992612838745117\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4527,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.057300567626953\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4528,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.182502746582031\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4529,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.410994529724121\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4530,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 12.805363655090332\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4531,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.158594131469727\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4532,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 12.188068389892578\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4533,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.155841827392578\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4534,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.229515075683594\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4535,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 11.308442115783691\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4536,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 12.738485336303711\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4537,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.34606647491455\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4538,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.106866836547852\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4539,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.252801895141602\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4540,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.842178344726562\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4541,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 9.874469757080078\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4542,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.378396034240723\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4543,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.147977828979492\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4544,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.12256908416748\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4545,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.122178077697754\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4546,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.113304138183594\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4547,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.502866744995117\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4548,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.548833847045898\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4549,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.317574501037598\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4550,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.782089233398438\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4551,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.023970603942871\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4552,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.072978973388672\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4553,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.22581672668457\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4554,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.232780456542969\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4555,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.623916625976562\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4556,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.606152534484863\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4557,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 12.57105827331543\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4558,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.629018783569336\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4559,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.315813064575195\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4560,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.121066093444824\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4561,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.775444030761719\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4562,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 13.979480743408203\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4563,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 12.588705062866211\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4564,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.397005081176758\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4565,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.400927543640137\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4566,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.267349243164062\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4567,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.614595413208008\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4568,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.818440437316895\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4569,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.13233757019043\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4570,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.113228797912598\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4571,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.119791030883789\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4572,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.283817291259766\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4573,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 11.002448081970215\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4574,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.004151344299316\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4575,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.61068344116211\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4576,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.968118667602539\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4577,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.181753158569336\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4578,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.983810424804688\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4579,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.020829200744629\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4580,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.222084045410156\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4581,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.414957046508789\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4582,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.087408065795898\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4583,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.524351119995117\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4584,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.79135513305664\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4585,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 12.95820140838623\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4586,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.610308647155762\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4587,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.104425430297852\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4588,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.292407989501953\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4589,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.658042907714844\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4590,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.354779243469238\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4591,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.409599304199219\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4592,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.084424018859863\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4593,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.350852966308594\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4594,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.40339469909668\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4595,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.349252700805664\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4596,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.40785026550293\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4597,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.852899551391602\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4598,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.134665489196777\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4599,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.348014831542969\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4600,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.081151962280273\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4601,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 11.432010650634766\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4602,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.029670715332031\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4603,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.452873229980469\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4604,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.672167778015137\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4605,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.835013389587402\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4606,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.355998039245605\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4607,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.975362777709961\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4608,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.225515365600586\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4609,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.940546989440918\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4610,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 13.012496948242188\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4611,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.088220596313477\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4612,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 12.861977577209473\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4613,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 11.912454605102539\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4614,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 10.842897415161133\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4615,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.310417175292969\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4616,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.807642936706543\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4617,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.675006866455078\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4618,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.82977294921875\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4619,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.20610237121582\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4620,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.679401397705078\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4621,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.207414627075195\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4622,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.843893051147461\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4623,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.606792449951172\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4624,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.148052215576172\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4625,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.150765419006348\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4626,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.014901161193848\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4627,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.214428901672363\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4628,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.88037109375\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4629,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.392308235168457\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4630,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.686208724975586\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4631,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.188928604125977\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4632,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.205301284790039\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4633,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.466007232666016\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4634,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 11.913430213928223\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4635,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.46368408203125\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4636,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.025468826293945\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4637,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.535462379455566\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4638,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.775732040405273\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4639,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 11.805030822753906\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4640,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 11.987285614013672\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4641,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.372453689575195\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4642,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.602481842041016\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4643,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.590997695922852\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4644,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.862088203430176\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4645,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.679579734802246\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4646,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.2120943069458\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4647,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.955436706542969\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4648,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.830266952514648\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4649,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.003120422363281\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4650,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 10.950773239135742\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4651,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 11.89799690246582\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4652,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.823458671569824\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4653,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.988128662109375\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4654,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 11.837451934814453\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4655,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.04043960571289\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4656,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.269437789916992\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4657,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.007659912109375\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4658,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.515504837036133\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4659,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.850458145141602\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4660,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.684287071228027\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4661,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.956411361694336\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4662,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.53097915649414\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4663,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.06782341003418\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4664,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.57133674621582\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4665,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.233672142028809\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4666,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.102876663208008\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4667,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.372053146362305\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4668,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.527205467224121\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4669,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 11.769959449768066\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4670,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.121877670288086\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4671,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.878660202026367\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4672,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.50456428527832\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4673,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.202081680297852\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4674,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.543996810913086\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4675,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.370723724365234\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4676,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.48721694946289\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4677,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.674793243408203\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4678,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.478216171264648\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4679,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.874509811401367\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4680,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.192577362060547\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4681,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.484952926635742\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4682,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.004951477050781\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4683,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.119699478149414\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4684,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.602767944335938\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4685,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.164092063903809\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4686,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.272232055664062\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4687,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.775543212890625\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4688,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.508781433105469\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4689,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.436333656311035\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4690,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.780441284179688\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4691,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.18078899383545\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4692,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.353463172912598\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4693,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.238516807556152\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4694,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.905452728271484\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4695,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.714903831481934\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4696,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.151488304138184\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4697,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.78402328491211\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4698,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.171043395996094\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4699,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.95255184173584\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4700,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.221489906311035\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4701,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.736595153808594\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4702,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.399022102355957\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4703,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.273588180541992\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4704,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.884042739868164\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4705,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.248351097106934\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4706,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.928324699401855\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4707,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.719573974609375\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4708,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 10.770313262939453\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4709,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 11.753260612487793\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4710,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.705421447753906\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4711,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.585962295532227\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4712,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.230264663696289\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4713,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 11.708394050598145\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4714,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.25130558013916\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4715,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.743969917297363\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4716,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.442941665649414\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4717,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.316472053527832\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4718,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.858875274658203\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4719,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.598640441894531\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4720,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.70947551727295\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4721,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.592706680297852\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4722,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.710273742675781\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4723,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.676926612854004\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4724,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.843974113464355\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4725,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.839435577392578\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4726,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.141518592834473\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4727,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.929229736328125\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4728,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.708548545837402\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4729,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.992410659790039\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4730,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.83026123046875\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4731,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 12.887051582336426\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4732,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.534303665161133\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4733,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.715628623962402\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4734,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.217355728149414\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4735,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.517099380493164\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4736,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.286345481872559\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4737,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.234588623046875\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4738,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.31440258026123\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4739,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.462484359741211\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4740,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.357002258300781\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4741,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.961909294128418\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4742,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 11.023061752319336\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4743,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.485733032226562\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4744,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.032323837280273\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4745,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.013320922851562\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4746,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.02074146270752\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4747,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.837749481201172\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4748,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.5941162109375\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4749,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.637639999389648\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4750,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.05085277557373\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4751,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.73782730102539\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4752,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.002368927001953\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4753,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 14.136911392211914\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4754,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 14.137456893920898\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4755,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.281083106994629\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4756,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 12.909399032592773\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4757,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.143714904785156\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4758,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 11.942997932434082\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4759,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.939885139465332\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4760,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.285985946655273\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4761,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.564220428466797\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4762,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.468463897705078\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4763,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.382665634155273\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4764,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.169536590576172\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4765,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.312969207763672\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4766,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.397296905517578\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4767,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.409751892089844\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4768,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.016386032104492\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4769,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.033967971801758\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4770,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.654814720153809\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4771,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.616643905639648\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4772,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.471139907836914\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4773,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.249256134033203\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4774,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.597246170043945\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4775,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.575980186462402\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4776,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.78610610961914\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4777,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.667135238647461\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4778,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.272740364074707\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4779,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.922993659973145\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4780,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.038110733032227\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4781,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 14.351746559143066\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4782,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.096453666687012\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4783,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.403733253479004\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4784,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.108125686645508\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4785,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 10.179533958435059\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4786,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.116943359375\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4787,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.409862518310547\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4788,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.281599044799805\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4789,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.566780090332031\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4790,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.277599334716797\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4791,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.508854866027832\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4792,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 12.658985137939453\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4793,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.826506614685059\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4794,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.888908386230469\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4795,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.362089157104492\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4796,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 11.330309867858887\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4797,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.035459518432617\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4798,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.003118515014648\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4799,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.124168395996094\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4800,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 11.66089916229248\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4801,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.09434700012207\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4802,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.566287994384766\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4803,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.484411239624023\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4804,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 12.6637601852417\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4805,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 12.787572860717773\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4806,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.173473358154297\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4807,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.637035369873047\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4808,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.347712516784668\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4809,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.32683277130127\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4810,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.364712715148926\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4811,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.32911205291748\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4812,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.327713012695312\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4813,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.345986366271973\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4814,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.49227523803711\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4815,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.377678871154785\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4816,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 14.051881790161133\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4817,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.420645713806152\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4818,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.808127403259277\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4819,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.32110595703125\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4820,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.68906307220459\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4821,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.437451362609863\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4822,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 11.868748664855957\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4823,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.147939682006836\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4824,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.539361953735352\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4825,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.336190223693848\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4826,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.57058334350586\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4827,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.116374969482422\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4828,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.095340728759766\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4829,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.257536888122559\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4830,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.531562805175781\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4831,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.070466041564941\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4832,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.56082534790039\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4833,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.29018783569336\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4834,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.806382179260254\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4835,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.120474815368652\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4836,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.425474166870117\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4837,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 10.186513900756836\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4838,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.160625457763672\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4839,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.188530921936035\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4840,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.321635246276855\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4841,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.690118789672852\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4842,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.585489273071289\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4843,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.600021362304688\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4844,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.174995422363281\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4845,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.65982437133789\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4846,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.669549942016602\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4847,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.657421112060547\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4848,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.793991088867188\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4849,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.779548645019531\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4850,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.33206558227539\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4851,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.467472076416016\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4852,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.156536102294922\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4853,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.631735801696777\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4854,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.671871185302734\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4855,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.606267929077148\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4856,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.604459762573242\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4857,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.934637069702148\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4858,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.327042579650879\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4859,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.682245254516602\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4860,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.099736213684082\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4861,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.169013977050781\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4862,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.658828735351562\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4863,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.926069259643555\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4864,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.561126708984375\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4865,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.944769859313965\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4866,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.28166675567627\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4867,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.116312026977539\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4868,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.720401763916016\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4869,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 11.465813636779785\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4870,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.652379989624023\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4871,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.142407417297363\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4872,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.630279541015625\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4873,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.905941009521484\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4874,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.491958618164062\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4875,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.165099143981934\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4876,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 10.822101593017578\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4877,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 11.526935577392578\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4878,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.241660118103027\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4879,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.661367416381836\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4880,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.622594833374023\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4881,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.557561874389648\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4882,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.505353927612305\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4883,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.163597106933594\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4884,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 14.12574577331543\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4885,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.191730499267578\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4886,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.482425689697266\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4887,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.40731430053711\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4888,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.371175765991211\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4889,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.926431655883789\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4890,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.430891036987305\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4891,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.55095100402832\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4892,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.385709762573242\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4893,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.661051750183105\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4894,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.44167709350586\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4895,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.64288330078125\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4896,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.142065048217773\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4897,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.714916229248047\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4898,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.427740097045898\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4899,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.923938751220703\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4900,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 11.992504119873047\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4901,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.704252243041992\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4902,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.460478782653809\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4903,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.777423858642578\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4904,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.286922454833984\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4905,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.728951454162598\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4906,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.607173919677734\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4907,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.695558547973633\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4908,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.724925994873047\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4909,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.998265266418457\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4910,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.246118545532227\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4911,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.247299194335938\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4912,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.594836235046387\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4913,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 11.989591598510742\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4914,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.922586441040039\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4915,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.454729080200195\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4916,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.723077774047852\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4917,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.454777717590332\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4918,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.542198181152344\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4919,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.725318908691406\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4920,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.554530143737793\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4921,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.930957794189453\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4922,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.14604377746582\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4923,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.102819442749023\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4924,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.676539421081543\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4925,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.082904815673828\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4926,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.079846382141113\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4927,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.238037109375\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4928,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.725263595581055\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4929,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.390213012695312\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4930,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.2415189743042\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4931,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.61957836151123\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4932,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.685580253601074\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4933,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.374356269836426\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4934,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 13.530641555786133\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4935,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.167415618896484\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4936,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.490543365478516\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4937,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.555131912231445\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4938,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.375978469848633\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4939,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.527764320373535\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4940,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 14.399721145629883\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4941,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.223957061767578\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4942,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.833910942077637\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4943,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.387535095214844\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4944,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.831709861755371\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4945,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.231151580810547\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4946,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.61612319946289\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4947,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 14.192891120910645\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4948,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 13.943841934204102\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4949,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.532855987548828\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4950,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 11.903339385986328\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4951,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.679302215576172\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4952,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.838080406188965\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4953,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 14.178400039672852\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4954,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.15627670288086\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4955,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.514208793640137\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4956,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.065918922424316\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4957,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.654906272888184\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4958,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.841005325317383\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4959,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.410314559936523\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4960,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.923694610595703\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4961,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.906181335449219\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4962,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.898513793945312\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4963,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.978414535522461\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4964,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.698230743408203\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4965,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.063018798828125\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4966,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.494542121887207\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4967,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.86956787109375\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4968,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.418917655944824\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4969,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.171630859375\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4970,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.337091445922852\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4971,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.750740051269531\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4972,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.685396194458008\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4973,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.359623908996582\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4974,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.319746017456055\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 4975,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.698610305786133\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4976,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 11.122455596923828\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4977,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.992424011230469\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4978,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.056585311889648\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4979,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.464600563049316\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4980,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.761956214904785\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4981,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.952281951904297\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4982,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.312331199645996\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4983,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.30712604522705\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 4984,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.940754890441895\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4985,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.422289848327637\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4986,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.496622085571289\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4987,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.506363868713379\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4988,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.544012069702148\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4989,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.940902709960938\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4990,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.00302505493164\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4991,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.904712677001953\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4992,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.604898452758789\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4993,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.589231491088867\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 4994,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.222335815429688\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4995,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.779668807983398\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 4996,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 13.966658592224121\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 4997,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.832670211791992\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 4998,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.717557907104492\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 4999,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.324911117553711\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5000,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.691298484802246\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5001,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.666128158569336\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5002,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.620504379272461\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5003,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.585697174072266\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5004,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.886266708374023\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5005,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.5745849609375\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5006,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.704136848449707\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5007,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.745901107788086\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5008,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.623775482177734\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5009,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.036273956298828\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5010,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.667773246765137\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5011,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.731792449951172\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5012,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.291906356811523\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5013,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.929099082946777\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5014,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 10.847679138183594\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5015,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.622981071472168\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5016,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.36258316040039\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5017,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.193294525146484\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5018,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.58615779876709\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5019,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.215566635131836\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5020,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.585705757141113\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5021,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.59321403503418\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5022,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.476680755615234\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5023,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.248966217041016\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5024,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.504376411437988\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5025,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.451732635498047\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5026,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 13.278968811035156\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5027,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 14.154541015625\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5028,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.709911346435547\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5029,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.838090896606445\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5030,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.134929656982422\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5031,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.699037551879883\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5032,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.728954315185547\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5033,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 13.435413360595703\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5034,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.795600891113281\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5035,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.37653636932373\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5036,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.71714973449707\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5037,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.951801300048828\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5038,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.869192123413086\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5039,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.74216079711914\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5040,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.253969192504883\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5041,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 13.13621997833252\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5042,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.462081909179688\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5043,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.78950023651123\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5044,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.704368591308594\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5045,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.405538558959961\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5046,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 14.12285041809082\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5047,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.416938781738281\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5048,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.736187934875488\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5049,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.987448692321777\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5050,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.793289184570312\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5051,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.576581954956055\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5052,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.430660247802734\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5053,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 14.098923683166504\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5054,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.221874237060547\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5055,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.220504760742188\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5056,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.618541717529297\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5057,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.73304557800293\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5058,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.476775169372559\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5059,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.343010902404785\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5060,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.607462882995605\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5061,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.739885330200195\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5062,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.575727462768555\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5063,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.252021789550781\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5064,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.629892349243164\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5065,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.397530555725098\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5066,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.322105407714844\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5067,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.277238845825195\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5068,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.936347961425781\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5069,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.633881568908691\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5070,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.056180953979492\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5071,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.3123779296875\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5072,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.23591423034668\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5073,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.369413375854492\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5074,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.445119857788086\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5075,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.496379852294922\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5076,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.33927059173584\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5077,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.690106391906738\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5078,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.451906204223633\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5079,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.300314903259277\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5080,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.620826721191406\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5081,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.764557838439941\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5082,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.226692199707031\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5083,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.974377632141113\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5084,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.448307991027832\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5085,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.707239151000977\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5086,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.322938919067383\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5087,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.54074478149414\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5088,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.024761199951172\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5089,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.844054222106934\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5090,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.44903564453125\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5091,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.523307800292969\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5092,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 12.691797256469727\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5093,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 12.716474533081055\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5094,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.57917594909668\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5095,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.557999610900879\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5096,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 14.27590560913086\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5097,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.551847457885742\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5098,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.443639755249023\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5099,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.363981246948242\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5100,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.702783584594727\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5101,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.47226333618164\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5102,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.482295989990234\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5103,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.602653503417969\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5104,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 13.240188598632812\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5105,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.540950775146484\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5106,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.728233337402344\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5107,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.909093856811523\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5108,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.597457885742188\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5109,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.261157989501953\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5110,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.44766616821289\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5111,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.296636581420898\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5112,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.232158660888672\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5113,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 13.65392780303955\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5114,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.791723251342773\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5115,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 13.742883682250977\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5116,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.448184967041016\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5117,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.183221817016602\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5118,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 11.205071449279785\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5119,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.493693351745605\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5120,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 11.917356491088867\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5121,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.837302207946777\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5122,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.828277587890625\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5123,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.53602409362793\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5124,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.735291481018066\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5125,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.243396759033203\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5126,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.6721773147583\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5127,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.865434646606445\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5128,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.669258117675781\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5129,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.387289047241211\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5130,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.789490699768066\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5131,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.55671215057373\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5132,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.411516189575195\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5133,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 11.226863861083984\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5134,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.280550003051758\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5135,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.585874557495117\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5136,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.396751403808594\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5137,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.717606544494629\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5138,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.378019332885742\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5139,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.7427978515625\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5140,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.616470336914062\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5141,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.693124771118164\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5142,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.690594673156738\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5143,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.656002044677734\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5144,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.774852752685547\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5145,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 12.954423904418945\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5146,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.724292755126953\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5147,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.85804271697998\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5148,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.997106552124023\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5149,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.419585227966309\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5150,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.59385871887207\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5151,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.529220581054688\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5152,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.445184707641602\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5153,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.947927474975586\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5154,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.329967498779297\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5155,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.2503662109375\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5156,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.745473861694336\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5157,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.688148498535156\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5158,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.75944995880127\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5159,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.649020195007324\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5160,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.764702796936035\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5161,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.745782852172852\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5162,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.308557510375977\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5163,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.475849151611328\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5164,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.704523086547852\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5165,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.383614540100098\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5166,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.744475364685059\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5167,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.723058700561523\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5168,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.881599426269531\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5169,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.096435546875\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5170,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.743728637695312\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5171,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.755455017089844\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5172,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.543174743652344\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5173,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.446812629699707\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5174,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.574082374572754\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5175,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.597173690795898\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5176,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.637666702270508\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5177,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 14.023307800292969\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5178,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.994269371032715\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5179,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.79851245880127\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5180,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.451713562011719\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5181,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.035518646240234\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5182,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.25175666809082\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5183,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.304559707641602\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5184,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.650449752807617\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5185,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.642159461975098\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5186,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.054319381713867\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5187,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.493496894836426\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5188,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.392416000366211\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5189,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.650127410888672\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5190,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.914388656616211\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5191,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.340394973754883\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5192,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.207637786865234\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5193,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.187705993652344\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5194,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.793802261352539\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5195,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.712020874023438\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5196,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.059996604919434\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5197,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.835396766662598\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5198,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.49318790435791\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5199,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.821657180786133\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5200,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.065508842468262\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5201,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.811483383178711\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5202,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.93191909790039\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5203,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.90639877319336\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5204,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.852745056152344\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5205,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 14.06820297241211\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5206,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.797914505004883\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5207,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.661860466003418\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5208,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.6876220703125\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5209,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.364456176757812\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5210,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.854225158691406\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5211,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.517532348632812\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5212,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 13.129323959350586\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5213,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.1229887008667\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5214,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.413771629333496\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5215,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.328598022460938\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5216,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.602117538452148\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5217,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.896450996398926\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5218,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.396925926208496\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5219,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.11184024810791\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5220,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.467947959899902\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5221,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.930951118469238\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5222,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.667312622070312\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5223,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.577295303344727\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5224,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.622687339782715\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5225,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.400869369506836\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5226,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.575764656066895\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5227,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.269872665405273\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5228,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.727643013000488\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5229,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.52063274383545\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5230,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 11.531737327575684\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5231,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.80677604675293\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5232,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.735515594482422\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5233,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.117744445800781\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5234,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.112272262573242\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5235,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.740339279174805\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5236,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.280115127563477\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5237,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.68914794921875\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5238,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.853347778320312\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5239,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.31610107421875\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5240,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.40942668914795\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5241,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.801416397094727\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5242,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.495444297790527\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5243,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 14.333513259887695\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5244,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.630215644836426\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5245,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.398019790649414\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5246,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.582353591918945\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5247,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.269725799560547\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5248,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 11.520257949829102\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5249,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.465066909790039\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5250,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.954133987426758\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5251,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.439458847045898\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5252,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.753767967224121\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5253,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.767680168151855\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5254,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.316499710083008\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5255,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.002192497253418\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5256,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.327642440795898\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5257,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.406525611877441\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5258,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.535552978515625\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5259,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.655694961547852\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5260,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 14.223651885986328\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5261,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.720256805419922\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5262,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.340103149414062\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5263,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.919267654418945\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5264,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.577824592590332\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5265,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.913095474243164\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5266,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.123212814331055\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5267,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.35000991821289\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5268,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.643373489379883\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5269,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.24654483795166\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5270,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.375734329223633\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5271,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.971412658691406\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5272,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.508005142211914\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5273,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.305168151855469\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5274,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.275101661682129\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5275,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.20095157623291\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5276,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.669449806213379\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5277,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.76772689819336\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5278,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.994375228881836\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5279,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.773054122924805\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5280,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.445158004760742\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5281,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.733917236328125\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5282,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 14.169692993164062\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5283,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.413982391357422\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5284,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 14.19842529296875\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5285,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 14.119638442993164\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5286,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 14.072317123413086\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5287,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.147726058959961\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5288,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.844568252563477\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5289,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.566637992858887\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5290,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.512407302856445\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5291,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 14.214794158935547\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5292,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.138069152832031\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5293,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.503013610839844\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5294,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.439336776733398\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5295,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.435060501098633\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5296,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 12.140007019042969\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5297,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.42725658416748\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5298,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.2452392578125\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5299,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.262117385864258\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5300,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.770341873168945\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5301,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.602765083312988\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5302,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.318695068359375\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5303,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.774505615234375\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5304,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.512737274169922\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5305,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.13328742980957\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5306,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.360186576843262\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5307,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.363224983215332\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5308,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.63509464263916\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5309,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.121381759643555\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5310,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.730712890625\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5311,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.17546272277832\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5312,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.78982925415039\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5313,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.420682907104492\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5314,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.549750328063965\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5315,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.099020004272461\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5316,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.175020217895508\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5317,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.036865234375\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5318,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.162715911865234\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5319,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 14.081138610839844\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5320,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.71756649017334\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5321,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.751335144042969\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5322,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.745109558105469\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5323,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.789055824279785\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5324,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.918730735778809\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5325,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.114712715148926\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5326,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.368682861328125\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5327,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.514902114868164\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5328,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.08538818359375\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5329,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 14.124073028564453\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5330,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 12.9298095703125\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5331,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.759162902832031\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5332,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.779695510864258\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5333,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.073110580444336\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5334,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.910712242126465\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5335,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 11.15519905090332\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5336,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.740216255187988\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5337,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.354110717773438\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5338,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.772806167602539\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5339,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 14.053683280944824\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5340,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 14.080184936523438\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5341,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.778996467590332\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5342,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 14.067964553833008\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5343,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.430610656738281\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5344,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.915180206298828\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5345,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.779876708984375\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5346,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.740368843078613\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5347,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.779701232910156\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5348,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.650851249694824\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5349,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.742780685424805\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5350,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.720151901245117\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5351,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 14.199010848999023\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5352,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.683881759643555\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5353,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.976194381713867\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5354,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.596199035644531\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5355,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.920555114746094\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5356,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.089851379394531\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5357,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 14.276460647583008\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5358,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.215749740600586\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5359,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 14.262431144714355\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5360,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.90084171295166\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5361,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.904109954833984\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5362,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.997739791870117\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5363,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.908392906188965\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5364,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.781371116638184\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5365,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.286399841308594\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5366,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.377922058105469\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5367,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.780550003051758\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5368,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.98395824432373\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5369,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.882280349731445\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5370,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.394317626953125\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5371,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.408554077148438\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5372,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.144041061401367\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5373,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.190898895263672\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5374,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.349895477294922\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5375,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.908686637878418\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5376,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 14.126912117004395\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5377,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.178308486938477\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5378,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.459559440612793\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5379,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.992210388183594\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5380,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.885318756103516\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5381,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.929034233093262\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5382,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.392873764038086\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5383,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.104635238647461\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5384,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.788305282592773\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5385,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.012685775756836\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5386,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.4948091506958\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5387,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.985570907592773\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5388,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.397650718688965\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5389,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.994255065917969\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5390,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.554763793945312\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5391,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 11.65186882019043\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5392,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.518780708312988\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5393,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 12.352615356445312\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5394,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.543663024902344\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5395,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.53386402130127\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5396,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 14.00533676147461\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5397,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.392093658447266\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5398,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.420674324035645\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5399,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.197224617004395\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5400,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.218402862548828\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5401,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.087883949279785\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5402,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.965692520141602\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5403,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.25944709777832\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5404,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.244782447814941\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5405,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.828964233398438\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5406,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.494796752929688\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5407,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.557650566101074\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5408,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 14.09950065612793\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5409,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.647431373596191\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5410,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.685815811157227\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5411,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.224985122680664\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5412,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.91557788848877\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5413,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.994851112365723\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5414,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.419078826904297\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5415,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 14.381706237792969\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5416,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.413164138793945\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5417,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 14.343626022338867\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5418,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.685012817382812\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5419,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.496706008911133\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5420,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.803646087646484\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5421,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 14.043460845947266\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5422,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.138870239257812\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5423,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 14.356544494628906\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5424,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.683510780334473\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5425,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 14.219366073608398\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5426,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 14.214742660522461\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5427,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 14.217086791992188\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5428,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 11.250955581665039\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5429,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.580985069274902\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5430,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.41695785522461\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5431,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.373274803161621\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5432,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.561532974243164\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5433,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.256227493286133\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5434,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.743855476379395\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5435,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.333662033081055\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5436,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.937002182006836\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5437,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 14.207685470581055\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5438,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.146075248718262\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5439,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.50795841217041\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5440,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.622259140014648\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5441,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.812740325927734\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5442,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 14.33633804321289\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5443,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.399153709411621\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5444,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.527042388916016\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5445,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.630941390991211\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5446,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.879487037658691\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5447,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.905914306640625\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5448,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 13.90579605102539\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5449,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.559357643127441\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5450,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.488332748413086\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5451,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.515256881713867\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5452,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.477699279785156\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5453,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.429539680480957\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5454,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.131340026855469\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5455,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 13.992376327514648\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5456,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.056047439575195\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5457,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.186790466308594\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5458,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.207722663879395\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5459,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.767688751220703\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5460,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.286042213439941\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5461,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.776321411132812\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5462,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.309103965759277\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5463,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.689741134643555\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5464,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.780024528503418\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5465,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.482187271118164\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5466,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.476594924926758\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5467,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.472002029418945\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5468,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 13.215466499328613\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5469,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 14.247739791870117\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5470,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 14.386027336120605\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5471,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 14.213064193725586\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5472,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 11.06523323059082\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5473,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.782551765441895\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5474,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.576532363891602\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5475,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.30076789855957\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5476,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.278446197509766\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5477,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 14.135842323303223\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5478,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.769177436828613\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5479,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.110923767089844\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5480,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.461457252502441\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5481,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.699394226074219\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5482,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.71760368347168\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5483,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.67131233215332\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5484,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 14.493014335632324\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5485,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.719720840454102\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5486,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 14.505146026611328\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5487,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.742372512817383\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5488,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.73946762084961\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5489,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 14.553325653076172\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5490,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.887664794921875\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5491,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.715476989746094\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5492,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 11.721780776977539\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5493,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.68072509765625\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5494,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.163518905639648\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5495,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.185877799987793\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5496,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.75821304321289\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5497,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.783915519714355\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5498,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.890642166137695\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5499,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 14.137958526611328\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5500,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 14.008544921875\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5501,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.806464195251465\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5502,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 14.003469467163086\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5503,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.755416870117188\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5504,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 11.904106140136719\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5505,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.776847839355469\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5506,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 14.288955688476562\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5507,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.781084060668945\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5508,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.07451057434082\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5509,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.663216590881348\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5510,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.781078338623047\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5511,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 14.422475814819336\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5512,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.324024200439453\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5513,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.708948135375977\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5514,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 11.665759086608887\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5515,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.358110427856445\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5516,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.108264923095703\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5517,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.585650444030762\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5518,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.574596405029297\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5519,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.07443618774414\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5520,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 14.014851570129395\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5521,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.515230178833008\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5522,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.633824348449707\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5523,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.555082321166992\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5524,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.423532485961914\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5525,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.406192779541016\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5526,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.174478530883789\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5527,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.960166931152344\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5528,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.349363327026367\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5529,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.715083122253418\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5530,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.261024475097656\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5531,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.526713371276855\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5532,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 14.265275955200195\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5533,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 10.819607734680176\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5534,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.919776916503906\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5535,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.93353271484375\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5536,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.555469512939453\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5537,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.758183479309082\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5538,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.306122779846191\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5539,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.318122863769531\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5540,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.71431827545166\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5541,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.716621398925781\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5542,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 13.053338050842285\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5543,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.547130584716797\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5544,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.844512939453125\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5545,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 13.119707107543945\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5546,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.818920135498047\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5547,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 13.186578750610352\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5548,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.21925163269043\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5549,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.920496940612793\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5550,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.35037899017334\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5551,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.803871154785156\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5552,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.463068962097168\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5553,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 14.330018997192383\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5554,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.638932228088379\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5555,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.30586051940918\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5556,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.606191635131836\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5557,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.408016204833984\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5558,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.215585708618164\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5559,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 12.323600769042969\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5560,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.875211715698242\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5561,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.771778106689453\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5562,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.271034240722656\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5563,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 13.452021598815918\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5564,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.046863555908203\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5565,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.78365707397461\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5566,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.539814949035645\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5567,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.536407470703125\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5568,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 14.183597564697266\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5569,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 13.282527923583984\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5570,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.8741455078125\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5571,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.753813743591309\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5572,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.332767486572266\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5573,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.71539306640625\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5574,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.11562728881836\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5575,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.169560432434082\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5576,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.3341064453125\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5577,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.004523277282715\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5578,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.07032299041748\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5579,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.360990524291992\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5580,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.592498779296875\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5581,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.53514289855957\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5582,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.671928405761719\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5583,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.383001327514648\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5584,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.534862518310547\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5585,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.792068481445312\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5586,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.871652603149414\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5587,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.457632064819336\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5588,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.537683486938477\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5589,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.69096851348877\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5590,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 14.330327987670898\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5591,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.083640098571777\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5592,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.021072387695312\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5593,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.125348091125488\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5594,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.726888656616211\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5595,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.860992431640625\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5596,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 14.186081886291504\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5597,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.874689102172852\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5598,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.7727689743042\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5599,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.782974243164062\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5600,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.8268404006958\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5601,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.582002639770508\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5602,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 12.124092102050781\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5603,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.385608673095703\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5604,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.716192245483398\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5605,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.827068328857422\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5606,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.07595443725586\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5607,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.305339813232422\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5608,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.911825180053711\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5609,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.376285552978516\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5610,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.903186798095703\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5611,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.737428665161133\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5612,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.36291217803955\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5613,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.108627319335938\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5614,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.832595825195312\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5615,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.635316848754883\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5616,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.933991432189941\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5617,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.688946723937988\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5618,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.801334381103516\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5619,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.37625789642334\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5620,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.529108047485352\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5621,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.133530616760254\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5622,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.648088455200195\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5623,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.608000755310059\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5624,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.635749816894531\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5625,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 14.12344741821289\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5626,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.389348030090332\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5627,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.746061325073242\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5628,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.242100715637207\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5629,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.525091171264648\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5630,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.572629928588867\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5631,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.519389152526855\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5632,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 14.101612091064453\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5633,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.40007209777832\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5634,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.767675399780273\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5635,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.530645370483398\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5636,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.821430206298828\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5637,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.155031204223633\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5638,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.502626419067383\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5639,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.706230163574219\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5640,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.54842758178711\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5641,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 14.015713691711426\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5642,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.543350219726562\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5643,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.256292343139648\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5644,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.85639762878418\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5645,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.545225143432617\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5646,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.667534828186035\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5647,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.704534530639648\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5648,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.9119291305542\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5649,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.642803192138672\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5650,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.992218017578125\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5651,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.541747093200684\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5652,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.442922592163086\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5653,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.628721237182617\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5654,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.444234848022461\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5655,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.826349258422852\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5656,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.858851432800293\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5657,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.403022766113281\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5658,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.58516788482666\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5659,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 14.086511611938477\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5660,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.873717308044434\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5661,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.792268753051758\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5662,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 13.287940979003906\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5663,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.396767616271973\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5664,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.709382057189941\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5665,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.70893669128418\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5666,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.345829010009766\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5667,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.82036018371582\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5668,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.789897918701172\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5669,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.48225212097168\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5670,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.408645629882812\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5671,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.113163948059082\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5672,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.497610092163086\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5673,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.504257202148438\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5674,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.346527099609375\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5675,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.712809562683105\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5676,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.713476181030273\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5677,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 13.264745712280273\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5678,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.326565742492676\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5679,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.395103454589844\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5680,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.041788101196289\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5681,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.534677505493164\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5682,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.733474731445312\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5683,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.533304214477539\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5684,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.54714584350586\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5685,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.572336196899414\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5686,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.708322525024414\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5687,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.84831428527832\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5688,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.769612312316895\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5689,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.173986434936523\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5690,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 12.983528137207031\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5691,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.547210693359375\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5692,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.769105911254883\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5693,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.56017780303955\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5694,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.99458122253418\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5695,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.947144508361816\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5696,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.646242141723633\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5697,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.757291793823242\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5698,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 14.14310073852539\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5699,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.316045761108398\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5700,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.42968463897705\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5701,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.664722442626953\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5702,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 14.027828216552734\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5703,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.509858131408691\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5704,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.502737045288086\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5705,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 14.010078430175781\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5706,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.238914489746094\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5707,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.422876358032227\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5708,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.375306129455566\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5709,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.582185745239258\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5710,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.546995162963867\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5711,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 14.166557312011719\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5712,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.588310241699219\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5713,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.3587007522583\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5714,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 14.228797912597656\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5715,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.447226524353027\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5716,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.41514778137207\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5717,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 14.046510696411133\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5718,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.813024520874023\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5719,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.967635154724121\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5720,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.747295379638672\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5721,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.40273666381836\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5722,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.442405700683594\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5723,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.732769012451172\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5724,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.551902770996094\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5725,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.681434631347656\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5726,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 13.855286598205566\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5727,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.266693115234375\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5728,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.269142150878906\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5729,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 14.22677230834961\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5730,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.801492691040039\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5731,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 14.239275932312012\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5732,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.825711250305176\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5733,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.692176818847656\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5734,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 13.859378814697266\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5735,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.319053649902344\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5736,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 14.053760528564453\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5737,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 13.188905715942383\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5738,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.509004592895508\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5739,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.824554443359375\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5740,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.559940338134766\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5741,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.675825119018555\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5742,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.824005126953125\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5743,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.564579010009766\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5744,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 14.393529891967773\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5745,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 14.035543441772461\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5746,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.990257263183594\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5747,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.394161224365234\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5748,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.239400863647461\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5749,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 14.035909652709961\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5750,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 11.700870513916016\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5751,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.554487228393555\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5752,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.666193008422852\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5753,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.712532043457031\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5754,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.724740982055664\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5755,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.82769775390625\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5756,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.904480934143066\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5757,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.922163009643555\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5758,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.786998748779297\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5759,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.48402214050293\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5760,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.480436325073242\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5761,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.55636978149414\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5762,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.628955841064453\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5763,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 14.060342788696289\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5764,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.437047958374023\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5765,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.811006546020508\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5766,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.752449035644531\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5767,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.816743850708008\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5768,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 14.184853553771973\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5769,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.534287452697754\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5770,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.79147720336914\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5771,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.446855545043945\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5772,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.441800117492676\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5773,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.474571228027344\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5774,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.287809371948242\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5775,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 14.150321006774902\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5776,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.569990158081055\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5777,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.80249309539795\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5778,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.278497695922852\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5779,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 14.037527084350586\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5780,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 14.200346946716309\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5781,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 14.030858039855957\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5782,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.314555168151855\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5783,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.807392120361328\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5784,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.75866413116455\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5785,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.401460647583008\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5786,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.62417984008789\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5787,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.717256546020508\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5788,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.595438003540039\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5789,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.741236686706543\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5790,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.817285537719727\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5791,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.543951034545898\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5792,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.926717758178711\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5793,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.66485595703125\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5794,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.969593048095703\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5795,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.768426895141602\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5796,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.934297561645508\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5797,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.366434097290039\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5798,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.373942375183105\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5799,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.550809860229492\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5800,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.930078506469727\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5801,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 14.008371353149414\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5802,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 14.054122924804688\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5803,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.394198417663574\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5804,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 13.899415016174316\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5805,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.813091278076172\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5806,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.561616897583008\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5807,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.841991424560547\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5808,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.189541816711426\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5809,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.20007610321045\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5810,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.049524307250977\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5811,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.857686042785645\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5812,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.692657470703125\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5813,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.821980476379395\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5814,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.956968307495117\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5815,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 14.024219512939453\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5816,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 14.081903457641602\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5817,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 14.234830856323242\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5818,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.448970794677734\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5819,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 14.385754585266113\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5820,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.823688507080078\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5821,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.456563949584961\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5822,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 14.169354438781738\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5823,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.295412063598633\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5824,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.854543685913086\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5825,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 14.426371574401855\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5826,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.812374114990234\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5827,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.760031700134277\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5828,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.283535957336426\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5829,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.669633865356445\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5830,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 14.517782211303711\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5831,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.78856086730957\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5832,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.512222290039062\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5833,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 13.038957595825195\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5834,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.819385528564453\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5835,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.478336334228516\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5836,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.7474365234375\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5837,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 12.995576858520508\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5838,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 11.734977722167969\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5839,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.767745971679688\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5840,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.83911418914795\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5841,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.65022087097168\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5842,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 14.103109359741211\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5843,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.699735641479492\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5844,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 14.21717643737793\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5845,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.691572189331055\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5846,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.325702667236328\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5847,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.255730628967285\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5848,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 13.569215774536133\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5849,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 14.103317260742188\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5850,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 14.160967826843262\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5851,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 14.258161544799805\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5852,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 14.116194725036621\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5853,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.545490264892578\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5854,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.314750671386719\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5855,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.544075012207031\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5856,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 14.209209442138672\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5857,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 14.022350311279297\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5858,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.318521499633789\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5859,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.805473327636719\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5860,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.435046195983887\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5861,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.556089401245117\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5862,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 14.38192367553711\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5863,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 14.233898162841797\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5864,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 14.396690368652344\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5865,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 14.03470230102539\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5866,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.655818939208984\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5867,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.718988418579102\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5868,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.450275421142578\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5869,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.644885063171387\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5870,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.295778274536133\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5871,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.853184700012207\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5872,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.976283073425293\n",
      "\n",
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5873,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 14.287409782409668\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5874,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.501359939575195\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5875,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.499155044555664\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5876,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.265008926391602\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5877,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.992344856262207\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5878,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.498703956604004\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5879,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 12.743633270263672\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5880,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.636222839355469\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5881,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.719157218933105\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5882,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.936193466186523\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5883,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.60346794128418\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5884,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.602676391601562\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5885,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.811318397521973\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5886,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.753332138061523\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5887,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.75576400756836\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5888,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.62842082977295\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5889,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.991961479187012\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5890,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.591471672058105\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5891,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.732460975646973\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5892,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.600391387939453\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5893,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.763669967651367\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5894,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.485162734985352\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5895,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 13.927112579345703\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5896,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.784700393676758\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5897,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.542037010192871\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5898,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 14.20556640625\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5899,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.652915954589844\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5900,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 14.130725860595703\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5901,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.818380355834961\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5902,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.313817977905273\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5903,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.311084747314453\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5904,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 14.185089111328125\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5905,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 14.253596305847168\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5906,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.468259811401367\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5907,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.764476776123047\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5908,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 12.553159713745117\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5909,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 14.212303161621094\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5910,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.883177757263184\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5911,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 14.221641540527344\n",
      "\n",
      "TX Location: [[-300.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5912,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-300.  -100.    21.5]], ep_loss: 13.09937572479248\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5913,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.818965911865234\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5914,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 14.241674423217773\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5915,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.783879280090332\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5916,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.720252990722656\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5917,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 13.237092018127441\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5918,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.847108840942383\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5919,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.658483505249023\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5920,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 14.25934886932373\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5921,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.84748649597168\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5922,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 14.485869407653809\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5923,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.919801712036133\n",
      "\n",
      "TX Location: [[-500.  -400.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5924,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -400.    21.5]], ep_loss: 14.533440589904785\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5925,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.814735412597656\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5926,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 13.332428932189941\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5927,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 14.378974914550781\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5928,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.845623016357422\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5929,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.728435516357422\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5930,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.84449291229248\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5931,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 14.20882797241211\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5932,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 13.458110809326172\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5933,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 14.203178405761719\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5934,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 12.776266098022461\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5935,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.54627513885498\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5936,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 14.208854675292969\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5937,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 14.499884605407715\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5938,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 12.608635902404785\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5939,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 12.565200805664062\n",
      "\n",
      "TX Location: [[-400.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5940,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-400.  -500.    21.5]], ep_loss: 14.269952774047852\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5941,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.783561706542969\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5942,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.494815826416016\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5943,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.833786010742188\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5944,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.78884506225586\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5945,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.82857894897461\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5946,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.48465347290039\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5947,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 13.530309677124023\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5948,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 14.274083137512207\n",
      "\n",
      "TX Location: [[-100.  -500.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5949,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -500.    21.5]], ep_loss: 14.849237442016602\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5950,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.839096069335938\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5951,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 14.378873825073242\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5952,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.268839836120605\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5953,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 13.829668998718262\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5954,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 14.031049728393555\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5955,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 14.043205261230469\n",
      "\n",
      "TX Location: [[-500.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5956,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-500.  -300.    21.5]], ep_loss: 13.4281005859375\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5957,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.990018844604492\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5958,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 14.34388256072998\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5959,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 14.006165504455566\n",
      "\n",
      "TX Location: [[-400.  -400.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5960,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-400.  -400.    21.5]], ep_loss: 14.173360824584961\n",
      "\n",
      "TX Location: [[-500.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5961,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-500.  -200.    21.5]], ep_loss: 14.056320190429688\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5962,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.930949211120605\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5963,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 14.040714263916016\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5964,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 14.010736465454102\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5965,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.971311569213867\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5966,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.832952499389648\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5967,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.767925262451172\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5968,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.497129440307617\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5969,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 14.023962020874023\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5970,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 13.132949829101562\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5971,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.419761657714844\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5972,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 14.412782669067383\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5973,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.831300735473633\n",
      "\n",
      "TX Location: [[-300.  -300.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5974,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-300.  -300.    21.5]], ep_loss: 14.478433609008789\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5975,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.810611724853516\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5976,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.736278533935547\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5977,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 12.721799850463867\n",
      "\n",
      "TX Location: [[-300.  -500.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5978,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -500.    21.5]], ep_loss: 14.393571853637695\n",
      "\n",
      "TX Location: [[-400.  -200.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5979,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-400.  -200.    21.5]], ep_loss: 13.280467987060547\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5980,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.167633056640625\n",
      "\n",
      "TX Location: [[-300.  -200.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 5981,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-300.  -200.    21.5]], ep_loss: 13.413094520568848\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5982,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.74124526977539\n",
      "\n",
      "TX Location: [[-200.  -300.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5983,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-200.  -300.    21.5]], ep_loss: 13.959701538085938\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5984,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 13.730512619018555\n",
      "\n",
      "TX Location: [[-200.  -100.    21.5]], Goal steps: 16, ep_actions: [13, 12, 14, 11, 15, 10, 0, 9, 1, 8, 2, 7, 3, 6, 4, 5], prevep_bestaction: 13\n",
      "Episode 5985,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 13, ep_len: 16, TXloc: [[-200.  -100.    21.5]], ep_loss: 13.6593656539917\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5986,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.826900482177734\n",
      "\n",
      "TX Location: [[-500.  -500.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5987,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-500.  -500.    21.5]], ep_loss: 14.311622619628906\n",
      "\n",
      "TX Location: [[-500.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5988,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-500.  -100.    21.5]], ep_loss: 14.745495796203613\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5989,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 14.106783866882324\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5990,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.593719482421875\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX Location: [[-100.  -200.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5991,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -200.    21.5]], ep_loss: 14.271430969238281\n",
      "\n",
      "TX Location: [[-100.  -300.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5992,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-100.  -300.    21.5]], ep_loss: 13.229965209960938\n",
      "\n",
      "TX Location: [[-400.  -100.    21.5]], Goal steps: 16, ep_actions: [14, 13, 15, 12, 0, 11, 1, 10, 2, 9, 3, 8, 4, 7, 5, 6], prevep_bestaction: 14\n",
      "Episode 5993,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 14, ep_len: 16, TXloc: [[-400.  -100.    21.5]], ep_loss: 13.599313735961914\n",
      "\n",
      "TX Location: [[-200.  -400.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5994,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -400.    21.5]], ep_loss: 14.27400016784668\n",
      "\n",
      "TX Location: [[-300.  -400.    21.5]], Goal steps: 16, ep_actions: [10, 9, 11, 8, 12, 7, 13, 6, 14, 5, 15, 4, 0, 3, 1, 2], prevep_bestaction: 10\n",
      "Episode 5995,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 10, ep_len: 16, TXloc: [[-300.  -400.    21.5]], ep_loss: 14.587204933166504\n",
      "\n",
      "TX Location: [[-100.  -100.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5996,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-100.  -100.    21.5]], ep_loss: 14.580429077148438\n",
      "\n",
      "TX Location: [[-100.  -400.    21.5]], Goal steps: 16, ep_actions: [8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15, 0], prevep_bestaction: 8\n",
      "Episode 5997,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 8, ep_len: 16, TXloc: [[-100.  -400.    21.5]], ep_loss: 14.278674125671387\n",
      "\n",
      "TX Location: [[-200.  -200.    21.5]], Goal steps: 16, ep_actions: [11, 10, 12, 9, 13, 8, 14, 7, 15, 6, 0, 5, 1, 4, 2, 3], prevep_bestaction: 11\n",
      "Episode 5998,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 11, ep_len: 16, TXloc: [[-200.  -200.    21.5]], ep_loss: 14.830759048461914\n",
      "\n",
      "TX Location: [[-200.  -500.    21.5]], Goal steps: 16, ep_actions: [9, 8, 10, 7, 11, 6, 12, 5, 13, 4, 14, 3, 15, 2, 0, 1], prevep_bestaction: 9\n",
      "Episode 5999,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 9, ep_len: 16, TXloc: [[-200.  -500.    21.5]], ep_loss: 13.636810302734375\n",
      "\n",
      "TX Location: [[-400.  -300.    21.5]], Goal steps: 16, ep_actions: [12, 11, 13, 10, 14, 9, 15, 8, 0, 7, 1, 6, 2, 5, 3, 4], prevep_bestaction: 12\n",
      "Episode 6000,\tScore: 1.00, eps: 0.5, moving avg_rwd: 1.0, current_best action: 12, ep_len: 16, TXloc: [[-400.  -300.    21.5]], ep_loss: 14.711470603942871\n",
      "\n",
      "\r"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6000 \t 200 episode moving avg: 1.0\r",
      "No. of false positives: 0\n"
     ]
    }
   ],
   "source": [
    "ep_rewards = []\n",
    "test_rewards = []\n",
    "test_data_rates = []\n",
    "test_eps_iters=[]\n",
    "test_minexh_rates = []\n",
    "test_maxexh_rates = []\n",
    "false_positives =0\n",
    "policy_net.train()\n",
    "test_txbdir = 0\n",
    "dqneplen_list = [min_episode_length for i in range(em.env.obs_space.nvec[3] * len(em.env.tx_locs))]\n",
    "dqnloc_count = [0 for i in range(em.env.obs_space.nvec[3] * len(em.env.tx_locs))]\n",
    "#iter_avg_error = [[] for i in range(em.env.obs_space.nvec[3] * len(em.env.tx_locs))]\n",
    "#loc_errors = [[] for i in range(em.env.obs_space.nvec[3] * len(em.env.tx_locs)) ]\n",
    "loc_errors = [0.0 for i in range(em.env.obs_space.nvec[3] * len(em.env.tx_locs)) ]\n",
    "iter_avg_error = []\n",
    "iter_errors = []\n",
    "\n",
    "outer = tqdm.notebook.tqdm(total=episodes, desc='training loop: ', position=0)\n",
    "train_steps = 0\n",
    "em.env.goal_steps = min_episode_length\n",
    "for episode in range(episodes):\n",
    " \n",
    "    \n",
    "    ep_rwd = 0.0\n",
    "    timestep = 0\n",
    "    tx_dirs = []\n",
    "    rx_dirs = []\n",
    "    data_rates =[]\n",
    "    #agent.current_step +=1\n",
    "    train_steps +=1\n",
    "    ep_count = 0\n",
    "    prevep_bestaction = 0\n",
    "    \n",
    "    #changing from LoS to NLoS and viceversa\n",
    "    #if(episode == 2100):\n",
    "        #strategy = EpsilonGreedyStrategy(eps_start, eps_end, eps_decay, 1000)\n",
    "        #train_steps = 1\n",
    "    #    em.env.sc_xyz = np.array([[650,300,21.5], [0,-550,21.5]])#np.array([[-100,50,21.5], [-100,-50,21.5], [-50,100,21.5],[50,100,21.5]])#np.array([[-100,50,11.5], [-100,-50,11.5], [-50,100,11.5],[50,100,11.5]])#np.array([[50,0,0], [-50,-100,0], [100,50,0],[50,-100,0]])#np.array([[0,100,0], [10,50,0], [40,60,0], [70,80,0], [100,50,0], [80,85,0], [20,30,0], [10,40,0], [80,20,0]])#np.array([[0,100,0]])#np.array([[0,100,0],[250,0,0],[-200,-150,0]]) #reflection points for now\n",
    "    #    em.env.ch_model ='uma-nlos'#'uma-nlos' #free-space path loss model\n",
    "    #    em.env.init_ch_model = 'uma-nlos'\n",
    "        #em.env.goal_steps = min_episode_length\n",
    "        #max_episode_length = 3\n",
    "        #print(\"came here\")\n",
    "    #3if(episode == 3000):\n",
    "        #strategy = EpsilonGreedyStrategy(eps_start, eps_end, eps_decay, 1000)\n",
    "        #train_steps = 1\n",
    "    #    em.env.sc_xyz = np.array([])#np.array([[650,300,21.5], [0,-550,21.5]])#np.array([[-100,50,21.5], [-100,-50,21.5], [-50,100,21.5],[50,100,21.5]])#np.array([[-100,50,11.5], [-100,-50,11.5], [-50,100,11.5],[50,100,11.5]])#np.array([[50,0,0], [-50,-100,0], [100,50,0],[50,-100,0]])#np.array([[0,100,0], [10,50,0], [40,60,0], [70,80,0], [100,50,0], [80,85,0], [20,30,0], [10,40,0], [80,20,0]])#np.array([[0,100,0]])#np.array([[0,100,0],[250,0,0],[-200,-150,0]]) #reflection points for now\n",
    "    #    em.env.ch_model ='uma-los'#'uma-nlos' #free-space path loss model\n",
    "    #    em.env.init_ch_model = 'uma-los'\n",
    "    \n",
    "    #Testing the last 100 episodes\n",
    "    #if((episode+1) == (episodes-100)):\n",
    "    #    em.env.goal_steps= min_episode_length\n",
    "    if ((episode+1) >= (episodes+100)):\n",
    "        eps = 0.5#strategy.get_exploration_rate(train_steps)\n",
    "        tx_num = em.env.get_txloc_ndx(np.array([[-100,-100,21.5]]))#*np.cos(58*np.pi/180)\n",
    "        rbdir_ndx = em.env.dqnbestbeam_ndxlist[tx_num * em.env.obs_space.nvec[3] + test_txbdir]\n",
    "        obs = em.test_reset(np.array([[-100,-100,21.5]]), em.env.sc_xyz, ch_randvals[episode], rbdir_ndx,test_txbdir)\n",
    "        dqneplen_list[tx_num * em.env.obs_space.nvec[3] + em.env.txdir_ndx] = min_episode_length\n",
    "        #dqnloc_count[tx_num * em.env.obs_space.nvec[3] + em.env.txdir_ndx] +=1\n",
    "    else:\n",
    "        eps = 0.5\n",
    "        obs = em.reset(ch_randvals[episode], episode+1)\n",
    "        tx_num = em.env.get_txloc_ndx(em.env.tx_loc)\n",
    "        dqnloc_count[tx_num * em.env.obs_space.nvec[3] + em.env.txdir_ndx] +=1\n",
    "        \n",
    "    #if (episode ==100):\n",
    "    #    for tx_loc in em.env.tx_locs:\n",
    "    #        tx_num = em.env.get_txloc_ndx(tx_loc)\n",
    "    #        dqneplen_list[tx_num * em.env.obs_space.nvec[3] + em.env.txdir_ndx] = min_episode_length\n",
    "    #    em.env.goal_steps = min_episode_length\n",
    "    #    max_episode_length = 3\n",
    "    \n",
    "    em.env.goal_steps = dqneplen_list[tx_num * em.env.obs_space.nvec[3] + em.env.txdir_ndx]\n",
    "    init_obs = obs\n",
    "    temp_val = []\n",
    "    ep_actions = []  \n",
    "    #rbdir_ndx = em.env.dqnbestbeam_ndxlist[tx_num * self.obs_space.nvec[3] + test_txbdir]\n",
    "    \n",
    "    #ep_actions.append(em.env.rbdir_ndx)\n",
    "    #init_randaction = em.env.rbdir_ndx\n",
    "    policy_net.eval()\n",
    "    with torch.no_grad():\n",
    "        action_probs = policy_net(obs).detach().data.cpu().numpy()[0]  \n",
    "    policy_net.train()\n",
    "    actions= np.argsort(action_probs)[::-1]\n",
    "\n",
    "    em.env.action_list = []\n",
    "    em.env.action_list.append(em.env.rbdir_ndx)\n",
    "\n",
    "    selected_actions = []\n",
    "    selected_actions.append(actions[0])\n",
    "    ep_actions.append(actions[0])\n",
    "    \n",
    "    #Re-collect the previous stored best dqn action for the TXlocation\n",
    "    #em.env.prev_bestaction#\n",
    "    tx_num = em.env.get_txloc_ndx(em.env.tx_loc)\n",
    "    prevep_bestaction = actions[0]#em.env.dqnbestbeam_ndxlist[tx_num * em.env.obs_space.nvec[3] + em.env.txdir_ndx]\n",
    "    \n",
    "    #Store the current best dqn action for the episode\n",
    "    tx_num = em.env.get_txloc_ndx(em.env.tx_loc)\n",
    "    #em.env.dqnbestbeam_ndxlist[em.env.tx_num * em.env.obs_space.nvec[3] + em.env.txdir_ndx] = actions[0]\n",
    "\n",
    "    nbour_len = 0\n",
    "    if (em.env.goal_steps % 2 == 0):\n",
    "        nbour_len = int((em.env.goal_steps)/2)+1\n",
    "    else:\n",
    "        nbour_len = int((em.env.goal_steps)/2)+1\n",
    "    for i in range(1,nbour_len):\n",
    "        if ((actions[0]-i) < 0):\n",
    "            selected_actions.append(em.env.N_rx+actions[0]-i)\n",
    "            ep_actions.append(em.env.N_rx+actions[0]-i)\n",
    "        else:\n",
    "            selected_actions.append(actions[0]-i)\n",
    "            ep_actions.append(actions[0]-i)\n",
    "        if((i+1)<nbour_len) or (not(em.env.goal_steps % 2 == 0)):\n",
    "        #if(len(selected_actions) < (em.env.goal_steps)):\n",
    "            #if ((actions[0]+i) > (em.env.N_rx-1)):\n",
    "            #    selected_actions.append(actions[0]+i -em.env.N_rx)\n",
    "            #    ep_actions.append(actions[0]+i -em.env.N_rx)\n",
    "            #else:\n",
    "            selected_actions.append((actions[0]+i) % em.env.N_rx)\n",
    "            ep_actions.append((actions[0]+i) % em.env.N_rx)\n",
    "        #else:\n",
    "        #    selected_actions.append((actions[0]+i) % em.env.N_rx)\n",
    "        #    ep_actions.append((actions[0]+i) % em.env.N_rx)\n",
    "\n",
    "    em.env.reward_list = []\n",
    "    em.env.reward_list.append(float(np.around(1.0, decimals=2)))\n",
    "\n",
    "    #tx_dirs.append((em.env.tx_bdir[0]*(180/np.pi), em.env.tx_bdir[1]))\n",
    "    #rx_dirs.append((em.env.rx_bdir[0]*(180/np.pi), em.env.rx_bdir[1]))\n",
    "    #data_rates.append(em.env.rate)\n",
    "    \n",
    "\n",
    "    memory = ReplayBuffer(available_actions, em.env.goal_steps, em.env.goal_steps, seed, device)\n",
    "    #memory.memory = em.env.goal_steps\n",
    "    #memory.batch_size = em.env.goal_steps\n",
    "    #print(\"TX Location: {}, Goal steps: {}, init_randaction: {},ep_actions: {}, prevep_bestaction: {}\".format(em.env.tx_loc, em.env.goal_steps, init_randaction, ep_actions,prevep_bestaction))\n",
    "    if PRIORITIZED_REPLAY:\n",
    "        beta = beta_strategy.get_exploration_rate(train_steps)\n",
    "    temp_actions = []\n",
    "    temp_rewards = []\n",
    "    temp_rates = []\n",
    "    temp_bestrates = []\n",
    "    rwd_action = -1\n",
    "    for i in range(len(selected_actions)):\n",
    "        \n",
    "        #print(action)\n",
    "        action = selected_actions[i]\n",
    "        action = torch.tensor(np.array([action]), dtype=torch.long).to(device)\n",
    "        next_obs, reward, done, _ = em.step(action)\n",
    "        if(reward.item() == 1.0):\n",
    "            rwd_action = action.item()\n",
    "        em.env.action_list.append(action.item())\n",
    "        em.env.reward_list.append(float(np.around(reward.item(), decimals=2)))\n",
    "        tx_dirs.append((em.env.tx_bdir[0]*(180/np.pi), em.env.tx_bdir[1]))\n",
    "        rx_dirs.append((em.env.rx_bdir[0]*(180/np.pi), em.env.rx_bdir[1]))\n",
    "        data_rates.append(em.env.rate)\n",
    "\n",
    "        ep_rwd += reward.item()\n",
    "        \n",
    "        min_exh_rate, max_exh_rate,min_action_ndx,max_action_ndx,min_rssi_val,max_rssi_val = em.env.get_minmax_exhrate(ch_randvals[episode])\n",
    "        \n",
    "        next_qactionvals = target_net(next_obs).detach().data.cpu().numpy()[0]\n",
    "        next_qactions= np.argsort(next_qactionvals)[::-1]\n",
    "        \n",
    "        next_act = torch.tensor(np.array([next_qactions[0]]), dtype=torch.long).to(device)\n",
    "        #print(\"obs: {}, action: {}, reward: {}, next_obs:{}, next_action: {}, done: {}\".format(obs, action, reward, next_obs, next_act, done))\n",
    "        #print(\"action: {}, reward: {}\".format(action, reward))\n",
    "        temp_actions.append(action.item())\n",
    "        temp_rewards.append(reward.item())\n",
    "        temp_rates.append(em.env.rate)\n",
    "        temp_bestrates.append(em.env.best_rate)\n",
    "        #print(\"dqnactionlist: {}, Next qactionvals: {}, next_qactions: {}, selected_nextact:{}\".format(agent.dqnaction_list,next_qactionvals, next_qactions, next_act))\n",
    "        #print(action)\n",
    "        memory.add(obs, action, reward, next_obs, next_act, done)\n",
    "        \n",
    "        #tensors\n",
    "        #current_qval = policy_net(obs).gather(1,index=action.unsqueeze(-1))\n",
    "        #next_qval = target_net(next_obs).detach().gather(1,index=next_act.unsqueeze(-1))\n",
    "        #target_qval = ((next_qval*GAMMA*(~done.unsqueeze(-1))) + reward.unsqueeze(-1))\n",
    "        #iter_lossval = ALPHA*(target_qval-current_qval)\n",
    "        #temp_val.append(iter_lossval)\n",
    "        #print(next_qval)\n",
    "        obs = next_obs\n",
    "        timestep +=1\n",
    "#if memory.can_provide_sample():\n",
    "    if PRIORITIZED_REPLAY:\n",
    "        experiences = memory.sample(beta)\n",
    "        observations, actions, rewards, next_observations, dones, weights, batch_indices = experiences\n",
    "    else:\n",
    "        experiences = memory.sample()\n",
    "        observations, actions, rewards, next_observations, next_actions, dones = experiences\n",
    "        weights, batch_indices = torch.tensor(np.ones_like(rewards.cpu().data.numpy())).to(device), None\n",
    "\n",
    "    #print(observations.shape, observations.dtype)\n",
    "    #print(actions.unsqueeze(-1).shape)\n",
    "    current_q_values = policy_net(observations).gather(1,index=actions.unsqueeze(-1))#(1-ALPHA)*\n",
    "\n",
    "    #next_q_values = target_net(next_observations).detach().max(1)[0]\n",
    "    next_q_values = target_net(next_observations).detach().gather(1,index=next_actions.unsqueeze(-1))#min(1)[0]\n",
    "    #next_q_actionvals = target_net(next_observations).detach().data.cpu().numpy()[0]\n",
    "    #next_qactions = np.argsort(next_q_actionvals)[::-1]\n",
    "    #for i in range(len(next_qactions)):\n",
    "    #    if next_qactions[i] not in agent.dqnaction_list:\n",
    "\n",
    "    target_q_values = ((next_q_values*GAMMA*(~dones.unsqueeze(-1))) + rewards.unsqueeze(-1))\n",
    "    #print(current_q_values.size())\n",
    "    #print(target_q_values.size())\n",
    "    #print(dones.unsqueeze(-1).size())\n",
    "    #print(next_actions.size(), actions.size(), next_q_values.size(), rewards.unsqueeze(-1).size())\n",
    "    ep_loss = F.mse_loss(current_q_values, target_q_values.float(), reduction='sum')\n",
    "    #ep_loss = (1-ALPHA)*torch.ones(loss.size()).to(device)+ ALPHA*loss\n",
    "  #  td_errors = ALPHA*(target_q_values.unsqueeze(1).float()-current_q_values)\n",
    "    #ep_loss = F.mse_loss(torch.zeros(current_q_values.size()).to(device), ALPHA*(target_q_values.float()-current_q_values),  reduction='sum')\n",
    "    #loss = F.l1_loss(torch.zeros(current_q_values.size()).to(device), ALPHA*(target_q_values.unsqueeze(1).float()-current_q_values),  reduction=None)\n",
    "    #loss = F.cross_entropy(torch.zeros(current_q_values.size()).to(device), ALPHA*(target_q_values.unsqueeze(1).float()-current_q_values),  reduction='mean')\n",
    "    #loss = F.cross_entropy(current_q_values, target_q_values.unsqueeze(1).long(),  reduction='mean')\n",
    "    #print(target_q_values.float()-current_q_values)\n",
    "    #weighted_loss = torch.mean(weights*loss)\n",
    "    #print(\"loss: \", loss)\n",
    "    #loss = ALPHA*loss\n",
    "    #ep_loss += weighted_loss.item()\n",
    " #   ep_loss = loss.item()\n",
    "    #ep_lossval = torch.cat(temp_val, dim=0)\n",
    "    #print(temp_val, temp_val.size())\n",
    "    #ep_lossval = torch.tensor(ep_lossarr,dtype=torch.float32).to(device)\n",
    "\n",
    "    #ep_loss = torch.sum(ep_lossval, dim=0)\n",
    "    #print(ep_lossval,ep_loss.item())\n",
    "    #loss = F.mse_loss(torch.zeros(ep_lossval.size()).to(device), ep_lossval, reduction='sum')\n",
    "    optimizer.zero_grad()\n",
    "    #weighted_loss.backward()\n",
    "    ep_loss.backward()\n",
    "    #loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    #if PRIORITIZED_REPLAY:\n",
    "    #    comp_errors = np.array([x[0] for x in td_errors.cpu().data.numpy()])\n",
    "    #    new_priorities = np.abs(comp_errors) + 1e-6\n",
    "        #print(new_priorities)\n",
    "    #    memory.update_priorities(batch_indices.cpu().data.numpy(), new_priorities)\n",
    "\n",
    "    #Update the policy network\n",
    "    if episode % UPDATE_EVERY == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "    #for local_param, target_param in zip(policy_net.parameters(), target_net.parameters()):\n",
    "    #    target_param.data.copy_(TAU*local_param.data + (1.0-TAU)*target_param.data)\n",
    "\n",
    "    #if memory.can_provide_sample():\n",
    "    \n",
    "    tx_num = em.env.get_txloc_ndx(em.env.tx_loc)\n",
    "    policy_net.eval()\n",
    "    with torch.no_grad():\n",
    "        action_probs = policy_net(init_obs).detach().data.cpu().numpy()[0]  \n",
    "    policy_net.train()\n",
    "    bestaction= np.argsort(action_probs)[::-1][0]\n",
    "    #em.env.dqnbestbeam_ndxlist[tx_num * em.env.obs_space.nvec[3] + em.env.txdir_ndx] = bestaction\n",
    "    \n",
    "    print(\"TX Location: {}, Goal steps: {}, ep_actions: {}, prevep_bestaction: {}\".format(em.env.tx_loc, em.env.goal_steps, ep_actions,prevep_bestaction))\n",
    "    \n",
    "    if not(prevep_bestaction == bestaction):\n",
    "        em.env.goal_steps = min(em.env.goal_steps + episode_delta, max_episode_length)\n",
    "        dqneplen_list[tx_num * em.env.obs_space.nvec[3] + em.env.txdir_ndx] = em.env.goal_steps\n",
    "    if (prevep_bestaction == bestaction) and (not(rwd_action == bestaction)):\n",
    "        print(\"tx_loc:{} not converged until episode: {}\".format(em.env.tx_loc, episode+1))\n",
    "        \n",
    "    ep_rewards.append(ep_rwd)\n",
    "    moving_avg_rwd = get_moving_average(100, ep_rewards)\n",
    "    #if (ep_rwd > 1.0):\n",
    "    print('Episode {},\\tScore: {:.2f}, eps: {}, moving avg_rwd: {}, current_best action: {}, ep_len: {}, TXloc: {}, ep_loss: {}\\n\\n'.format(episode+1, ep_rwd, eps, moving_avg_rwd[-1], bestaction, em.env.rbdir_count, em.env.tx_loc, ep_loss.item()), end=\"\\r\")\n",
    "    \n",
    "    \n",
    "    #get the average error between exhaustive and learnt rate for all TXlocations\n",
    "    #iter_error = Compute_AvgError(em, device, policy_net, ch_randvals[episode])\n",
    "    #iter_avg_error.append(iter_error)\n",
    "    rx_bdir =em.env.BeamSet[bestaction]                \n",
    "    wRF = ula.var_steervec(em.env.N_rx, rx_bdir , 0)\n",
    "    rssi_val = np.sqrt(em.env.N_rx*em.env.N_tx)*np.array(np.conj(wRF.T).dot(em.env.eff_ch)) #+ (np.conj(wRF.T).dot(self.noise))[0]\n",
    "    Es = db2lin(em.env.P_tx)  # * (1e-3 / self.B)\n",
    "    SNR = Es * np.abs(rssi_val) ** 2 / (em.env.N0 * em.env.B)\n",
    "    dqn_rate = np.log2(1 + SNR)\n",
    "    \n",
    "    SNR_exh = Es * np.abs(max_rssi_val) ** 2 / (em.env.N0 * em.env.B)\n",
    "    error = 10*np.log10(SNR_exh)-10*np.log10(SNR)#max_exh_rate - dqn_rate\n",
    "    iter_errors.append(error)\n",
    "    \n",
    "    tx_num = em.env.get_txloc_ndx(em.env.tx_loc)\n",
    "    loc_errors[tx_num * em.env.obs_space.nvec[3] + em.env.txdir_ndx] = error\n",
    "    iter_avg_error.append(np.mean(loc_errors))\n",
    "\n",
    "    #loc_errors[tx_num * em.env.obs_space.nvec[3] + em.env.txdir_ndx].append(error)\n",
    "    #iter_avg_error[tx_num * em.env.obs_space.nvec[3] + em.env.txdir_ndx].append(np.mean(loc_errors[tx_num * em.env.obs_space.nvec[3] + em.env.txdir_ndx]))\n",
    "    #iter_error = Compute_AvgError(em, device, policy_net, ch_randvals[episode])\n",
    "    #iter_avg_error.append(iter_error)\n",
    "    timestep = 0\n",
    "        \n",
    "            \n",
    "    # update tqdm bar\n",
    "    outer.update(1)\n",
    "    \n",
    "torch.save(policy_net.state_dict(), 'checkpoint.pth')\n",
    "plot(ep_rewards, 200, test_rewards) \n",
    "print(\"No. of false positives: {}\".format(false_positives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure(figsize=[9, 6])\n",
    "min_ndx=0\n",
    "max_ndx=6000\n",
    "#for ndx in range(em.env.obs_space.nvec[3] * len(em.env.tx_locs)):\n",
    "#        plt.plot(loc_errors[ndx][min_ndx:max_ndx])\n",
    "plt.plot(iter_avg_error[min_ndx:max_ndx])\n",
    "#plt.xticks(np.arange(0, max_ndx-min_ndx), [str(x) for x in np.arange(min_ndx, max_ndx)])\n",
    "#plt.legend(['learnt rate','min exhrate', 'max exhrate'])\n",
    "plt.xlabel('Episode #')\n",
    "plt.ylabel('Average Error (Exh-DQN) (dB)')\n",
    "plt.title('Average errors over all locations vs Episode #')\n",
    "plt.show()\n",
    "plt.show()\n",
    "#print(np.mean(iter_avg_error), len(iter_avg_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3262758996985577 6000\n"
     ]
    }
   ],
   "source": [
    "fig=plt.figure()\n",
    "min_ndx=0\n",
    "max_ndx=1600\n",
    "plt.plot(iter_errors[min_ndx:max_ndx])\n",
    "#plt.xticks(np.arange(0, max_ndx-min_ndx), [str(x) for x in np.arange(min_ndx, max_ndx)])\n",
    "#plt.legend(['learnt rate','min exhrate', 'max exhrate'])\n",
    "plt.xlabel('Episode #')\n",
    "plt.ylabel('Episode Error (Exh-DQN) (bits/s)')\n",
    "plt.title('Iteration errors over all locations vs Episode #')\n",
    "plt.show()\n",
    "plt.show()\n",
    "print(np.mean(iter_errors), len(iter_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9055831611552335, 1.711002922954017, 2.5988580294203687, 3.133285445857362, 4.122067749536174, 3.6439147638440192, 4.483772158935178, 6.006233699772192, 5.820942316350756, 6.522576512364525, 7.432255488997336, 7.432255488997336, 7.618207855750358, 7.618207855750358, 8.313442821859569, 9.414848043780689, 9.846911070105676, 9.126218973012861, 9.126218973012861, 10.013773334919906, 10.013773334919906, 10.687575132051336, 10.470481044203895, 11.35985619970328, 11.35985619970328, 11.031874848778523, 10.772609047153065, 10.260733002986662, 10.889146931733087, 9.547404928775286, 8.024943387938274, 8.801846754066643, 8.928409549630645, 9.758830803381926, 10.44305454015351, 11.220775230689505, 12.616680247159854, 12.616680247159854, 11.811260485361071, 12.405686083708385, 12.475607087376229, 12.475607087376229, 12.475607087376229, 12.216330380133735, 12.216330380133735, 12.216330380133735, 12.216330380133735, 11.940021620039168, 11.04107697306582, 10.540482367032016, 10.485992631680146, 10.544029987005962, 10.602076582992568, 10.602076582992568, 10.602076582992568, 10.716913025512026, 12.141813536803143, 11.446578570693932, 11.39291451106064, 11.39291451106064, 11.470463079061016, 10.582607972594666, 11.139642680088901, 12.09974173346135, 13.399762719317906, 14.182703531401389, 14.182703531401389, 13.139219673779543, 13.139219673779543, 13.139219673779543, 12.920708688592981, 12.920708688592981, 12.920708688592981, 13.964192546214827, 13.90614595022822, 13.90614595022822, 13.848108594902406, 14.476788990766464, 15.253692356894833, 14.625278428148409, 15.362061314299986, 15.085752554205419, 14.281319675654904, 14.269339998103847, 14.883232558066451, 14.883232558066451, 14.25491179692512, 13.477191106389123, 13.624542817750143, 13.624542817750143, 13.717326077396265, 14.52175895594678, 14.52175895594678, 14.521761773941996, 14.310402261904674, 15.227448403764496, 17.06509557971664, 16.171615992528924, 17.15423922466513, 16.141148952755085, 16.889407386113607, 16.013683314384004, 16.743345343807174, 15.875701854712355, 15.875701854712355, 15.875701854712355, 16.093888828355926, 16.724015192585167, 16.25206551932121, 15.69503081182697, 15.487613351880546, 15.487613351880546, 15.487613351880546, 15.487613351880546, 13.649966175928405, 13.649966175928405, 12.76889739976006, 10.992279258461409, 10.992279258461409, 10.556101320165865, 10.614165848382346, 11.627253302297177, 11.71630001093438, 10.986637981511208, 10.356903980091495, 11.084977468877891, 12.259377012081178, 11.89009426357578, 11.671907289932214, 11.579146483086689, 11.579146483086689, 11.579146483086689, 11.579146483086689, 10.65881983601738, 10.65881983601738, 11.117393066862967, 12.08252815029814, 12.08252815029814, 12.08252815029814, 11.468635590335534, 11.468635590335534, 12.349704366503879, 11.800132061417695, 10.840033008045246, 10.840033008045246, 10.840033008045246, 12.677680183997387, 12.677680183997387, 12.80414796373514, 12.80414796373514, 11.594821548924331, 11.200578233468594, 11.299410737647513, 11.823490013995036, 11.823490013995036, 11.823490013995036, 11.823490013995036, 10.840866781858827, 10.840866781858827, 10.840866781858827, 10.840866781858827, 10.742034277679904, 10.742034277679904, 11.23397100843732, 12.041366287963433, 12.041366287963433, 12.041366287963433, 11.411239923734193, 11.880519573543625, 11.880519573543625, 11.880519573543625, 11.880519573543625, 11.073124294017514, 10.107989210582343, 10.107989210582343, 10.107989210582343, 10.270531853199538, 10.270531853199538, 11.538759248678284, 11.538759248678284, 11.538759248678284, 12.503894332113454, 12.503894332113454, 13.624132144678434, 14.252546073424856, 14.936769810196438, 15.767191063947719, 15.767191063947719, 15.767191063947719, 15.767191063947719, 16.397317428176958, 15.768903499430534, 15.04083001064414, 15.25901698428771, 16.179343631357014, 16.438205167092978, 17.901159925250212, 17.417694814713137, 16.944208949821576, 18.787798877293575, 19.65624589511168, 18.388018499632935, 18.388018499632935, 18.388018499632935, 19.597344914443745, 19.597344914443745, 19.698899370411606, 18.452193778108878, 18.452193778108878, 18.452193778108878, 20.054193029010435, 19.42591537434588, 19.982950081840116, 19.982950081840116, 19.52437685099453, 18.836410834263077, 18.836410834263077, 18.836410834263077, 16.99282090679108, 16.99282090679108, 16.99282090679108, 16.99282090679108, 16.891266450823217, 16.891266450823217, 16.207042714051635, 15.586575081311034, 15.368388107667466, 15.893811481781718, 15.893811481781718, 15.893811481781718, 15.893811481781718, 15.242192673254785, 15.341025177433707, 15.46749295717146, 15.389944389171083, 15.389944389171083, 15.014611827693422, 14.992536192019488, 14.73367465628353, 14.73367465628353, 14.693000846853556, 14.199886390513111, 14.199886390513111, 14.240560199943083, 13.127864257501228, 13.007843697546923, 11.170196521594784, 11.388383495238351, 11.388383495238351, 11.388383495238351, 10.53932129704372, 10.53932129704372, 10.53932129704372, 10.53932129704372, 10.913775265785844, 10.913775265785844, 10.913775265785844, 9.052630798502015, 9.26004825844844, 9.880515891189042, 9.880515891189042, 9.880515891189042, 9.748949329321237, 10.694384867476753, 10.694384867476753, 10.073917234736152, 10.073917234736152, 9.975084730557233, 9.975084730557233, 10.524657035643415, 10.524657035643415, 10.306470061999848, 10.958088870526781, 10.488809220717346, 10.488809220717346, 10.412958322638728, 10.412958322638728, 9.582537068887447, 9.832897640919322, 9.4584436721772, 11.29609084812934, 11.373639416129718, 12.103357985013279, 11.186311843153453, 11.915973872576624, 11.42403714181921, 11.297569362081456, 10.567850793197895, 10.69657977287124, 8.8589325969191, 8.333509222804848, 8.333509222804848, 7.603847193381677, 7.82235817856824, 7.82235817856824, 7.82235817856824, 7.82235817856824, 6.522337192711684, 6.522337192711684, 6.522337192711684, 6.522337192711684, 6.781198728447646, 7.742415109014494, 7.742415109014494, 7.742415109014494, 7.742415109014494, 7.742415109014494, 7.800573803763443, 7.800573803763443, 7.539663855474316, 8.226408779554855, 8.226408779554855, 8.620652095010593, 9.853368597406755, 9.853368597406755, 8.955117586011383, 9.487055281595191, 8.238202242202863, 8.238202242202863, 9.198301295575314, 9.198301295575314, 9.198301295575314, 9.198301295575314, 9.198301295575314, 8.94794072354344, 8.425909859749083, 8.425909859749083, 8.425909859749083, 9.385252465375157, 9.916673389478557, 8.956574336106106, 9.440039446643182, 9.3138440122305, 9.3138440122305, 8.352627631663651, 8.352627631663651, 8.352627631663651, 8.352627631663651, 7.665882707583114, 7.665882707583114, 7.665882707583114, 8.914735746975442, 7.682019244579281, 7.682019244579281, 8.41168127400245, 8.41168127400245, 8.513235729970313, 8.816016384494887, 9.59895719657837, 9.59895719657837, 9.674808094656987, 10.019497509159443, 10.019497509159443, 9.674808094656987, 10.57305910605236, 10.041121410468552, 9.07598632703338, 8.03909515340693, 9.52426399680836, 9.466105302059411, 9.096822553554016, 8.404657697106783, 8.404657697106783, 8.86323092795237, 8.86323092795237, 8.86323092795237, 9.513580624230395, 9.16051192382465, 9.276619547927524, 10.390547445976354, 10.261818466303007, 10.319977161051957, 11.426804724331562, 11.426804724331562, 13.261734880820502, 15.099382056772642, 14.84052052103668, 14.969249500710026, 14.82252099080287, 14.82252099080287, 12.98487381485073, 12.98487381485073, 13.354156563356126, 11.868987719954696, 11.868987719954696, 11.868987719954696, 11.868987719954696, 11.868987719954696, 12.496617473191664, 13.768714064368673, 13.966855158323973, 13.218596724965447, 11.946500133788438, 13.431668977189867, 13.431668977189867, 13.431668977189867, 13.431668977189867, 13.447604855317707, 12.923652392483126, 12.832000356928779, 13.363938052512587, 13.678723439669733, 14.370888296116966, 13.50244127829886, 12.978362001951341, 13.037481897294082, 12.076265516727238, 12.076265516727238, 11.44863576349027, 10.916698067906461, 11.6739706185826, 12.105929700277867, 11.64601116731327, 11.64601116731327, 11.331225780156124, 11.177251753158115, 12.662420596559546, 12.703094405989518, 11.59788281838414, 11.223428849642016, 9.738260006240587, 10.486518439599113, 10.384963983631248, 10.384963983631248, 9.734614287353223, 8.93337245715256, 8.93337245715256, 8.401951533049159, 7.278923254836774, 6.884679939381036, 6.884679939381036, 7.376616670138451, 7.260509046035578, 7.260509046035578, 7.260509046035578, 7.260509046035578, 7.260509046035578, 7.260509046035578, 8.506499383197912, 8.506499383197912, 9.030578659545432, 10.891723126829259, 11.384837583169702, 11.384837583169702, 11.384837583169702, 10.152373511749934, 9.266371981400452, 9.266371981400452, 9.266371981400452, 8.773257525060009, 8.281320794302594, 7.066144795577019, 7.066144795577019, 7.066144795577019, 7.05020891744918, 7.05020891744918, 7.127757485449557, 5.881767148287223, 5.1520485794036635, 5.1520485794036635, 6.452069565260217, 5.723110696852057, 5.851839676525401, 6.110701212261362, 6.212255668229225, 6.212255668229225, 6.083526688555881, 4.783505702699325, 4.783505702699325, 4.783505702699325, 4.783505702699325, 4.783505702699325, 5.094941842259411, 5.211049466362284, 5.939122955148679, 5.939122955148679, 5.939122955148679, 5.133500898361908, 5.133500898361908, 5.133500898361908, 5.234748999038654, 5.250684877166493, 5.9055688156753625, 5.9055688156753625, 6.437506511259172, 6.968927435362572, 6.968927435362572, 8.806574611314712, 8.806574611314712, 8.806574611314712, 8.806574611314712, 8.907445938899018, 8.781621177719076, 9.746756261154246, 9.746756261154246, 9.746756261154246, 9.214818565570438, 9.214818565570438, 9.214818565570438, 10.699987408971868, 11.32826506363642, 12.05722393204458, 10.847897517233774, 10.847897517233774, 10.847897517233774, 10.847897517233774, 10.434906921705826, 10.588880948703832, 10.588880948703832, 10.48337641826399, 9.753714388840818, 9.024755520432656, 8.765893984696696, 9.725993038069145, 9.710057159941307, 9.583589380203556, 10.115527075787364, 10.115527075787364, 10.204573784424564, 10.204573784424564, 12.048163711896564, 11.894189684898558, 11.894189684898558, 11.164637961450193, 10.640685498615612, 10.546653510186673, 10.546653510186673, 11.755979924997483, 11.755979924997483, 11.755979924997483, 11.755979924997483, 11.755979924997483, 11.833528492997857, 12.485147301524792, 12.485147301524792, 12.485147301524792, 12.485147301524792, 12.483098888971627, 12.394052180334425, 12.520519960072178, 10.682872784120038, 11.141446014965625, 11.141446014965625, 10.221119367896318, 10.72171397393012, 9.761614920557669, 9.761614920557669, 9.22967722497386, 8.707646361179506, 8.707646361179506, 9.842879476682896, 9.842879476682896, 9.842879476682896, 9.94443393265076, 8.983217552083913, 8.983217552083913, 8.856749772346157, 8.856749772346157, 8.856749772346157, 8.856749772346157, 8.856749772346157, 8.398176541500572, 7.241047138761603, 6.10581402325821, 6.7355480246779225, 7.259627301025444, 7.259627301025444, 7.947912360003633, 7.947912360003633, 6.982777276568462, 7.611098037709794, 9.213097288611351, 8.524812229633163, 7.908657626796184, 8.868756680168634, 8.767202224200771, 8.689653656200395, 8.689653656200395, 8.689653656200395, 9.221591351784204, 9.221591351784204, 8.690170427680805, 8.690170427680805, 7.998005571233572, 7.998005571233572, 7.939958975246964, 7.939958975246964, 8.673093258923773, 9.808326374427166, 9.806277961874, 11.082892422056588, 11.082892422056588, 12.097251057554834, 13.932706468036349, 14.464786993893648, 15.115136690171674, 14.958821082927761, 16.421775841084997, 15.770157032558064, 14.650859795182509, 14.177441401006709, 14.177441401006709, 13.65541053721235, 11.819955126730838, 11.946422906468593, 11.946422906468593, 12.598041714995524, 12.323480662164302, 13.015645518611537, 11.413646267709979, 10.758762329201108, 10.108412632923084, 10.600349363680499, 10.600349363680499, 10.600349363680499, 10.141776132834911, 10.141776132834911, 9.449611276387678, 9.449611276387678, 8.91767358080387, 8.271185484850525, 8.271185484850525, 8.793216348644881, 9.786448461288897, 9.786448461288897, 9.863997029289273, 9.863997029289273, 9.863997029289273, 9.863997029289273, 9.863997029289273, 9.863997029289273, 9.863997029289273, 9.863997029289273, 11.070649531113661, 11.762814387560892, 11.762814387560892, 10.453833656401661, 10.453833656401661, 10.32736587666391, 10.32736587666391, 9.635201020216677, 9.635201020216677, 9.005074655987437, 9.005074655987437, 8.851100628989432, 7.8520355061001235, 7.326612131985871, 6.119959630161483, 6.119959630161483, 6.119959630161483, 5.626845173821039, 4.998524412679707, 4.998524412679707, 5.6146790155166855, 5.716233471484548, 5.087819542738125, 5.81589303152452, 6.466242727802544, 6.592710507540297, 6.592710507540297, 6.592710507540297, 6.592710507540297, 6.592710507540297, 5.787088450753526, 5.787088450753526, 5.787088450753526, 5.1709338479165465, 5.825817786425416, 5.699622352012735, 5.598067896044873, 4.969790241380321, 3.976558128736306, 3.976558128736306, 5.439512886893542, 5.932627343233985, 6.038131873673827, 6.038131873673827, 6.038131873673827, 6.666452634815159, 6.666452634815159, 6.666452634815159, 6.144421771020805, 6.772835699767227, 6.279721243426784, 6.811658939010592, 7.427813541847573, 7.797096290352967, 7.797096290352967, 7.797096290352967, 8.17155025909509, 8.300279238768434, 7.649929542490411, 7.649929542490411, 9.485384952971923, 8.471026317473678, 8.471026317473678, 8.471026317473678, 8.471026317473678, 8.471026317473678, 8.342297337800334, 8.342297337800334, 8.342297337800334, 8.835411794140777, 8.835411794140777, 8.835411794140777, 8.835411794140777, 8.46612904563538, 7.003174287478143, 7.003174287478143, 8.86431875476197, 8.248164151924989, 10.223113357495485, 10.223113357495485, 10.915278213942718, 10.915278213942718, 9.68281414252295, 10.206893418870472, 9.713778962530027, 9.713778962530027, 10.066847662935773, 10.066847662935773, 10.066847662935773, 10.066847662935773, 9.692393694193651, 9.16831441784613, 6.677975068855747, 6.677975068855747, 6.677975068855747, 6.4807979640587545, 6.4807979640587545, 5.988861233301339, 5.988861233301339, 5.988861233301339, 5.988861233301339, 5.988861233301339, 5.988861233301339, 5.988861233301339, 5.988861233301339, 5.988861233301339, 6.165174108088162, 6.165174108088162, 6.165174108088162, 6.165174108088162, 6.165174108088162, 6.165174108088162, 6.696595032191563, 7.6617301156267335, 5.686780910056237, 5.686780910056237, 6.179895366396681, 6.646879963428688, 6.343462462191877, 6.343462462191877, 7.806417220349114, 7.806417220349114, 7.895463928986316, 7.436890698140728, 7.436890698140728, 6.4717556147055575, 6.4717556147055575, 5.008800856548321, 5.008800856548321, 5.008800856548321, 4.832487981761499, 4.832487981761499, 5.733598245493486, 6.363724609722726, 6.992002264387278, 6.363321868523218, 6.363321868523218, 6.363321868523218, 6.363321868523218, 5.7331955042939775, 6.948371503019554, 6.948371503019554, 7.02592007101993, 7.02592007101993, 6.333755214572697, 5.705434453431366, 5.8069889093992275, 5.8069889093992275, 4.889942767539403, 5.904301403037651, 5.904301403037651, 5.904301403037651, 5.276023748373099, 5.276023748373099, 5.276023748373099, 5.404752728046442, 5.404752728046442, 5.961787435540678, 5.961787435540678, 5.961787435540678, 5.961787435540678, 5.429849739956869, 5.555674501136812, 6.0194965649038785, 6.0194965649038785, 6.0194965649038785, 6.0194965649038785, 7.994445770474374, 6.910156073966706, 6.910156073966706, 7.368729304812294, 7.240000325138949, 7.240000325138949, 7.240000325138949, 7.240000325138949, 7.240000325138949, 7.240000325138949, 7.240000325138949, 7.240000325138949, 7.240000325138949, 9.101144792422776, 8.544110084928539, 9.066140948722897, 8.599156351690887, 8.599156351690887, 7.3666922802711206, 7.3666922802711206, 7.3666922802711206, 9.20162243676006, 9.20162243676006, 9.20162243676006, 9.203670849313225, 9.203670849313225, 9.203670849313225, 9.126122281312849, 9.126122281312849, 9.126122281312849, 9.126122281312849, 9.126122281312849, 9.024567825344986, 8.898100045607235, 9.390036776364648, 9.390036776364648, 8.174860777639072, 8.174860777639072, 8.174860777639072, 8.174860777639072, 6.830037936297817, 6.830037936297817, 6.830037936297817, 6.830037936297817, 7.4583586974391505, 7.4583586974391505, 8.150523553886382, 8.150523553886382, 8.150523553886382, 7.658586823128969, 7.658586823128969, 7.658586823128969, 7.305518122723222, 6.812403666382779, 8.275358424540016, 8.275358424540016, 7.260999789041769, 7.260999789041769, 7.260999789041769, 7.155495258601928, 7.771649861438907, 8.736784944874078, 7.273830186716841, 7.273830186716841, 7.273830186716841, 9.764169535707223, 9.764169535707223, 9.890637315444978, 9.9894698196239, 10.11566525403658, 11.60784483326633, 10.401192331441944, 10.401192331441944, 10.401192331441944, 10.401192331441944, 11.610518746252751, 10.645383662817578, 9.953218806370346, 11.168394805095922, 11.168394805095922, 11.322368832093927, 11.322368832093927, 12.336727467592175, 12.277607572249433, 12.898075204990034, 12.771607425252279, 12.151139792511678, 12.151139792511678, 12.151139792511678, 12.151139792511678, 12.151139792511678, 12.151139792511678, 11.594105085017443, 11.594105085017443, 11.594105085017443, 11.594105085017443, 10.384778670206636, 10.384778670206636, 10.384778670206636, 10.384778670206636, 10.384778670206636, 10.384778670206636, 10.384778670206636, 8.541188742734636, 7.912911088070084, 8.404847818827498, 8.404847818827498, 8.404847818827498, 6.308751785292852, 6.308751785292852, 6.308751785292852, 6.308751785292852, 6.308751785292852, 6.308751785292852, 6.308751785292852, 6.308751785292852, 6.308751785292852, 6.308751785292852, 6.308751785292852, 6.192644161189979, 6.192644161189979, 5.700707430432565, 4.208527851202814, 4.337256830876158, 4.353192709003997, 5.045357565451228, 5.414640313956625, 5.414640313956625, 5.288444879543943, 5.288444879543943, 6.521161381940105, 6.39243240226676, 6.39243240226676, 7.3575674857019315, 7.660348140226506, 8.191769064329906, 7.4996042078826735, 7.4996042078826735, 7.605108738322515, 7.605108738322515, 7.605108738322515, 7.663173266538996, 7.663173266538996, 7.605108738322515, 8.23352266706894, 8.86180032173349, 8.86180032173349, 8.86180032173349, 8.86180032173349, 7.89666523829832, 7.770840477118378, 7.770840477118378, 7.770840477118378, 7.770840477118378, 7.616866450120372, 7.616866450120372, 8.832042448845947, 8.832042448845947, 9.185111149251693, 9.185111149251693, 9.185111149251693, 9.310935910431635, 9.310935910431635, 9.310935910431635, 10.796104753833067, 10.796104753833067, 10.796104753833067, 10.796104753833067, 10.912212377935939, 12.118864879760327, 12.118864879760327, 12.118864879760327, 11.389906011352165, 11.516101445764848, 11.500165567637008, 11.500165567637008, 11.374340806457067, 11.374340806457067, 11.07156015193249, 11.07156015193249, 9.469560901030935, 9.469560901030935, 9.35345327692806, 8.894880046082474, 8.266199650218415, 8.266199650218415, 8.266199650218415, 8.266199650218415, 8.82323435771265, 8.194913596571318, 8.194913596571318, 6.359983440082378, 6.359983440082378, 5.965740124626641, 6.458854580967084, 6.458854580967084, 7.264476637753855, 7.264476637753855, 7.264476637753855, 7.264476637753855, 7.390301398933797, 7.390301398933797, 6.6622279101474025, 7.12080114099299, 7.209847849630191, 6.685768573282669, 6.685768573282669, 6.192654116942226, 6.066458682529546, 5.988910114529168, 5.988910114529168, 6.95404519796434, 6.95404519796434, 6.95404519796434, 5.988910114529168, 5.988910114529168, 6.520847810112977, 4.677257882640979, 4.677257882640979, 4.677257882640979, 4.677257882640979, 4.677257882640979, 4.693193760768817, 4.693193760768817, 4.677257882640979, 4.056790249900377, 4.056790249900377, 4.426072998405773, 4.426072998405773, 4.426072998405773, 4.503621566406149, 4.503621566406149, 5.027700842753671, 5.027700842753671, 5.027700842753671, 5.027700842753671, 5.027700842753671, 5.027700842753671, 5.027700842753671, 5.402470687607531, 5.402470687607531, 5.504025143575393, 5.504025143575393, 4.972087447991584, 4.972087447991584, 4.870532992023723, 4.870532992023723, 4.870532992023723, 4.870532992023723, 4.870532992023723, 4.870532992023723, 4.870532992023723, 4.870532992023723, 4.870532992023723, 4.870532992023723, 5.024507019021728, 5.555927943125128, 5.555927943125128, 5.055333337091326, 5.055333337091326, 4.498298629597088, 5.051167402001356, 5.16727502610423, 5.16727502610423, 5.470055680628804, 5.864298996084542, 5.864298996084542, 5.864298996084542, 5.864298996084542, 5.864298996084542, 5.864298996084542, 5.864298996084542, 5.864298996084542, 5.864298996084542, 5.864298996084542, 5.864298996084542, 5.864298996084542, 4.780009299576874, 4.780009299576874, 4.780009299576874, 4.780009299576874, 4.908738279250218, 4.780009299576874, 4.780009299576874, 4.780009299576874, 4.321436068731288, 4.321436068731288, 4.321436068731288, 4.321436068731288, 4.321436068731288, 4.321436068731288, 3.3282039560872727, 3.3282039560872727, 3.4569329357606167, 3.454884523207452, 3.0606412077517136, 3.0606412077517136, 3.0606412077517136, 3.1868366421643954, 2.8175538936589994, 2.9433786548389413, 4.786968582310941, 4.786968582310941, 4.786968582310941, 4.670860958208067, 4.670860958208067, 4.670860958208067, 4.670860958208067, 4.670860958208067, 4.544665523795386, 4.544665523795386, 2.7010755963233875, 3.258110303817623, 5.748449652808007, 4.850198641412633, 4.850198641412633, 4.850198641412633, 4.955703171852475, 4.955703171852475, 5.920838255287647, 5.920838255287647, 5.920838255287647, 5.920838255287647, 5.920838255287647, 5.39880739149329, 4.906870660735875, 4.906870660735875, 4.906870660735875, 4.906870660735875, 5.5990355171831085, 5.5990355171831085, 5.5990355171831085, 6.227449445929531, 6.227449445929531, 6.227449445929531, 6.227449445929531, 6.10162468474959, 6.10162468474959, 6.10162468474959, 6.10162468474959, 5.996120154309747, 5.367706225563324, 5.367706225563324, 5.367706225563324, 5.367706225563324, 5.367706225563324, 3.271610192028678, 3.271610192028678, 2.579445335581446, 2.63856523092419, 3.1391598369579925, 2.836379182433418, 2.836379182433418, 2.962574616846099, 2.962574616846099, 2.962574616846099, 2.962574616846099, 3.976933252344346, 3.976933252344346, 4.665218311322535, 5.3519632354030735, 5.3519632354030735, 6.313179615969923, 5.812585009936121, 5.812585009936121, 5.812585009936121, 5.683856030262777, 5.683856030262777, 6.643955083635226, 6.643955083635226, 7.336119940082458, 6.647834881104269, 6.647834881104269, 6.647834881104269, 6.647834881104269, 7.148429487138071, 7.679850411241471, 7.679850411241471, 8.201881275035827, 7.24066489446898, 7.367132674206732, 7.367132674206732, 7.367132674206732, 6.680387750126192, 6.680387750126192, 6.526413723128187, 6.526413723128187, 6.0043828593338295, 5.9452629639910874, 5.9452629639910874, 5.9452629639910874, 5.9452629639910874, 5.9452629639910874, 6.403836194836674, 8.238766351325614, 8.238766351325614, 8.238766351325614, 8.238766351325614, 8.16121778332524, 8.16121778332524, 7.808149082919495, 7.115984226472262, 7.6380150902666175, 7.6380150902666175, 6.431362588442229, 6.431362588442229, 5.471263535069778, 5.471263535069778, 5.471263535069778, 5.471263535069778, 5.471263535069778, 5.471263535069778, 5.471263535069778, 5.344795755332025, 5.360731633459864, 5.344795755332025, 5.344795755332025, 5.9731165164733575, 5.344838861808807, 5.344838861808807, 5.344838861808807, 5.344838861808807, 5.239334331368964, 4.682299623874728, 4.682299623874728, 4.682299623874728, 4.682299623874728, 4.28805630841899, 4.28805630841899, 3.7874617023851873, 3.7874617023851873, 3.7874617023851873, 3.7874617023851873, 3.7874617023851873, 3.7874617023851873, 3.88901615835305, 3.88901615835305, 3.2606953972117174, 3.2606953972117174, 3.38716317694947, 3.38716317694947, 3.38716317694947, 3.38716317694947, 3.38716317694947, 3.38716317694947, 3.38716317694947, 2.3728045414512233, 2.526778568449229, 2.526778568449229, 2.526778568449229, 2.526778568449229, 2.655507548122573, 2.655507548122573, 2.655507548122573, 2.529312113709892, 2.529312113709892, 3.0863468212041285, 3.0863468212041285, 3.1753935298413296, 3.1753935298413296, 3.046664550167985, 2.4896298426737493, 2.4896298426737493, 4.32455999916269, 4.198092219424938, 4.198092219424938, 4.198092219424938, 4.198092219424938, 4.198092219424938, 4.198092219424938, 4.044118192426931, 4.044118192426931, 4.044118192426931, 3.9425637364590695, 3.9425637364590695, 2.7359112346346803, 2.841415765074522, 2.841415765074522, 4.679062941026661, 4.679062941026661, 4.679062941026661, 4.679062941026661, 4.679062941026661, 3.713927857591491, 3.713927857591491, 4.2458655531753, 4.7389800095157435, 4.7389800095157435, 4.7389800095157435, 4.2169491457213875, 3.6850114501375777, 3.6850114501375777, 1.8473642741854384, 1.8473642741854384, 1.8473642741854384, 2.369395137979794, 2.369395137979794, 2.369395137979794, 1.7489275052391933, 1.7489275052391933, 1.7489275052391933, 2.143170820694931, 2.143170820694931, 2.143170820694931, 2.143170820694931, 2.143170820694931, 2.143170820694931, 2.143170820694931, 2.143170820694931, 2.143170820694931, 2.143170820694931, 2.143170820694931, 2.037666290255089, 2.037666290255089, 2.037666290255089, 2.037666290255089, 2.037666290255089, 1.4093886355905372, 1.4093886355905372, 1.4093886355905372, 1.4093886355905372, 1.4093886355905372, 1.4093886355905372, 0.8873577717961811, 0.8873577717961811, 0.8873577717961811, 0.8873577717961811, 0.8873577717961811, 1.4443924792904173, 1.4443924792904173, 1.4443924792904173, 1.4443924792904173, 1.5705879137030985, 1.6970556934408512, 1.6970556934408512, 1.6970556934408512, 1.140020985946615, 1.140020985946615, 1.140020985946615, 1.0138255515339338, 0.8873577717961811, 0.8873577717961811, 1.0413317987941868, 2.006466882229358, 2.006466882229358, 2.006466882229358, 2.006466882229358, 2.006466882229358, 2.006466882229358, 2.006466882229358, 2.006466882229358, 2.6986317386765903, 2.6986317386765903, 2.6986317386765903, 2.205517282336147, 1.811273966880409, 1.811273966880409, 1.811273966880409, 1.811273966880409, 1.6572999398824033, 0.9651350834351712, 1.465729689468974, 1.465729689468974, 1.465729689468974, 1.465729689468974, 1.465729689468974, 1.465729689468974, 1.465729689468974, 1.465729689468974, 1.465729689468974, 1.465729689468974, 1.98776055326333, 1.98776055326333, 1.98776055326333, 2.1142283330010825, 1.5921974692067267, 1.6081333473345651, 1.6081333473345651, 1.6081333473345651, 1.6081333473345651, 1.6081333473345651, 1.6081333473345651, 1.6081333473345651, 1.6081333473345651, 1.7368623270079093, 1.7368623270079093, 1.7368623270079093, 1.7368623270079093, 1.7368623270079093, 2.268283251111309, 2.268283251111309, 3.282641886609556, 3.282641886609556, 3.282641886609556, 2.3175068031743846, 2.3175068031743846, 2.8094435339317987, 3.3335228102793195, 3.1363457054823267, 2.832928204245517, 4.676518131717516, 4.676518131717516, 4.676518131717516, 3.662159496219269, 3.662159496219269, 3.662159496219269, 3.13073857211587, 3.13073857211587, 2.6388018413584553, 3.267482237222514, 3.267482237222514, 3.267482237222514, 4.232617320657686, 4.232617320657686, 4.860894975322237, 5.230177723827633, 5.101448744154288, 5.101448744154288, 5.101448744154288, 5.0994003316011245, 4.134265248165953, 2.290675320693954, 2.290675320693954, 1.921392572188558, 2.0268971026284, 2.0268971026284, 1.9004293228906475, 1.9004293228906475, 1.9004293228906475, 1.9004293228906475, 3.1070818247150362, 3.1070818247150362, 3.1070818247150362, 3.1070818247150362, 3.2335496044527887, 3.3110981724531654, 3.2951622943253267, 3.2951622943253267, 3.2951622943253267, 3.2951622943253267, 3.2951622943253267, 3.2951622943253267, 3.2951622943253267, 2.666481898461268, 2.666481898461268, 3.1584186292186827, 3.1584186292186827, 3.1584186292186827, 3.1584186292186827, 3.0808700612183055, 3.0808700612183055, 3.0808700612183055, 3.0808700612183055, 3.0808700612183055, 3.0808700612183055, 3.0808700612183055, 3.0808700612183055, 1.8742175593939168, 1.8742175593939168, 1.8742175593939168, 1.3521866955995607, 2.2692328374593855, 2.2692328374593855, 2.2692328374593855, 2.2692328374593855, 4.112822764931385, 4.112822764931385, 4.112822764931385, 4.112822764931385, 4.112822764931385, 4.112822764931385, 4.112822764931385, 4.112822764931385, 4.112822764931385, 3.986354985193632, 3.986354985193632, 3.986354985193632, 3.986354985193632, 3.986354985193632, 3.986354985193632, 4.606822617934233, 4.606822617934233, 4.517775909297032, 4.91201922475277, 4.283741570088218, 4.283741570088218, 4.283741570088218, 4.283741570088218, 5.248876653523389, 4.331830511663565, 4.331830511663565, 4.331830511663565, 4.960108166328116, 4.960108166328116, 4.960108166328116, 4.960108166328116, 4.960108166328116, 4.565864850872378, 4.565864850872378, 5.7725173526967675, 5.7725173526967675, 5.7725173526967675, 5.7725173526967675, 5.7725173526967675, 5.926491379694774, 6.458429075278582, 6.458429075278582, 5.966492344521169, 5.966492344521169, 5.966492344521169, 6.0680468004890304, 5.962542270049189, 5.962542270049189, 5.962542270049189, 5.962542270049189, 5.430604574465378, 5.430604574465378, 5.430604574465378, 3.5870146469933797, 4.3159735154015415, 4.4421689498142225, 4.4421689498142225, 4.4421689498142225, 4.4421689498142225, 4.9641998136085785, 4.9641998136085785, 4.9641998136085785, 4.9641998136085785, 4.9641998136085785, 5.0532465222457805, 5.158751052685622, 5.158751052685622, 5.158751052685622, 5.158751052685622, 5.004777025687615, 5.004777025687615, 5.004777025687615, 5.004777025687615, 4.878581591274934, 4.789534882637733, 5.803893518135981, 5.803893518135981, 5.803893518135981, 5.702339062168118, 5.702339062168118, 5.702339062168118, 5.702339062168118, 5.702339062168118, 5.8288068419058705, 5.8288068419058705, 5.8288068419058705, 5.8288068419058705, 4.863671758470699, 4.863671758470699, 4.863671758470699, 3.8493131229724526, 3.8493131229724526, 3.8493131229724526, 3.8493131229724526, 3.8493131229724526, 3.8493131229724526, 3.1203542545642917, 2.9938864748265384, 2.9938864748265384, 2.9938864748265384, 2.9938864748265384, 2.9938864748265384, 2.9938864748265384, 2.9938864748265384, 2.9938864748265384, 2.9938864748265384, 2.9938864748265384, 3.622300403572962, 3.622300403572962, 3.622300403572962, 3.622300403572962, 3.622300403572962, 3.622300403572962, 3.622300403572962, 3.622300403572962, 3.51679587313312, 3.51679587313312, 3.51679587313312, 3.51679587313312, 3.51679587313312, 3.51679587313312, 3.51679587313312, 3.51679587313312, 5.354443049085259, 5.354443049085259, 3.5195128925963193, 3.5195128925963193, 3.5195128925963193, 3.5195128925963193, 2.8910989638498963, 2.8910989638498963, 2.8910989638498963, 3.2853422793056337, 1.4476951033534937, 1.4476951033534937, 1.4476951033534937, 1.4476951033534937, 1.9796327989373026, 1.9796327989373026, 1.9796327989373026, 1.9796327989373026, 1.9796327989373026, 2.1336068259353085, 2.1336068259353085, 2.1336068259353085, 1.6016691303514994, 1.679217698351876, 1.679217698351876, 1.679217698351876, 2.644352781787047, 1.679217698351876, 1.679217698351876, 1.679217698351876, 1.679217698351876, 2.1711544291092904, 2.0936058611089137, 2.0956542736620785, 2.2011588041019206, 2.2011588041019206, 2.0956542736620785, 2.0956542736620785, 2.0956542736620785, 2.0956542736620785, 2.0956542736620785, 2.0956542736620785, 1.7014109582063406, 1.7014109582063406, 1.7014109582063406, 1.7014109582063406, 1.7014109582063406, 1.7014109582063406, 1.7014109582063406, 1.7014109582063406, 1.547436931208335, 1.547436931208335, 1.547436931208335, 1.547436931208335, 1.547436931208335, 1.547436931208335, 1.547436931208335, 1.547436931208335, 1.547436931208335, 1.5633728093361734, 1.547436931208335, 1.547436931208335, 1.547436931208335, 1.547436931208335, 1.547436931208335, 4.0377762801987185, 4.0377762801987185, 4.139330736166581, 4.139330736166581, 4.139330736166581, 4.139330736166581, 4.228377444803782, 4.228377444803782, 4.228377444803782, 4.228377444803782, 4.228377444803782, 4.228377444803782, 4.1268229888359205, 4.1268229888359205, 4.1268229888359205, 4.1268229888359205, 4.1268229888359205, 4.1268229888359205, 1.636483639845536, 1.636483639845536, 1.016016007104935, 1.016016007104935, 1.0139675945517703, 1.0139675945517703, 1.0139675945517703, 1.0139675945517703, 1.0139675945517703, 1.0139675945517703, 1.0139675945517703, 1.0139675945517703, 1.0139675945517703, 1.9122186059471438, 2.4053330622875873, 2.4053330622875873, 4.240263218776528, 4.868583979917861, 4.868583979917861, 4.868583979917861, 5.49726437578192, 5.49726437578192, 5.49726437578192, 5.49726437578192, 4.975233511987563, 4.975233511987563, 4.07698250059219, 4.07698250059219, 4.07698250059219, 4.07698250059219, 4.07698250059219, 4.07698250059219, 4.07698250059219, 4.07698250059219, 4.07698250059219, 4.07698250059219, 4.07698250059219, 4.07698250059219, 4.07698250059219, 2.870329998767801, 2.870329998767801, 2.870329998767801, 2.870329998767801, 2.8862658768956395, 3.280509192351377, 3.3860137227912195, 2.8928992664507756, 2.8928992664507756, 2.8928992664507756, 2.8928992664507756, 2.8928992664507756, 3.2459679668565204, 3.323516534856898, 3.323516534856898, 3.323516534856898, 3.323516534856898, 2.831579804099483, 2.831579804099483, 2.9580475838372364, 2.9580475838372364, 2.9580475838372364, 2.9580475838372364, 2.9580475838372364, 4.164700085661625, 4.164700085661625, 4.164700085661625, 4.164700085661625, 4.0871515176612485, 4.0871515176612485, 2.8804990158368593, 2.8804990158368593, 2.8804990158368593, 2.8804990158368593, 2.8804990158368593, 2.7540312360991073, 3.2854521602025066, 2.9323834597967617, 2.9323834597967617, 2.9323834597967617, 2.9323834597967617, 2.9323834597967617, 2.3037030639327027, 2.3037030639327027, 2.3037030639327027, 2.3037030639327027, 2.3037030639327027, 2.457677090930708, 2.457677090930708, 1.8293994362661565, 1.8293994362661565, 1.8293994362661565, 1.8293994362661565, 1.7238949058263144, 1.707959027698476, 1.707959027698476, 1.707959027698476, 1.707959027698476, 1.707959027698476, 1.707959027698476, 1.707959027698476, 1.707959027698476, 1.707959027698476, 1.707959027698476, 1.707959027698476, 2.1998957584558902, 2.1998957584558902, 2.1998957584558902, 2.1998957584558902, 2.1998957584558902, 2.1998957584558902, 2.1998957584558902, 1.6684748343524904, 1.6684748343524904, 1.6684748343524904, 1.6684748343524904, 1.6684748343524904, 1.6684748343524904, 1.6684748343524904, 1.6684748343524904, 1.6684748343524904, 1.6684748343524904, 1.6684748343524904, 1.6684748343524904, 1.6684748343524904, 1.6684748343524904, 1.6684748343524904, 1.6684748343524904, 1.6684748343524904, 1.6684748343524904, 1.6684748343524904, 1.6684748343524904, 1.6684748343524904, 1.6684748343524904, 2.1925541107000113, 2.1925541107000113, 2.1925541107000113, 2.1925541107000113, 2.1925541107000113, 2.1925541107000113, 2.1925541107000113, 2.1925541107000113, 2.0385800837020054, 2.0385800837020054, 1.6443367682462675, 1.6443367682462675, 2.658695403744514, 2.658695403744514, 2.658695403744514, 2.658695403744514, 2.658695403744514, 2.658695403744514, 2.658695403744514, 2.658695403744514, 2.658695403744514, 2.658695403744514, 2.658695403744514, 2.658695403744514, 2.658695403744514, 2.658695403744514, 2.658695403744514, 2.658695403744514, 2.658695403744514, 1.6443367682462675, 1.6443367682462675, 1.6443367682462675, 1.6443367682462675, 1.6443367682462675, 1.016016007104935, 1.016016007104935, 1.016016007104935, 1.016016007104935, 1.016016007104935, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.0, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.618404510495167, 1.310569366942399, 1.310569366942399, 1.9310369996830001, 1.9310369996830001, 1.9310369996830001, 1.9310369996830001, 2.085011026681006, 2.085011026681006, 1.9310369996830001, 1.9310369996830001, 1.238872143235768, 1.238872143235768, 1.238872143235768, 1.238872143235768, 1.238872143235768, 1.238872143235768, 1.238872143235768, 2.253230778734015, 2.253230778734015, 2.253230778734015, 4.096820706206014, 4.096820706206014, 2.253230778734015, 2.253230778734015, 2.253230778734015, 2.253230778734015, 2.253230778734015, 2.253230778734015, 1.632763145993414, 1.632763145993414, 1.632763145993414, 1.7103117139937905, 1.7103117139937905, 1.7103117139937905, 1.7103117139937905, 1.7103117139937905, 1.7103117139937905, 1.8158162444336323, 2.5079811008808646, 2.4024765704410225, 2.4024765704410225, 2.4024765704410225, 2.4024765704410225, 2.4024765704410225, 2.4024765704410225, 2.4024765704410225, 2.4024765704410225, 2.4024765704410225, 2.4024765704410225, 2.4024765704410225, 2.9344142660248314, 2.9344142660248314, 2.9344142660248314, 2.9344142660248314, 2.807946486287079, 2.807946486287079, 2.807946486287079, 2.807946486287079, 2.807946486287079, 2.807946486287079, 1.7935878507888319, 1.7935878507888319, 1.7935878507888319, 1.7935878507888319, 1.7935878507888319, 1.7935878507888319, 1.7160392827884552, 1.7160392827884552, 1.7160392827884552, 1.7160392827884552, 1.7160392827884552, 1.7160392827884552, 1.7160392827884552, 1.7160392827884552, 1.7160392827884552, 1.7160392827884552, 1.7160392827884552, 1.7160392827884552, 1.7160392827884552, 1.7160392827884552, 1.7160392827884552, 1.7160392827884552, 1.7160392827884552, 1.7160392827884552, 1.1841015872046463, 1.1841015872046463, 1.1841015872046463, 1.1841015872046463, 1.1841015872046463, 1.1841015872046463, 1.1841015872046463, 1.1841015872046463, 1.1841015872046463, 1.1841015872046463, 1.1841015872046463, 1.1841015872046463, 1.1841015872046463, 1.1841015872046463, 1.1841015872046463, 1.1841015872046463, 1.1841015872046463, 1.1841015872046463, 1.1841015872046463, 1.1841015872046463, 1.1841015872046463, 1.1841015872046463, 1.1841015872046463, 1.1841015872046463, 1.1841015872046463, 1.1841015872046463, 1.1841015872046463, 1.1841015872046463, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.5694852987577909, 0.5694852987577909, 0.5694852987577909, 0.5694852987577909, 0.5694852987577909, 0.5694852987577909, 0.5694852987577909, 0.5694852987577909, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.5974412611972562, 0.5974412611972562, 0.5974412611972562, 0.5974412611972562, 0.5974412611972562, 0.5974412611972562, 0.5974412611972562, 0.5974412611972562, 0.5974412611972562, 0.5974412611972562, 0.5974412611972562, 0.5974412611972562, 0.5974412611972562, 0.5974412611972562, 0.5974412611972562, 0.5974412611972562, 0.5974412611972562, 0.5974412611972562, 0.5974412611972562, 0.5974412611972562, 0.5974412611972562, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 1.0139675945517703, 1.0139675945517703, 0.4919367307574143, 0.6459107577554201, 0.6459107577554201, 0.6459107577554201, 0.1539740269980058, 0.8461388834452379, 0.8461388834452379, 0.8461388834452379, 0.8461388834452379, 0.8461388834452379, 1.3775598075486377, 1.4551083755490142, 1.4551083755490142, 1.4551083755490142, 1.4551083755490142, 1.4551083755490142, 1.4551083755490142, 1.4551083755490142, 1.4551083755490142, 1.4551083755490142, 1.4551083755490142, 1.3775598075486377, 1.3775598075486377, 1.3775598075486377, 1.3775598075486377, 1.5040275872863904, 1.5040275872863904, 1.5040275872863904, 0.9726066631829906, 0.9726066631829906, 0.9726066631829906, 0.9726066631829906, 0.9726066631829906, 0.9726066631829906, 0.9726066631829906, 0.9726066631829906, 0.9726066631829906, 0.9726066631829906, 0.9726066631829906, 0.9726066631829906, 0.9726066631829906, 0.9726066631829906, 0.9726066631829906, 0.9726066631829906, 0.9726066631829906, 0.2804418067357585, 0.2804418067357585, 0.2804418067357585, 0.2804418067357585, 0.2804418067357585, 0.2804418067357585, 0.2804418067357585, 0.2804418067357585, 0.2804418067357585, 0.2804418067357585, 0.2804418067357585, 0.2804418067357585, 0.1539740269980058, 0.1539740269980058, 0.1539740269980058, 0.1539740269980058, 0.1539740269980058, 0.1539740269980058, 0.1539740269980058, 0.1539740269980058, 0.1539740269980058, 0.1539740269980058, 0.1539740269980058, 0.1539740269980058, 0.1539740269980058, 0.1539740269980058, 0.1539740269980058, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01593587812783852, 0.14240365786559125, 0.14240365786559125, 0.14240365786559125, 0.14240365786559125, 0.14240365786559125, 0.14240365786559125, 0.14240365786559125, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.886180046213152, 0.886180046213152, 0.886180046213152, 0.886180046213152, 0.886180046213152, 0.886180046213152, 0.886180046213152, 0.886180046213152, 0.886180046213152, 0.886180046213152, 0.886180046213152, 0.886180046213152, 0.886180046213152, 0.886180046213152, 0.886180046213152, 0.886180046213152, 0.886180046213152, 0.886180046213152, 0.886180046213152, 0.886180046213152, 0.886180046213152, 0.886180046213152, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.8342015786279745, 0.8342015786279745, 0.8342015786279745, 0.8342015786279745, 0.8342015786279745, 0.8342015786279745, 0.8342015786279745, 0.8342015786279745, 0.3027806545245747, 0.3027806545245747, 0.3027806545245747, 0.3027806545245747, 0.3027806545245747, 0.3027806545245747, 0.4286054157045169, 0.4286054157045169, 0.4286054157045169, 0.25229254091769493, 0.25229254091769493, 0.12582476117994218, 0.12582476117994218, 0.2273792171478047, 0.2273792171478047, 0.2273792171478047, 0.30492778514818125, 0.4589018121461871, 0.4589018121461871, 0.4589018121461871, 0.4589018121461871, 0.4589018121461871, 0.4589018121461871, 0.4589018121461871, 2.060901063047744, 2.060901063047744, 2.060901063047744, 2.060901063047744, 2.060901063047744, 2.060901063047744, 4.551240412038127, 4.677435846450809, 4.677435846450809, 4.677435846450809, 4.677435846450809, 4.677435846450809, 4.677435846450809, 4.806164826124153, 4.806164826124153, 4.679969391711471, 3.0779701408099145, 0.5876307918195312, 0.46180603063958897, 0.46180603063958897, 0.3842574626392124, 0.3842574626392124, 0.3842574626392124, 0.3842574626392124, 0.3842574626392124, 0.3842574626392124, 0.9083367389867331, 0.9083367389867331, 0.779607759313389, 0.779607759313389, 2.617254935265529, 0.779607759313389, 0.9054325204933312, 1.0319003002310838, 1.0319003002310838, 1.0319003002310838, 1.0319003002310838, 1.0319003002310838, 1.0319003002310838, 1.0319003002310838, 1.0319003002310838, 1.0319003002310838, 1.0319003002310838, 1.0319003002310838, 1.0319003002310838, 0.9054325204933312, 0.9054325204933312, 0.9054325204933312, 0.3813532441458105, 0.3813532441458105, 0.397289122273649, 0.8892258530310633, 0.8892258530310633, 0.8892258530310633, 0.9947303834709053, 0.9947303834709053, 0.9947303834709053, 0.9947303834709053, 0.9947303834709053, 0.9947303834709053, 0.9947303834709053, 0.9947303834709053, 0.9947303834709053, 0.868905622290963, 0.8529697441631245, 0.8529697441631245, 0.8529697441631245, 0.8529697441631245, 0.8529697441631245, 0.8529697441631245, 0.8529697441631245, 0.9791651785758058, 0.9791651785758058, 0.9791651785758058, 0.8529697441631245, 0.3610330134057102, 0.3610330134057102, 0.3610330134057102, 0.3610330134057102, 0.3610330134057102, 0.3610330134057102, 0.3610330134057102, 0.3610330134057102, 0.3610330134057102, 0.3610330134057102, 0.3610330134057102, 0.3610330134057102, 0.3610330134057102, 0.3610330134057102, 0.3610330134057102, 0.3610330134057102, 0.3610330134057102, 0.3610330134057102, 0.3610330134057102, 0.3610330134057102, 0.3610330134057102, 0.20705898640770443, 0.20705898640770443, 0.20705898640770443, 0.20705898640770443, 0.20705898640770443, 0.20705898640770443, 0.20705898640770443, 0.20705898640770443, 0.20705898640770443, 0.20705898640770443, 0.20705898640770443, 0.20705898640770443, 0.20705898640770443, 0.20705898640770443, 0.20705898640770443, 0.20705898640770443, 0.20705898640770443, 0.20705898640770443, 0.20705898640770443, 0.20705898640770443, 0.20705898640770443, 0.10550453043984191, 0.10550453043984191, 0.10550453043984191, 0.10550453043984191, 0.10550453043984191, 0.10550453043984191, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4931144563404433, 0.4931144563404433, 0.4931144563404433, 0.4931144563404433, 0.4931144563404433, 0.4931144563404433, 0.4931144563404433, 0.4931144563404433, 0.4931144563404433, 0.4931144563404433, 0.4931144563404433, 0.4931144563404433, 0.4931144563404433, 0.4931144563404433, 0.4931144563404433, 0.4931144563404433, 0.4931144563404433, 0.4931144563404433, 0.0, 0.0, 0.0, 0.0, 0.522030863794356, 0.522030863794356, 0.522030863794356, 0.522030863794356, 0.522030863794356, 0.522030863794356, 0.522030863794356, 0.522030863794356, 1.0139675945517703, 1.0139675945517703, 1.0139675945517703, 1.0139675945517703, 1.0139675945517703, 1.0139675945517703, 1.0139675945517703, 1.0139675945517703, 1.0139675945517703, 1.0139675945517703, 1.0139675945517703, 1.140435374289523, 1.140435374289523, 1.140435374289523, 1.140435374289523, 1.140435374289523, 1.140435374289523, 1.140435374289523, 1.140435374289523, 1.140435374289523, 0.618404510495167, 0.618404510495167, 0.618404510495167, 0.618404510495167, 0.618404510495167, 0.618404510495167, 0.12646777973775272, 0.6578887038411526, 0.6578887038411526, 0.6578887038411526, 0.6578887038411526, 0.6578887038411526, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.12646777973775272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.6089694921037764, 0.6089694921037764, 0.6089694921037764, 0.6089694921037764, 0.6089694921037764, 0.6089694921037764, 0.6089694921037764, 0.6089694921037764, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 0.5314209241033998, 1.0534517878977558, 1.0534517878977558, 1.4476951033534937, 1.4476951033534937, 1.4476951033534937, 1.4476951033534937, 1.4476951033534937, 1.4476951033534937, 1.4476951033534937, 1.4476951033534937, 1.4476951033534937, 1.4476951033534937, 1.4476951033534937, 0.9256642395591377, 0.9256642395591377, 0.9256642395591377, 0.9256642395591377, 0.9256642395591377, 0.9256642395591377, 0.9256642395591377, 0.9256642395591377, 0.9256642395591377, 0.9256642395591377, 0.9256642395591377, 0.9256642395591377, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 1.022657244202161, 1.5540781683055611, 1.5540781683055611, 1.022657244202161, 1.022657244202161, 1.022657244202161, 1.022657244202161, 2.8603044201543013, 2.8603044201543013, 2.8603044201543013, 2.8603044201543013, 4.075480418879876, 4.17703487484774, 4.17703487484774, 4.17703487484774, 4.17703487484774, 4.17703487484774, 4.17703487484774, 4.17703487484774, 4.17703487484774, 4.17703487484774, 4.17703487484774, 4.17703487484774, 4.17703487484774, 4.17703487484774, 4.254583442848116, 4.254583442848116, 4.254583442848116, 4.254583442848116, 4.254583442848116, 4.254583442848116, 4.254583442848116, 4.254583442848116, 2.410993515376117, 2.410993515376117, 2.410993515376117, 2.410993515376117, 2.410993515376117, 2.410993515376117, 2.410993515376117, 0.5733463394239768, 0.5733463394239768, 0.5733463394239768, 0.5733463394239768, 0.4957977714236003, 0.4957977714236003, 0.4957977714236003, 0.4957977714236003, 0.4957977714236003, 0.4957977714236003, 0.4957977714236003, 0.4957977714236003, 0.4957977714236003, 0.4957977714236003, 0.4957977714236003, 0.4957977714236003, 0.4957977714236003, 0.4957977714236003, 0.4957977714236003, 0.10155445596786251, 0.10155445596786251, 0.10155445596786251, 0.10155445596786251, 0.10155445596786251, 0.10155445596786251, 0.10155445596786251, 0.10155445596786251, 0.10155445596786251, 0.10155445596786251, 0.10155445596786251, 0.10155445596786251, 0.10155445596786251, 0.10155445596786251, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39424331545573776, 0.39424331545573776, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12646777973775272, 0.12646777973775272, 0.6270623857715555, 0.6270623857715555, 0.6270623857715555, 0.6270623857715555, 0.6270623857715555, 0.6270623857715555, 1.3192272422187876, 1.3192272422187876, 1.3192272422187876, 1.3192272422187876, 1.3192272422187876, 1.3192272422187876, 1.1927594624810347, 1.1927594624810347, 1.1927594624810347, 1.1927594624810347, 1.1927594624810347, 1.1927594624810347, 1.1927594624810347, 1.1927594624810347, 1.1927594624810347, 1.1927594624810347, 1.1927594624810347, 1.1927594624810347, 1.1927594624810347, 1.1927594624810347, 1.1927594624810347, 1.1927594624810347, 1.1927594624810347, 1.1927594624810347, 1.1927594624810347, 1.1927594624810347, 1.1927594624810347, 1.1927594624810347, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.692164856447232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.4919367307574143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.39424331545573776, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12582476117994218, 0.12582476117994218, 0.12582476117994218, 0.12582476117994218, 0.12582476117994218, 0.12582476117994218, 0.12582476117994218, 0.12582476117994218, 0.12582476117994218, 0.12582476117994218, 0.12582476117994218, 0.12582476117994218, 0.12582476117994218, 0.12582476117994218, 0.12582476117994218, 0.12582476117994218, 0.12582476117994218, 0.12582476117994218, 0.12582476117994218, 0.2313292916197841, 0.2313292916197841, 0.12582476117994218, 0.12582476117994218, 0.12582476117994218, 0.12582476117994218, 0.12582476117994218, 0.12582476117994218, 0.12582476117994218, 0.12582476117994218, 0.20337332918031875, 0.20337332918031875, 0.20337332918031875, 0.20337332918031875, 0.20337332918031875, 0.20337332918031875, 0.20337332918031875, 0.20337332918031875, 0.20337332918031875, 0.20337332918031875, 0.20337332918031875, 0.20337332918031875, 0.20337332918031875, 0.20337332918031875, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.6089694921037764, 0.6089694921037764, 0.6089694921037764, 0.6089694921037764, 0.6089694921037764, 0.6089694921037764, 0.6089694921037764, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.07754856800037657, 0.23152259499838237, 0.23152259499838237, 0.23152259499838237, 0.23152259499838237, 0.23152259499838237, 0.23152259499838237, 0.23152259499838237, 0.23152259499838237, 0.23152259499838237, 0.23152259499838237, 0.23152259499838237, 0.23152259499838237, 0.23152259499838237, 0.7535534587927384, 0.7535534587927384, 0.7535534587927384, 0.7535534587927384, 0.7535534587927384, 0.7535534587927384, 0.7535534587927384, 0.7535534587927384, 0.7535534587927384, 1.2454901895501527, 1.2454901895501527, 1.2454901895501527, 1.2454901895501527, 1.2454901895501527, 1.2454901895501527, 0.7535534587927384, 0.7535534587927384, 0.23152259499838237, 0.23152259499838237, 0.1539740269980058, 0.1539740269980058, 1.119109110433177, 1.119109110433177, 1.119109110433177, 1.119109110433177, 1.119109110433177, 1.119109110433177, 1.119109110433177, 1.119109110433177, 1.119109110433177, 1.119109110433177, 1.119109110433177, 1.119109110433177, 1.119109110433177, 1.119109110433177, 1.119109110433177, 1.119109110433177, 1.119109110433177, 1.119109110433177, 1.119109110433177, 1.119109110433177, 1.119109110433177, 1.119109110433177, 1.119109110433177, 1.119109110433177, 1.119109110433177, 0.9651350834351712, 0.9651350834351712, 0.9651350834351712, 0.9651350834351712, 0.9651350834351712, 0.9651350834351712, 0.9651350834351712, 0.9651350834351712, 0.9651350834351712, 0.9651350834351712, 0.9651350834351712, 0.9651350834351712, 0.9651350834351712, 0.9651350834351712, 0.9651350834351712, 0.9651350834351712, 0.9651350834351712, 0.9651350834351712, 0.9651350834351712, 0.9651350834351712, 0.9651350834351712, 0.9651350834351712, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0143586354982468, 1.0143586354982468, 1.0143586354982468, 1.0143586354982468, 1.0143586354982468, 1.0143586354982468, 1.0143586354982468, 1.0143586354982468, 1.0143586354982468, 1.0143586354982468, 1.0143586354982468, 1.0143586354982468, 1.0143586354982468, 1.0143586354982468, 1.0143586354982468, 1.0143586354982468, 1.0143586354982468, 1.0143586354982468, 1.0143586354982468, 1.0143586354982468, 1.0143586354982468, 1.0143586354982468, 1.0143586354982468, 1.0143586354982468, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(iter_avg_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 4])\n",
      "torch.Size([3, 4])\n",
      "torch.Size([1, 3, 4])\n",
      "torch.Size([2, 3, 4])\n",
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(1, 3, 4)\n",
    "print(a.shape)\n",
    "b = torch.rand(3, 4)\n",
    "print(b.shape)\n",
    "b = b.unsqueeze(0)\n",
    "print(b.shape)\n",
    "c = torch.cat([a, b], dim=0)\n",
    "print(c.shape)\n",
    "print(torch.zeros(1,1, dtype=torch.float).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {},
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[263, 211, 221, 233, 253, 270, 253, 232, 238, 241, 257, 222, 232, 225, 234, 215, 273, 229, 246, 234, 228, 240, 237, 256, 257]\n"
     ]
    }
   ],
   "source": [
    "print(dqnloc_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-606801f44006>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtx_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_txloc_ndx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m58\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m180\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m58\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m180\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m11.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtx_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mrbdir_ndx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdqnbestbeam_ndxlist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtx_num\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobs_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnvec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtest_txbdir\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m58\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m180\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m58\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m180\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m11.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msc_xyz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mch_randvals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mepisode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrbdir_ndx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_txbdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdqneplen_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtx_num\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobs_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnvec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtxdir_ndx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_episode_length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#test a particular TXlocation\n",
    "tx_num = em.env.get_txloc_ndx(np.array([[-100*np.cos(58*np.pi/180),-100*np.sin(58*np.pi/180)+50,11.5]]))\n",
    "print(tx_num)\n",
    "rbdir_ndx = em.env.dqnbestbeam_ndxlist[tx_num * em.env.obs_space.nvec[3] + test_txbdir]\n",
    "obs = em.test_reset(np.array([[-100*np.cos(58*np.pi/180),-100*np.sin(58*np.pi/180)+50,11.5]]), em.env.sc_xyz, ch_randvals[episode], rbdir_ndx,test_txbdir)\n",
    "dqneplen_list[tx_num * em.env.obs_space.nvec[3] + em.env.txdir_ndx] = min_episode_length\n",
    "\n",
    "em.env.goal_steps = dqneplen_list[tx_num * em.env.obs_space.nvec[3] + em.env.txdir_ndx]\n",
    "init_obs = obs\n",
    "temp_val = []\n",
    "ep_actions = []  \n",
    "#rbdir_ndx = em.env.dqnbestbeam_ndxlist[tx_num * self.obs_space.nvec[3] + test_txbdir]\n",
    "#Re-collect the previous stored best dqn action for the TXlocation\n",
    "#em.env.prev_bestaction#\n",
    "tx_num = em.env.get_txloc_ndx(em.env.tx_loc)\n",
    "prevep_bestaction = em.env.dqnbestbeam_ndxlist[tx_num * em.env.obs_space.nvec[3] + em.env.txdir_ndx]#em.env.rbdir_ndx\n",
    "#ep_actions.append(em.env.rbdir_ndx)\n",
    "init_randaction = em.env.rbdir_ndx\n",
    "policy_net.eval()\n",
    "with torch.no_grad():\n",
    "    action_probs = policy_net(obs).detach().data.cpu().numpy()[0]  \n",
    "policy_net.train()\n",
    "actions= np.argsort(action_probs)[::-1]\n",
    "\n",
    "em.env.action_list = []\n",
    "em.env.action_list.append(em.env.rbdir_ndx)\n",
    "\n",
    "selected_actions = []\n",
    "selected_actions.append(actions[0])\n",
    "ep_actions.append(actions[0])\n",
    "\n",
    "#Store the current best dqn action for the episode\n",
    "tx_num = em.env.get_txloc_ndx(em.env.tx_loc)\n",
    "em.env.dqnbestbeam_ndxlist[em.env.tx_num * em.env.obs_space.nvec[3] + em.env.txdir_ndx] = actions[0]\n",
    "\n",
    "nbour_len = 0\n",
    "if (em.env.goal_steps % 2 == 0):\n",
    "    nbour_len = int(em.env.goal_steps/2)+1\n",
    "else:\n",
    "    nbour_len = int((em.env.goal_steps)/2)+1\n",
    "for i in range(1,nbour_len):\n",
    "    if ((actions[0]-i) < 0):\n",
    "        selected_actions.append(em.env.N_rx+actions[0]-i)\n",
    "        ep_actions.append(em.env.N_rx+actions[0]-i)\n",
    "    else:\n",
    "        selected_actions.append(actions[0]-i)\n",
    "        ep_actions.append(actions[0]-i)\n",
    "    if((i+1)<nbour_len) or (not(em.env.goal_steps % 2 == 0)):\n",
    "        #if ((actions[0]+i) > (em.env.N_rx-1)):\n",
    "        #    selected_actions.append(actions[0]+i -em.env.N_rx)\n",
    "        #    ep_actions.append(actions[0]+i -em.env.N_rx)\n",
    "        #else:\n",
    "        selected_actions.append((actions[0]+i) % em.env.N_rx)\n",
    "        ep_actions.append((actions[0]+i) % em.env.N_rx)\n",
    "    #else:\n",
    "    #    selected_actions.append((actions[0]+i) % em.env.N_rx)\n",
    "    #    ep_actions.append((actions[0]+i) % em.env.N_rx)\n",
    "\n",
    "em.env.reward_list = []\n",
    "em.env.reward_list.append(float(np.around(1.0, decimals=2)))\n",
    "\n",
    "tx_dirs.append((em.env.tx_bdir[0]*(180/np.pi), em.env.tx_bdir[1]))\n",
    "rx_dirs.append((em.env.rx_bdir[0]*(180/np.pi), em.env.rx_bdir[1]))\n",
    "data_rates.append(em.env.rate)\n",
    "print(\"TX Location: {}, Goal steps: {}, init_randaction: {},ep_actions: {}, prevep_bestaction: {}\".format(em.env.tx_loc, em.env.goal_steps, init_randaction, ep_actions,prevep_bestaction))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "min_ndx=0\n",
    "max_ndx=500\n",
    "plt.plot(test_eps_iters[min_ndx:max_ndx])\n",
    "plt.show()\n",
    "print(np.mean(test_eps_iters), len(test_eps_iters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "print(em.env.ch_model)\n",
    "print(em.env.sc_xyz)\n",
    "\n",
    "test_net = QNetwork(state_size, available_actions, seed).to(device)\n",
    "test_net.load_state_dict(torch.load('checkpoint.pth'))\n",
    "test_net.eval()\n",
    "tx_loc = np.array([[-100*np.cos(58*np.pi/180),-100*np.sin(58*np.pi/180),21.5]])\n",
    "tbdir_ndx = 0\n",
    "rbdir_ndx = 0\n",
    "norm_tx_xloc = np.array([(tx_loc[0][0]) / 1000])  # np.max(self.rx_xcov)])#np.array([(self.tx_loc[0][0]+np.max(self.rx_xcov))/(np.max(self.rx_xcov))])#-np.min(self.rx_xcov))])\n",
    "norm_tx_yloc = np.array([(tx_loc[0][1]) / 1000])  # max(np.max(self.rx_ycov),1)])#np.array([(self.tx_loc[0][1] + np.max(self.rx_ycov)) / (np.max(self.rx_ycov))])# - np.min(self.rx_ycov))])\n",
    "norm_tx_zloc = np.array([(tx_loc[0][2]) / 22.5])\n",
    "norm_tx_ndx = np.array([tbdir_ndx / em.env.obs_space.nvec[3]])\n",
    "norm_rx_ndx = np.array([rbdir_ndx / em.env.action_space.n])\n",
    "obs = np.array([np.concatenate((norm_rx_ndx, norm_tx_ndx, norm_tx_xloc, norm_tx_yloc,norm_tx_zloc), axis=0)])\n",
    "\n",
    "obs_tensor = torch.tensor(obs, device=device, dtype=torch.float32)\n",
    "#print(np.sort(test_net(obs_tensor).data.cpu().numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[9, 6])\n",
    "min_ndx=24\n",
    "max_ndx=48\n",
    "plt.plot(np.arange(len(test_data_rates[min_ndx:max_ndx])), test_data_rates[min_ndx:max_ndx], 'b', np.arange(len(test_data_rates[min_ndx:max_ndx])), test_minexh_rates[min_ndx:max_ndx], 'r--', np.arange(len(test_data_rates[min_ndx:max_ndx])), test_maxexh_rates[min_ndx:max_ndx], 'g--')\n",
    "#plt.plot(np.arange(len(test_data_rates[3080:3140])), test_data_rates[3080:3140], 'b', np.arange(len(test_data_rates[3080:3140])), test_minexh_rates[3080:3140], 'r--', np.arange(len(test_data_rates[3080:3140])), test_maxexh_rates[3080:3140],'g--')\n",
    "#plt.plot(np.arange(len(test_data_rates[4650:4740])), test_data_rates[4650:4740], 'b', np.arange(len(test_data_rates[4650:4740])), test_minexh_rates[4650:4740], 'r--', np.arange(len(test_data_rates[4650:4740])), test_maxexh_rates[4650:4740],'g--')\n",
    "#plt.plot(np.arange(len(test_data_rates[6230:])), test_data_rates[6230:], 'b', np.arange(len(test_data_rates[6230:])), test_minexh_rates[6230:], 'r--', np.arange(len(test_data_rates[6230:])), test_maxexh_rates[6230:],'g--')\n",
    "\n",
    "plt.xticks(np.arange(0, max_ndx-min_ndx), [str(x) for x in np.arange(min_ndx, max_ndx)])\n",
    "plt.legend(['learnt rate','min exhrate', 'max exhrate'])\n",
    "plt.xlabel('Episode #')\n",
    "plt.ylabel('data rate (bits/s)')\n",
    "plt.title('Beam alignment with episode length:{}'.format(em.env.goal_steps))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "min_ndx=60\n",
    "max_ndx=80\n",
    "print(test_data_rates[min_ndx:max_ndx])\n",
    "print(test_maxexh_rates[min_ndx:max_ndx])\n",
    "print(em.env.sc_xyz)\n",
    "print(em.env.ch_model)\n",
    "print(em.env.init_ch_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "print(test_data_rates[69])\n",
    "print([(x[0]*180/np.pi, x[1]) for x in em.env.BeamSet])\n",
    "#print(em.env.BeamSet[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "print(em.env.dqnobs_counter)\n",
    "print(len(em.env.dqnobs_counter))\n",
    "print(np.mean(em.env.dqnobs_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "print(em.env.dqneplen_counter)\n",
    "print(np.mean(em.env.dqneplen_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "tx_loc = np.array([[-100*np.cos(58*np.pi/180),-100*np.sin(58*np.pi/180),21.5]])\n",
    "txdir_ndx = 0\n",
    "\n",
    "tx_num = em.env.get_txloc_ndx(tx_loc)\n",
    "obs_epiters = em.env.dqneplen_list[tx_num * em.env.obs_space.nvec[3] + txdir_ndx]\n",
    "\n",
    "count = 0\n",
    "for x,y,z,w in zip(em.env.dqnepaction_list[tx_num * em.env.obs_space.nvec[3] + txdir_ndx],em.env.dqnepsilon_list[tx_num * em.env.obs_space.nvec[3] + txdir_ndx],em.env.dqnactionflag_list[tx_num * em.env.obs_space.nvec[3] + txdir_ndx], em.env.dqnactionrwd_list[tx_num * em.env.obs_space.nvec[3] + txdir_ndx]):\n",
    "    #print(\"episode actions: {}, eps: {}\".format(x,y,z))\n",
    "    temp_list =[(i,j,k) for i,j,k in zip(x,z,w)]\n",
    "    count = count + 1\n",
    "    if (count >2980):\n",
    "        print(\"NLoS episode actions: {}, eps: {}\".format(temp_list,y))\n",
    "    elif (count >=2300 and count <2340):\n",
    "        print(\"NLoS-random episode actions: {}, eps: {}\".format(temp_list,y))\n",
    "    \n",
    "    elif(count > 1990 and count <= 2000):\n",
    "    #    break\n",
    "        print(\"LoS episode actions: {}, eps: {}\".format(temp_list,y))\n",
    "    #else:\n",
    "    #    pass\n",
    "    \n",
    "        \n",
    "#print(em.env.dqnepsilon_list[tx_num * em.env.obs_space.nvec[3] + txdir_ndx])\n",
    "#fig = plt.figure(figsize=[9, 6])\n",
    "#plt.plot(np.arange(len(obs_epiters)), obs_epiters, 'b')\n",
    "#plt.xlabel('Episode #')\n",
    "#plt.ylabel('Episode Iterations')\n",
    "#plt.title('Training convergence for tx_loc:{}, txdir: {}, ep_len:{}'.format(tx_loc, (em.env.BeamSet[txdir_ndx][0]*180/np.pi,em.env.BeamSet[txdir_ndx][1]),em.env.goal_steps))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "tx_loc = np.array([[-200,-200,21.5]])\n",
    "txdir_ndx = 0\n",
    "#print(em.env.BeamSet[5][0]*180/np.pi)\n",
    "print(\"tx-loc: \", tx_loc)\n",
    "\n",
    "em.env.sc_xyz = np.array([[650,300,21.5], [0,-550,21.5]])#[-200,300,21.5], [-200,-300,21.5], [150,-400,21.5], ,[-250,-200,21.5]np.array([[-100,50,11.5], [-100,-50,11.5], [-50,100,11.5],[50,100,11.5]])#np.array([[50,0,0], [-50,-100,0], [100,50,0],[50,-100,0]])#np.array([[0,100,0], [10,50,0], [40,60,0], [70,80,0], [100,50,0], [80,85,0], [20,30,0], [10,40,0], [80,20,0]])#np.array([[0,100,0]])#np.array([[0,100,0],[250,0,0],[-200,-150,0]]) #reflection points for now\n",
    "em.env.ch_model ='uma-nlos'#'uma-nlos' #free-space path loss model\n",
    "em.env.init_ch_model = 'uma-nlos'\n",
    "tx_num = em.env.get_txloc_ndx(tx_loc)\n",
    "print(em.env.ch_model)\n",
    "print(em.env.sc_xyz)\n",
    "for rbdir_ndx in range(8):\n",
    "    obs = em.test_reset(tx_loc, em.env.sc_xyz, np.exp(1j*2*np.pi*0.6), rbdir_ndx,txdir_ndx)\n",
    "    #_ = em.env.test_reset(tx_loc, txdir_ndx, rbdir_ndx,em.env.sc_xyz, np.exp(1j * 2 * np.pi * 0.6))\n",
    "    print(\"rbdir_ndx: {}, SNR:{}, rate: {}\".format(rbdir_ndx, em.env.SNR, em.env.rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "tx_loc = np.array([[-200,-200,21.5]])#np.array([[-100*np.cos(58*np.pi/180),-100*np.sin(58*np.pi/180),21.5]])\n",
    "txdir_ndx = 0\n",
    "\n",
    "#tx_num = em.env.get_txloc_ndx(tx_loc)\n",
    "em.env.sc_xyz=np.array([])\n",
    "em.env.ch_model ='uma-los'#'uma-nlos' #free-space path loss model\n",
    "em.env.init_ch_model = 'uma-los'\n",
    "print(em.env.ch_model)\n",
    "print(em.env.sc_xyz)\n",
    "for rbdir_ndx in range(8):\n",
    "    obs = em.test_reset(tx_loc, em.env.sc_xyz, np.exp(1j*2*np.pi*0.6), rbdir_ndx,txdir_ndx)\n",
    "    #_ = em.env.test_reset(tx_loc, txdir_ndx, rbdir_ndx,em.env.sc_xyz, np.exp(1j * 2 * np.pi * 0.6))\n",
    "    print(\"rbdir_ndx: {}, SNR:{}, rate: {}\".format(rbdir_ndx, em.env.SNR, em.env.rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "print(\"angle 5: \", em.env.BeamSet[5][0]*180/np.pi)\n",
    "print(\"angle 6: \", em.env.BeamSet[6][0]*180/np.pi)\n",
    "tx_loc = np.array([[-100*np.cos(45*np.pi/180),-100*np.sin(45*np.pi/180),21.5]])\n",
    "print(tx_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "#import pickle\n",
    "\n",
    "#memory.save('memory_checkpoint.pth')\n",
    "plot(ep_rewards, 100, test_rewards)\n",
    "print(ep_rewards[:100])\n",
    "moving_avg_rwd = get_moving_average(100, ep_rewards[:100])\n",
    "print(moving_avg_rwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Test the DQN agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "from Source.misc_fun.utils import var_plotbeam\n",
    "\n",
    "print(tx_dirs)\n",
    "print(rx_dirs)\n",
    "for tx_ang, rx_ang in zip(tx_dirs, rx_dirs):\n",
    "    tx_theta, tx_gr = var_plotbeam(tx_ang, em.env.N_tx)\n",
    "    rx_theta, rx_gr = var_plotbeam(rx_ang, em.env.N_rx)\n",
    "    ax1 = plt.subplot(122, projection='polar')\n",
    "    ax1.plot(tx_theta, tx_gr)\n",
    "\n",
    "    ax2 = plt.subplot(121, projection='polar')\n",
    "    ax2.plot(rx_theta, rx_gr)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Display all exhaustive rate measurements from env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
    "from matplotlib.collections import PolyCollection\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "poly = PolyCollection(verts[:4], facecolors=['r', 'g', 'b', 'y'], alpha=0.6)\n",
    "print(len(verts))\n",
    "print(verts[0:2])\n",
    "#print(np.array(tx_locs[:4]))\n",
    "ax.add_collection3d(poly, zs=np.arange(1,5), zdir='y')\n",
    "\n",
    "ax.set_xlabel('X (beam pairs)')\n",
    "ax.set_ylabel('Y (tx_locs)')\n",
    "ax.set_zlabel('Z (data rates)')\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_ylim(1, 5)\n",
    "ax.set_zlim(10, 30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "from Source.misc_fun.utils import plotbeam\n",
    "\n",
    "tx_theta, tx_gr = plotbeam(exh_txbeams[0]*(np.pi/180), em.env.N_tx)\n",
    "rx_theta, rx_gr = plotbeam(exh_rxbeams[0]*(np.pi/180), em.env.N_rx)\n",
    "ax1 = plt.subplot(122, projection='polar')\n",
    "ax1.plot(tx_theta, tx_gr)\n",
    "\n",
    "ax2 = plt.subplot(121, projection='polar')\n",
    "ax2.plot(rx_theta, rx_gr)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
