{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_combrf\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize gym environment\n",
    "env = gym.make('combrf-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper-parameters\n",
    "UPDATE_EVERY = 50 #how often to update the network\n",
    "EPS_START = 1\n",
    "EPS_END = 0.01\n",
    "EPS_DECAY = 0.9983\n",
    "EPS_STEP_LIMIT = 50\n",
    "\n",
    "TRAIN_EPISODES = 20\n",
    "TEST_EPISODES = 1\n",
    "seed = 0\n",
    "\n",
    "#initialize GPU device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine state and action spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of each action:  (1,)\n",
      "Size of each observation:  (65,)\n",
      "Observation looks like:\n",
      "[-1.40685647e-07-6.56304894e-08j  1.50340783e-07-3.86970426e-08j\n",
      " -9.15157490e-08+1.25398086e-07j -8.99467536e-09-1.54980347e-07j\n",
      "  1.05408028e-07+1.13969118e-07j -1.53808063e-07-2.10449971e-08j\n",
      "  1.32148582e-07-8.14651121e-08j -5.02954707e-08+1.46867893e-07j\n",
      "  1.50340783e-07-3.86970426e-08j -9.15157490e-08+1.25398086e-07j\n",
      " -8.99467536e-09-1.54980347e-07j  1.05408028e-07+1.13969118e-07j\n",
      " -1.53808063e-07-2.10449971e-08j  1.32148582e-07-8.14651121e-08j\n",
      " -5.02954707e-08+1.46867893e-07j -5.44672093e-08-1.45372402e-07j\n",
      " -9.15157490e-08+1.25398086e-07j -8.99467536e-09-1.54980347e-07j\n",
      "  1.05408028e-07+1.13969118e-07j -1.53808063e-07-2.10449971e-08j\n",
      "  1.32148582e-07-8.14651121e-08j -5.02954707e-08+1.46867893e-07j\n",
      " -5.44672093e-08-1.45372402e-07j  1.34420096e-07+7.76598365e-08j\n",
      " -8.99467536e-09-1.54980347e-07j  1.05408028e-07+1.13969118e-07j\n",
      " -1.53808063e-07-2.10449971e-08j  1.32148582e-07-8.14651121e-08j\n",
      " -5.02954707e-08+1.46867893e-07j -5.44672093e-08-1.45372402e-07j\n",
      "  1.34420096e-07+7.76598365e-08j -1.53144678e-07+2.54267563e-08j\n",
      "  1.05408028e-07+1.13969118e-07j -1.53808063e-07-2.10449971e-08j\n",
      "  1.32148582e-07-8.14651121e-08j -5.02954707e-08+1.46867893e-07j\n",
      " -5.44672093e-08-1.45372402e-07j  1.34420096e-07+7.76598365e-08j\n",
      " -1.53144678e-07+2.54267563e-08j  1.02111916e-07-1.16931471e-07j\n",
      " -1.53808063e-07-2.10449971e-08j  1.32148582e-07-8.14651121e-08j\n",
      " -5.02954707e-08+1.46867893e-07j -5.44672093e-08-1.45372402e-07j\n",
      "  1.34420096e-07+7.76598365e-08j -1.53144678e-07+2.54267563e-08j\n",
      "  1.02111916e-07-1.16931471e-07j -4.56721392e-09+1.55173944e-07j\n",
      "  1.32148582e-07-8.14651121e-08j -5.02954707e-08+1.46867893e-07j\n",
      " -5.44672093e-08-1.45372402e-07j  1.34420096e-07+7.76598365e-08j\n",
      " -1.53144678e-07+2.54267563e-08j  1.02111916e-07-1.16931471e-07j\n",
      " -4.56721392e-09+1.55173944e-07j -9.50578523e-08-1.22734742e-07j\n",
      " -5.02954707e-08+1.46867893e-07j -5.44672093e-08-1.45372402e-07j\n",
      "  1.34420096e-07+7.76598365e-08j -1.53144678e-07+2.54267563e-08j\n",
      "  1.02111916e-07-1.16931471e-07j -4.56721392e-09+1.55173944e-07j\n",
      " -9.50578523e-08-1.22734742e-07j  1.51384102e-07+3.43899112e-08j\n",
      "  1.38678274e-07+1.39376809e-07j]\n"
     ]
    }
   ],
   "source": [
    "#reset the environment\n",
    "obs = env.reset()\n",
    "\n",
    "#size of each action\n",
    "action_size = env.action_space.shape\n",
    "print(\"Size of each action: \", action_size)\n",
    "\n",
    "#size of observation\n",
    "print(\"Size of each observation: \", obs.shape)\n",
    "print(\"Observation looks like:\")\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform random actions in the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random TX location: [[ -50 -100    0]]\n",
      "Capacity: 55.53076991098181\n",
      "Episodic score: 3.2813957174806715e-10 with episode length: 8 \n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "count = 0\n",
    "ep_rwd=0\n",
    "while True:\n",
    "    action = np.array([round(np.random.uniform(0,2*math.pi), 2)])\n",
    "    obs, rwd, done, _ = env.step(action)\n",
    "    ep_rwd += rwd\n",
    "    count +=1\n",
    "    if done:\n",
    "        break\n",
    "print(\"Random TX location: {0}\".format(env.tx_loc))\n",
    "print(\"Capacity: {0}\".format(env.cap))\n",
    "print(\"Episodic score: {0} with episode length: {1} \".format(ep_rwd, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate DDPG agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.complex128. The only supported types are: float64, float32, float16, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-c976f331e9f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mobs_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.complex128. The only supported types are: float64, float32, float16, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "#import custom classes\n",
    "from Source.ddpg_rcv_agent import Agent\n",
    "from Source.nn_model import Actor, Critic\n",
    "from Source.ddpg_rcv_agent import Agent, ReplayBuffer, OUNoise\n",
    "from collections import deque\n",
    "\n",
    "#reset the environment\n",
    "obs = env.reset()\n",
    "\n",
    "state_size = obs.shape[0]\n",
    "action_size = env.action_space.shape[0]\n",
    "\n",
    "#instantiate the agent\n",
    "agent = Agent(state_size=state_size, action_size=action_size, seed=0)\n",
    "\n",
    "print(type(obs))\n",
    "obs_tensor = torch.from_numpy(obs).to(device)\n",
    "print(obs_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDPG Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_episodes = 400\n",
    "print_every= 100\n",
    "\n",
    "scores_deque = deque(maxlen=print_every)\n",
    "scores = []\n",
    "\n",
    "for i_episode in range(1,train_episodes+1):\n",
    "    \n",
    "    # reset the environment\n",
    "    obs = env.reset()\n",
    "    agent.reset()\n",
    "        \n",
    "    score = 0\n",
    "    while True:\n",
    "        action = agent.act(obs)\n",
    "        env_info = env.step(action)[brain_name]\n",
    "        next_state = env_info.vector_observations\n",
    "        reward = env_info.rewards\n",
    "        done = env_info.local_done[0]\n",
    "        agent.step(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        score+=env_info.rewards\n",
    "        t_step +=1\n",
    "        if done:\n",
    "            #print('t_step: {}'.format(t_step))\n",
    "            break\n",
    "            \n",
    "    scores_deque.append(score[0])\n",
    "    scores.append(score[0])\n",
    "    #print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)), end=\"\")\n",
    "    torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "    torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "    #if i_episode % print_every == 0:\n",
    "    #    print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
    "    \n",
    "    \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
